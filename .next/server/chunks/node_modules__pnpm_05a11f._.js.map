{
  "version": 3,
  "sections": [
    {"offset": {"line": 5, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/postprocess.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Event} Event\n */\n\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * @param {Array<Event>} events\n * @returns {Array<Event>}\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events\n}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;AAQM,SAAS,YAAY,MAAM;IAChC,MAAO,CAAC,sPAAY,QAAS;IAC3B,QAAQ;IACV;IACA,OAAO;AACT"}},
    {"offset": {"line": 19, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 24, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/postprocess.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Event} Event\n */\n\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * @param {Array<Event>} events\n * @returns {Array<Event>}\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n\n  return events\n}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;AAQM,SAAS,YAAY,MAAM;IAChC,MAAO,CAAC,sPAAY,QAAS;IAC3B,QAAQ;IACV;IAEA,OAAO;AACT"}},
    {"offset": {"line": 38, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 43, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/preprocess.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Value} Value\n */\n\n/**\n * @callback Preprocessor\n * @param {Value} value\n * @param {Encoding | null | undefined} [encoding]\n * @param {boolean | null | undefined} [end=false]\n * @returns {Array<Chunk>}\n */\n\nconst search = /[\\0\\t\\n\\r]/g\n\n/**\n * @returns {Preprocessor}\n */\nexport function preprocess() {\n  let column = 1\n  let buffer = ''\n  /** @type {boolean | undefined} */\n  let start = true\n  /** @type {boolean | undefined} */\n  let atCarriageReturn\n  return preprocessor\n\n  /** @type {Preprocessor} */\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = []\n    /** @type {RegExpMatchArray | null} */\n    let match\n    /** @type {number} */\n    let next\n    /** @type {number} */\n    let startPosition\n    /** @type {number} */\n    let endPosition\n    /** @type {Code} */\n    let code\n\n    // @ts-expect-error `Buffer` does allow an encoding.\n    value = buffer + value.toString(encoding)\n    startPosition = 0\n    buffer = ''\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++\n      }\n      start = undefined\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition =\n        match && match.index !== undefined ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5)\n          atCarriageReturn = undefined\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n        switch (code) {\n          case 0: {\n            chunks.push(65533)\n            column++\n            break\n          }\n          case 9: {\n            next = Math.ceil(column / 4) * 4\n            chunks.push(-2)\n            while (column++ < next) chunks.push(-1)\n            break\n          }\n          case 10: {\n            chunks.push(-4)\n            column = 1\n            break\n          }\n          default: {\n            atCarriageReturn = true\n            column = 1\n          }\n        }\n      }\n      startPosition = endPosition + 1\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5)\n      if (buffer) chunks.push(buffer)\n      chunks.push(null)\n    }\n    return chunks\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;CAKC,GAED;;;;;;CAMC;;;AAED,MAAM,SAAS;AAKR,SAAS;IACd,IAAI,SAAS;IACb,IAAI,SAAS;IACb,gCAAgC,GAChC,IAAI,QAAQ;IACZ,gCAAgC,GAChC,IAAI;IACJ,OAAO;IAEP,yBAAyB,GACzB,SAAS,aAAa,KAAK,EAAE,QAAQ,EAAE,GAAG;QACxC,yBAAyB,GACzB,MAAM,SAAS,EAAE;QACjB,oCAAoC,GACpC,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,iBAAiB,GACjB,IAAI;QAEJ,oDAAoD;QACpD,QAAQ,SAAS,MAAM,QAAQ,CAAC;QAChC,gBAAgB;QAChB,SAAS;QACT,IAAI,OAAO;YACT,+DAA+D;YAC/D,IAAI,MAAM,UAAU,CAAC,OAAO,OAAO;gBACjC;YACF;YACA,QAAQ;QACV;QACA,MAAO,gBAAgB,MAAM,MAAM,CAAE;YACnC,OAAO,SAAS,GAAG;YACnB,QAAQ,OAAO,IAAI,CAAC;YACpB,cACE,SAAS,MAAM,KAAK,KAAK,YAAY,MAAM,KAAK,GAAG,MAAM,MAAM;YACjE,OAAO,MAAM,UAAU,CAAC;YACxB,IAAI,CAAC,OAAO;gBACV,SAAS,MAAM,KAAK,CAAC;gBACrB;YACF;YACA,IAAI,SAAS,MAAM,kBAAkB,eAAe,kBAAkB;gBACpE,OAAO,IAAI,CAAC,CAAC;gBACb,mBAAmB;YACrB,OAAO;gBACL,IAAI,kBAAkB;oBACpB,OAAO,IAAI,CAAC,CAAC;oBACb,mBAAmB;gBACrB;gBACA,IAAI,gBAAgB,aAAa;oBAC/B,OAAO,IAAI,CAAC,MAAM,KAAK,CAAC,eAAe;oBACvC,UAAU,cAAc;gBAC1B;gBACA,OAAQ;oBACN,KAAK;wBAAG;4BACN,OAAO,IAAI,CAAC;4BACZ;4BACA;wBACF;oBACA,KAAK;wBAAG;4BACN,OAAO,KAAK,IAAI,CAAC,SAAS,KAAK;4BAC/B,OAAO,IAAI,CAAC,CAAC;4BACb,MAAO,WAAW,KAAM,OAAO,IAAI,CAAC,CAAC;4BACrC;wBACF;oBACA,KAAK;wBAAI;4BACP,OAAO,IAAI,CAAC,CAAC;4BACb,SAAS;4BACT;wBACF;oBACA;wBAAS;4BACP,mBAAmB;4BACnB,SAAS;wBACX;gBACF;YACF;YACA,gBAAgB,cAAc;QAChC;QACA,IAAI,KAAK;YACP,IAAI,kBAAkB,OAAO,IAAI,CAAC,CAAC;YACnC,IAAI,QAAQ,OAAO,IAAI,CAAC;YACxB,OAAO,IAAI,CAAC;QACd;QACA,OAAO;IACT;AACF"}},
    {"offset": {"line": 140, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 145, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/preprocess.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Value} Value\n */\n\n/**\n * @callback Preprocessor\n * @param {Value} value\n * @param {Encoding | null | undefined} [encoding]\n * @param {boolean | null | undefined} [end=false]\n * @returns {Array<Chunk>}\n */\n\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {constants} from 'micromark-util-symbol/constants.js'\n\nconst search = /[\\0\\t\\n\\r]/g\n\n/**\n * @returns {Preprocessor}\n */\nexport function preprocess() {\n  let column = 1\n  let buffer = ''\n  /** @type {boolean | undefined} */\n  let start = true\n  /** @type {boolean | undefined} */\n  let atCarriageReturn\n\n  return preprocessor\n\n  /** @type {Preprocessor} */\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = []\n    /** @type {RegExpMatchArray | null} */\n    let match\n    /** @type {number} */\n    let next\n    /** @type {number} */\n    let startPosition\n    /** @type {number} */\n    let endPosition\n    /** @type {Code} */\n    let code\n\n    // @ts-expect-error `Buffer` does allow an encoding.\n    value = buffer + value.toString(encoding)\n    startPosition = 0\n    buffer = ''\n\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === codes.byteOrderMarker) {\n        startPosition++\n      }\n\n      start = undefined\n    }\n\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition =\n        match && match.index !== undefined ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n\n      if (\n        code === codes.lf &&\n        startPosition === endPosition &&\n        atCarriageReturn\n      ) {\n        chunks.push(codes.carriageReturnLineFeed)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(codes.carriageReturn)\n          atCarriageReturn = undefined\n        }\n\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n\n        switch (code) {\n          case codes.nul: {\n            chunks.push(codes.replacementCharacter)\n            column++\n\n            break\n          }\n\n          case codes.ht: {\n            next = Math.ceil(column / constants.tabSize) * constants.tabSize\n            chunks.push(codes.horizontalTab)\n            while (column++ < next) chunks.push(codes.virtualSpace)\n\n            break\n          }\n\n          case codes.lf: {\n            chunks.push(codes.lineFeed)\n            column = 1\n\n            break\n          }\n\n          default: {\n            atCarriageReturn = true\n            column = 1\n          }\n        }\n      }\n\n      startPosition = endPosition + 1\n    }\n\n    if (end) {\n      if (atCarriageReturn) chunks.push(codes.carriageReturn)\n      if (buffer) chunks.push(buffer)\n      chunks.push(codes.eof)\n    }\n\n    return chunks\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;CAKC,GAED;;;;;;CAMC;;;;;;;;AAKD,MAAM,SAAS;AAKR,SAAS;IACd,IAAI,SAAS;IACb,IAAI,SAAS;IACb,gCAAgC,GAChC,IAAI,QAAQ;IACZ,gCAAgC,GAChC,IAAI;IAEJ,OAAO;IAEP,yBAAyB,GACzB,SAAS,aAAa,KAAK,EAAE,QAAQ,EAAE,GAAG;QACxC,yBAAyB,GACzB,MAAM,SAAS,EAAE;QACjB,oCAAoC,GACpC,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,iBAAiB,GACjB,IAAI;QAEJ,oDAAoD;QACpD,QAAQ,SAAS,MAAM,QAAQ,CAAC;QAChC,gBAAgB;QAChB,SAAS;QAET,IAAI,OAAO;YACT,+DAA+D;YAC/D,IAAI,MAAM,UAAU,CAAC,OAAO,+NAAM,eAAe,EAAE;gBACjD;YACF;YAEA,QAAQ;QACV;QAEA,MAAO,gBAAgB,MAAM,MAAM,CAAE;YACnC,OAAO,SAAS,GAAG;YACnB,QAAQ,OAAO,IAAI,CAAC;YACpB,cACE,SAAS,MAAM,KAAK,KAAK,YAAY,MAAM,KAAK,GAAG,MAAM,MAAM;YACjE,OAAO,MAAM,UAAU,CAAC;YAExB,IAAI,CAAC,OAAO;gBACV,SAAS,MAAM,KAAK,CAAC;gBACrB;YACF;YAEA,IACE,SAAS,+NAAM,EAAE,IACjB,kBAAkB,eAClB,kBACA;gBACA,OAAO,IAAI,CAAC,+NAAM,sBAAsB;gBACxC,mBAAmB;YACrB,OAAO;gBACL,IAAI,kBAAkB;oBACpB,OAAO,IAAI,CAAC,+NAAM,cAAc;oBAChC,mBAAmB;gBACrB;gBAEA,IAAI,gBAAgB,aAAa;oBAC/B,OAAO,IAAI,CAAC,MAAM,KAAK,CAAC,eAAe;oBACvC,UAAU,cAAc;gBAC1B;gBAEA,OAAQ;oBACN,KAAK,+NAAM,GAAG;wBAAE;4BACd,OAAO,IAAI,CAAC,+NAAM,oBAAoB;4BACtC;4BAEA;wBACF;oBAEA,KAAK,+NAAM,EAAE;wBAAE;4BACb,OAAO,KAAK,IAAI,CAAC,SAAS,uOAAU,OAAO,IAAI,uOAAU,OAAO;4BAChE,OAAO,IAAI,CAAC,+NAAM,aAAa;4BAC/B,MAAO,WAAW,KAAM,OAAO,IAAI,CAAC,+NAAM,YAAY;4BAEtD;wBACF;oBAEA,KAAK,+NAAM,EAAE;wBAAE;4BACb,OAAO,IAAI,CAAC,+NAAM,QAAQ;4BAC1B,SAAS;4BAET;wBACF;oBAEA;wBAAS;4BACP,mBAAmB;4BACnB,SAAS;wBACX;gBACF;YACF;YAEA,gBAAgB,cAAc;QAChC;QAEA,IAAI,KAAK;YACP,IAAI,kBAAkB,OAAO,IAAI,CAAC,+NAAM,cAAc;YACtD,IAAI,QAAQ,OAAO,IAAI,CAAC;YACxB,OAAO,IAAI,CAAC,+NAAM,GAAG;QACvB;QAEA,OAAO;IACT;AACF"}},
    {"offset": {"line": 247, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 252, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/initialize/text.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n\n/**\n * @param {'string' | 'text'} field\n * @returns {InitialConstruct}\n */\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n    return start\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code)\n        return\n      }\n      effects.enter('data')\n      effects.consume(code)\n      return data\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data')\n        return text(code)\n      }\n\n      // Data.\n      effects.consume(code)\n      return data\n    }\n\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true\n      }\n      const list = constructs[code]\n      let index = -1\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index]\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n      return false\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n * @returns {Resolver}\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number | undefined} */\n    let enter\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n        enter = undefined\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0 // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === 'lineEnding') &&\n      events[eventIndex - 1][1].type === 'data'\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean | undefined} */\n      let tabs\n      while (index--) {\n        const chunk = chunks[index]\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++\n            bufferIndex--\n          }\n          if (bufferIndex) break\n          bufferIndex = -1\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true\n          size++\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length || tabs || size < 2\n              ? 'lineSuffix'\n              : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        }\n        data.end = Object.assign({}, token.start)\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n      eventIndex++\n    }\n  }\n  return events\n}\n"],"names":[],"mappings":"AAAA;;;;;;;CAOC;;;;;AAEM,MAAM,WAAW;IACtB,YAAY;AACd;AACO,MAAM,SAAS,kBAAkB;AACjC,MAAM,OAAO,kBAAkB;AAEtC;;;CAGC,GACD,SAAS,kBAAkB,KAAK;IAC9B,OAAO;QACL,UAAU;QACV,YAAY,eACV,UAAU,SAAS,yBAAyB;IAEhD;IAEA;;;GAGC,GACD,SAAS,eAAe,OAAO;QAC7B,MAAM,OAAO,IAAI;QACjB,MAAM,aAAa,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,MAAM;QAChD,MAAM,OAAO,QAAQ,OAAO,CAAC,YAAY,OAAO;QAChD,OAAO;QAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;YACjB,OAAO,QAAQ,QAAQ,KAAK,QAAQ,QAAQ;QAC9C;QAEA,kBAAkB,GAClB,SAAS,QAAQ,IAAI;YACnB,IAAI,SAAS,MAAM;gBACjB,QAAQ,OAAO,CAAC;gBAChB;YACF;YACA,QAAQ,KAAK,CAAC;YACd,QAAQ,OAAO,CAAC;YAChB,OAAO;QACT;QAEA,kBAAkB,GAClB,SAAS,KAAK,IAAI;YAChB,IAAI,QAAQ,OAAO;gBACjB,QAAQ,IAAI,CAAC;gBACb,OAAO,KAAK;YACd;YAEA,QAAQ;YACR,QAAQ,OAAO,CAAC;YAChB,OAAO;QACT;QAEA;;;KAGC,GACD,SAAS,QAAQ,IAAI;YACnB,IAAI,SAAS,MAAM;gBACjB,OAAO;YACT;YACA,MAAM,OAAO,UAAU,CAAC,KAAK;YAC7B,IAAI,QAAQ,CAAC;YACb,IAAI,MAAM;gBACR,gCAAgC;gBAEhC,MAAO,EAAE,QAAQ,KAAK,MAAM,CAAE;oBAC5B,MAAM,OAAO,IAAI,CAAC,MAAM;oBACxB,IAAI,CAAC,KAAK,QAAQ,IAAI,KAAK,QAAQ,CAAC,IAAI,CAAC,MAAM,KAAK,QAAQ,GAAG;wBAC7D,OAAO;oBACT;gBACF;YACF;YACA,OAAO;QACT;IACF;AACF;AAEA;;;CAGC,GACD,SAAS,eAAe,aAAa;IACnC,OAAO;IAEP,qBAAqB,GACrB,SAAS,eAAe,MAAM,EAAE,OAAO;QACrC,IAAI,QAAQ,CAAC;QACb,+BAA+B,GAC/B,IAAI;QAEJ,sEAAsE;QACtE,kCAAkC;QAClC,MAAO,EAAE,SAAS,OAAO,MAAM,CAAE;YAC/B,IAAI,UAAU,WAAW;gBACvB,IAAI,MAAM,CAAC,MAAM,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,QAAQ;oBACrD,QAAQ;oBACR;gBACF;YACF,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,QAAQ;gBAC7D,gDAAgD;gBAChD,IAAI,UAAU,QAAQ,GAAG;oBACvB,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,GAAG;oBAC/C,OAAO,MAAM,CAAC,QAAQ,GAAG,QAAQ,QAAQ;oBACzC,QAAQ,QAAQ;gBAClB;gBACA,QAAQ;YACV;QACF;QACA,OAAO,gBAAgB,cAAc,QAAQ,WAAW;IAC1D;AACF;AAEA;;;;;;;;;;CAUC,GACD,SAAS,uBAAuB,MAAM,EAAE,OAAO;IAC7C,IAAI,aAAa,EAAE,cAAc;;IAEjC,MAAO,EAAE,cAAc,OAAO,MAAM,CAAE;QACpC,IACE,CAAC,eAAe,OAAO,MAAM,IAC3B,MAAM,CAAC,WAAW,CAAC,EAAE,CAAC,IAAI,KAAK,YAAY,KAC7C,MAAM,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,IAAI,KAAK,QACnC;YACA,MAAM,OAAO,MAAM,CAAC,aAAa,EAAE,CAAC,EAAE;YACtC,MAAM,SAAS,QAAQ,WAAW,CAAC;YACnC,IAAI,QAAQ,OAAO,MAAM;YACzB,IAAI,cAAc,CAAC;YACnB,IAAI,OAAO;YACX,gCAAgC,GAChC,IAAI;YACJ,MAAO,QAAS;gBACd,MAAM,QAAQ,MAAM,CAAC,MAAM;gBAC3B,IAAI,OAAO,UAAU,UAAU;oBAC7B,cAAc,MAAM,MAAM;oBAC1B,MAAO,MAAM,UAAU,CAAC,cAAc,OAAO,GAAI;wBAC/C;wBACA;oBACF;oBACA,IAAI,aAAa;oBACjB,cAAc,CAAC;gBACjB,OAEK,IAAI,UAAU,CAAC,GAAG;oBACrB,OAAO;oBACP;gBACF,OAAO,IAAI,UAAU,CAAC,GAAG;gBACvB,QAAQ;gBACV,OAAO;oBACL,+BAA+B;oBAC/B;oBACA;gBACF;YACF;YACA,IAAI,MAAM;gBACR,MAAM,QAAQ;oBACZ,MACE,eAAe,OAAO,MAAM,IAAI,QAAQ,OAAO,IAC3C,eACA;oBACN,OAAO;wBACL,MAAM,KAAK,GAAG,CAAC,IAAI;wBACnB,QAAQ,KAAK,GAAG,CAAC,MAAM,GAAG;wBAC1B,QAAQ,KAAK,GAAG,CAAC,MAAM,GAAG;wBAC1B,QAAQ,KAAK,KAAK,CAAC,MAAM,GAAG;wBAC5B,cAAc,QACV,cACA,KAAK,KAAK,CAAC,YAAY,GAAG;oBAChC;oBACA,KAAK,OAAO,MAAM,CAAC,CAAC,GAAG,KAAK,GAAG;gBACjC;gBACA,KAAK,GAAG,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG,MAAM,KAAK;gBACxC,IAAI,KAAK,KAAK,CAAC,MAAM,KAAK,KAAK,GAAG,CAAC,MAAM,EAAE;oBACzC,OAAO,MAAM,CAAC,MAAM;gBACtB,OAAO;oBACL,OAAO,MAAM,CACX,YACA,GACA;wBAAC;wBAAS;wBAAO;qBAAQ,EACzB;wBAAC;wBAAQ;wBAAO;qBAAQ;oBAE1B,cAAc;gBAChB;YACF;YACA;QACF;IACF;IACA,OAAO;AACT"}},
    {"offset": {"line": 432, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 437, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/constructs.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Extension} Extension\n */\n\nimport {\n  attention,\n  autolink,\n  blockQuote,\n  characterEscape,\n  characterReference,\n  codeFenced,\n  codeIndented,\n  codeText,\n  definition,\n  hardBreakEscape,\n  headingAtx,\n  htmlFlow,\n  htmlText,\n  labelEnd,\n  labelStartImage,\n  labelStartLink,\n  lineEnding,\n  list,\n  setextUnderline,\n  thematicBreak\n} from 'micromark-core-commonmark'\nimport {resolver as resolveText} from './initialize/text.js'\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n}\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n}\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n}\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n}\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n}\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n}\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n}\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n}\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;;;;;;;;;;;AA2BM,MAAM,WAAW;IACtB,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;AACN;AAGO,MAAM,iBAAiB;IAC5B,CAAC,GAAG;AACN;AAGO,MAAM,cAAc;IACzB,CAAC,CAAC,EAAE;IACJ,CAAC,CAAC,EAAE;IACJ,CAAC,GAAG;AACN;AAGO,MAAM,OAAO;IAClB,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG,EAAE;;;KAAgC;IACtC,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,IAAI;AACP;AAGO,MAAM,SAAS;IACpB,CAAC,GAAG;IACJ,CAAC,GAAG;AACN;AAGO,MAAM,OAAO;IAClB,CAAC,CAAC,EAAE;IACJ,CAAC,CAAC,EAAE;IACJ,CAAC,CAAC,EAAE;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG,EAAE;;;KAAoB;IAC1B,CAAC,GAAG;IACJ,CAAC,GAAG,EAAE;;;KAAkC;IACxC,CAAC,GAAG;IACJ,CAAC,GAAG;IACJ,CAAC,GAAG;AACN;AAGO,MAAM,aAAa;IACxB,MAAM;;;KAAwB;AAChC;AAGO,MAAM,mBAAmB;IAC9B,MAAM;QAAC;QAAI;KAAG;AAChB;AAGO,MAAM,UAAU;IACrB,MAAM,EAAE;AACV"}},
    {"offset": {"line": 531, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 536, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/create-tokenizer.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenType} TokenType\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * @callback Restore\n * @returns {void}\n *\n * @typedef Info\n * @property {Restore} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {void}\n */\n\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(\n    from\n      ? Object.assign({}, from)\n      : {\n          line: 1,\n          column: 1,\n          offset: 0\n        },\n    {\n      _index: 0,\n      _bufferIndex: -1\n    }\n  )\n  /** @type {Record<string, number>} */\n  const columnStart = {}\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = []\n  /** @type {Array<Chunk>} */\n  let chunks = []\n  /** @type {Array<Token>} */\n  let stack = []\n  /** @type {boolean | undefined} */\n  let consumed = true\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  }\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  }\n\n  /**\n   * The state function.\n   *\n   * @type {State | void}\n   */\n  let state = initialize.tokenize.call(context, effects)\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n  return context\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice)\n    main()\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n    addResult(initialize, 0)\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {line, column, offset, _index, _bufferIndex} = point\n    return {\n      line,\n      column,\n      offset,\n      _index,\n      _bufferIndex\n    }\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {void}\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index]\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {void}\n   */\n  function go(code) {\n    consumed = undefined\n    expectedCode = code\n    state = state(code)\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++\n\n      // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code\n\n    // Mark as consumed.\n    consumed = true\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   */\n  function constructFactory(onreturn, fields) {\n    return hook\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | Construct | ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State | undefined} [bogusState]\n     * @returns {State}\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      let listOfConstructs\n      /** @type {number} */\n      let constructIndex\n      /** @type {Construct} */\n      let currentConstruct\n      /** @type {Info} */\n      let info\n      return Array.isArray(constructs) /* c8 ignore next 1 */\n        ? handleListOfConstructs(constructs)\n        : 'tokenize' in constructs\n        ? // @ts-expect-error Looks like a construct.\n          handleListOfConstructs([constructs])\n        : handleMapOfConstructs(constructs)\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n      function handleMapOfConstructs(map) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          const def = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n            /* c8 ignore next 2 */\n            ...(Array.isArray(def) ? def : def ? [def] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n          return handleListOfConstructs(list)(code)\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n        if (list.length === 0) {\n          return bogusState\n        }\n        return handleConstruct(list[constructIndex])\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n      function handleConstruct(construct) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          // Always populated by defaults.\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a “live binding”, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true\n        info.restore()\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n        return bogusState\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {void}\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n    return {\n      restore,\n      from: startEventsIndex\n    }\n\n    /**\n     * Restore state.\n     *\n     * @returns {void}\n     */\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {void}\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'end' | 'start'>} token\n * @returns {Array<Chunk>}\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Array<Chunk>} */\n  let view\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n    if (startBufferIndex > -1) {\n      const head = view[0]\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex)\n      } else {\n        view.shift()\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n  return view\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean | undefined} [expandTabs=false]\n * @returns {string}\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {Array<string>} */\n  const result = []\n  /** @type {boolean | undefined} */\n  let atTab\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n    let value\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case -5: {\n          value = '\\r'\n          break\n        }\n        case -4: {\n          value = '\\n'\n          break\n        }\n        case -3: {\n          value = '\\r' + '\\n'\n          break\n        }\n        case -2: {\n          value = expandTabs ? ' ' : '\\t'\n          break\n        }\n        case -1: {\n          if (!expandTabs && atTab) continue\n          value = ' '\n          break\n        }\n        default: {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n    atTab = chunk === -2\n    result.push(value)\n  }\n  return result.join('')\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;CAaC,GAED;;;;;;;;;;;;;CAaC;;;;;;;;;;AAmBM,SAAS,gBAAgB,MAAM,EAAE,UAAU,EAAE,IAAI;IACtD,kBAAkB,GAClB,IAAI,QAAQ,OAAO,MAAM,CACvB,OACI,OAAO,MAAM,CAAC,CAAC,GAAG,QAClB;QACE,MAAM;QACN,QAAQ;QACR,QAAQ;IACV,GACJ;QACE,QAAQ;QACR,cAAc,CAAC;IACjB;IAEF,mCAAmC,GACnC,MAAM,cAAc,CAAC;IACrB,6BAA6B,GAC7B,MAAM,uBAAuB,EAAE;IAC/B,yBAAyB,GACzB,IAAI,SAAS,EAAE;IACf,yBAAyB,GACzB,IAAI,QAAQ,EAAE;IACd,gCAAgC,GAChC,IAAI,WAAW;IAEf;;;;GAIC,GACD,MAAM,UAAU;QACd;QACA;QACA;QACA,SAAS,iBAAiB;QAC1B,OAAO,iBAAiB;QACxB,WAAW,iBAAiB,mBAAmB;YAC7C,WAAW;QACb;IACF;IAEA;;;;GAIC,GACD,MAAM,UAAU;QACd,UAAU;QACV,MAAM;QACN,gBAAgB,CAAC;QACjB,QAAQ,EAAE;QACV;QACA;QACA;QACA;QACA;QACA;IACF;IAEA;;;;GAIC,GACD,IAAI,QAAQ,WAAW,QAAQ,CAAC,IAAI,CAAC,SAAS;IAE9C;;;;GAIC,GACD,IAAI;IACJ,IAAI,WAAW,UAAU,EAAE;QACzB,qBAAqB,IAAI,CAAC;IAC5B;IACA,OAAO;IAEP,qCAAqC,GACrC,SAAS,MAAM,KAAK;QAClB,SAAS,uOAAK,QAAQ;QACtB;QAEA,sDAAsD;QACtD,IAAI,MAAM,CAAC,OAAO,MAAM,GAAG,EAAE,KAAK,MAAM;YACtC,OAAO,EAAE;QACX;QACA,UAAU,YAAY;QAEtB,gCAAgC;QAChC,QAAQ,MAAM,GAAG,oPAAW,sBAAsB,QAAQ,MAAM,EAAE;QAClE,OAAO,QAAQ,MAAM;IACvB;IAEA,EAAE;IACF,SAAS;IACT,EAAE;IAEF,8CAA8C,GAC9C,SAAS,eAAe,KAAK,EAAE,UAAU;QACvC,OAAO,gBAAgB,YAAY,QAAQ;IAC7C;IAEA,2CAA2C,GAC3C,SAAS,YAAY,KAAK;QACxB,OAAO,YAAY,QAAQ;IAC7B;IAEA,mCAAmC,GACnC,SAAS;QACP,iFAAiF;QACjF,MAAM,EAAC,IAAI,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,YAAY,EAAC,GAAG;QACrD,OAAO;YACL;YACA;YACA;YACA;YACA;QACF;IACF;IAEA,0CAA0C,GAC1C,SAAS,WAAW,KAAK;QACvB,WAAW,CAAC,MAAM,IAAI,CAAC,GAAG,MAAM,MAAM;QACtC;IACF;IAEA,EAAE;IACF,oBAAoB;IACpB,EAAE;IAEF;;;;;;;;;GASC,GACD,SAAS;QACP,mBAAmB,GACnB,IAAI;QACJ,MAAO,MAAM,MAAM,GAAG,OAAO,MAAM,CAAE;YACnC,MAAM,QAAQ,MAAM,CAAC,MAAM,MAAM,CAAC;YAElC,+CAA+C;YAC/C,IAAI,OAAO,UAAU,UAAU;gBAC7B,aAAa,MAAM,MAAM;gBACzB,IAAI,MAAM,YAAY,GAAG,GAAG;oBAC1B,MAAM,YAAY,GAAG;gBACvB;gBACA,MACE,MAAM,MAAM,KAAK,cACjB,MAAM,YAAY,GAAG,MAAM,MAAM,CACjC;oBACA,GAAG,MAAM,UAAU,CAAC,MAAM,YAAY;gBACxC;YACF,OAAO;gBACL,GAAG;YACL;QACF;IACF;IAEA;;;;;GAKC,GACD,SAAS,GAAG,IAAI;QACd,WAAW;QACX,eAAe;QACf,QAAQ,MAAM;IAChB;IAEA,+BAA+B,GAC/B,SAAS,QAAQ,IAAI;QACnB,IAAI,yPAAmB,OAAO;YAC5B,MAAM,IAAI;YACV,MAAM,MAAM,GAAG;YACf,MAAM,MAAM,IAAI,SAAS,CAAC,IAAI,IAAI;YAClC;QACF,OAAO,IAAI,SAAS,CAAC,GAAG;YACtB,MAAM,MAAM;YACZ,MAAM,MAAM;QACd;QAEA,yBAAyB;QACzB,IAAI,MAAM,YAAY,GAAG,GAAG;YAC1B,MAAM,MAAM;QACd,OAAO;YACL,MAAM,YAAY;YAElB,0BAA0B;YAC1B,mEAAmE;YACnE,WAAW;YACX,IAAI,MAAM,YAAY,KAAK,MAAM,CAAC,MAAM,MAAM,CAAC,CAAC,MAAM,EAAE;gBACtD,MAAM,YAAY,GAAG,CAAC;gBACtB,MAAM,MAAM;YACd;QACF;QAEA,iCAAiC;QACjC,QAAQ,QAAQ,GAAG;QAEnB,oBAAoB;QACpB,WAAW;IACb;IAEA,6BAA6B,GAC7B,SAAS,MAAM,IAAI,EAAE,MAAM;QACzB,kBAAkB,GAClB,uEAAuE;QACvE,MAAM,QAAQ,UAAU,CAAC;QACzB,MAAM,IAAI,GAAG;QACb,MAAM,KAAK,GAAG;QACd,QAAQ,MAAM,CAAC,IAAI,CAAC;YAAC;YAAS;YAAO;SAAQ;QAC7C,MAAM,IAAI,CAAC;QACX,OAAO;IACT;IAEA,4BAA4B,GAC5B,SAAS,KAAK,IAAI;QAChB,MAAM,QAAQ,MAAM,GAAG;QACvB,MAAM,GAAG,GAAG;QACZ,QAAQ,MAAM,CAAC,IAAI,CAAC;YAAC;YAAQ;YAAO;SAAQ;QAC5C,OAAO;IACT;IAEA;;;;GAIC,GACD,SAAS,sBAAsB,SAAS,EAAE,IAAI;QAC5C,UAAU,WAAW,KAAK,IAAI;IAChC;IAEA;;;;GAIC,GACD,SAAS,kBAAkB,CAAC,EAAE,IAAI;QAChC,KAAK,OAAO;IACd;IAEA;;;;;GAKC,GACD,SAAS,iBAAiB,QAAQ,EAAE,MAAM;QACxC,OAAO;QAEP;;;;;;;;KAQC,GACD,SAAS,KAAK,UAAU,EAAE,WAAW,EAAE,UAAU;YAC/C,6BAA6B,GAC7B,IAAI;YACJ,mBAAmB,GACnB,IAAI;YACJ,sBAAsB,GACtB,IAAI;YACJ,iBAAiB,GACjB,IAAI;YACJ,OAAO,MAAM,OAAO,CAAC,cACjB,uBAAuB,cACvB,cAAc,aAEd,uBAAuB;gBAAC;aAAW,IACnC,sBAAsB;YAE1B;;;;;OAKC,GACD,SAAS,sBAAsB,GAAG;gBAChC,OAAO;gBAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;oBACjB,MAAM,MAAM,SAAS,QAAQ,GAAG,CAAC,KAAK;oBACtC,MAAM,MAAM,SAAS,QAAQ,IAAI,IAAI;oBACrC,MAAM,OAAO;wBACX,mCAAmC;wBACnC,oBAAoB,MAChB,MAAM,OAAO,CAAC,OAAO,MAAM,MAAM;4BAAC;yBAAI,GAAG,EAAE;2BAC3C,MAAM,OAAO,CAAC,OAAO,MAAM,MAAM;4BAAC;yBAAI,GAAG,EAAE;qBAChD;oBACD,OAAO,uBAAuB,MAAM;gBACtC;YACF;YAEA;;;;;OAKC,GACD,SAAS,uBAAuB,IAAI;gBAClC,mBAAmB;gBACnB,iBAAiB;gBACjB,IAAI,KAAK,MAAM,KAAK,GAAG;oBACrB,OAAO;gBACT;gBACA,OAAO,gBAAgB,IAAI,CAAC,eAAe;YAC7C;YAEA;;;;;OAKC,GACD,SAAS,gBAAgB,SAAS;gBAChC,OAAO;gBAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;oBACjB,mEAAmE;oBACnE,oEAAoE;oBACpE,uEAAuE;oBACvE,kBAAkB;oBAClB,OAAO;oBACP,mBAAmB;oBACnB,IAAI,CAAC,UAAU,OAAO,EAAE;wBACtB,QAAQ,gBAAgB,GAAG;oBAC7B;oBAEA,gCAAgC;oBAEhC,IACE,UAAU,IAAI,IACd,QAAQ,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,IAAI,GAC9D;wBACA,OAAO,IAAI;oBACb;oBACA,OAAO,UAAU,QAAQ,CAAC,IAAI,CAC5B,6DAA6D;oBAC7D,aAAa;oBACb,iEAAiE;oBACjE,SAAS,OAAO,MAAM,CAAC,OAAO,MAAM,CAAC,UAAU,UAAU,SACzD,SACA,IACA,KACA;gBACJ;YACF;YAEA,kBAAkB,GAClB,SAAS,GAAG,IAAI;gBACd,WAAW;gBACX,SAAS,kBAAkB;gBAC3B,OAAO;YACT;YAEA,kBAAkB,GAClB,SAAS,IAAI,IAAI;gBACf,WAAW;gBACX,KAAK,OAAO;gBACZ,IAAI,EAAE,iBAAiB,iBAAiB,MAAM,EAAE;oBAC9C,OAAO,gBAAgB,gBAAgB,CAAC,eAAe;gBACzD;gBACA,OAAO;YACT;QACF;IACF;IAEA;;;;GAIC,GACD,SAAS,UAAU,SAAS,EAAE,IAAI;QAChC,IAAI,UAAU,UAAU,IAAI,CAAC,qBAAqB,QAAQ,CAAC,YAAY;YACrE,qBAAqB,IAAI,CAAC;QAC5B;QACA,IAAI,UAAU,OAAO,EAAE;YACrB,yOACE,QAAQ,MAAM,EACd,MACA,QAAQ,MAAM,CAAC,MAAM,GAAG,MACxB,UAAU,OAAO,CAAC,QAAQ,MAAM,CAAC,KAAK,CAAC,OAAO;QAElD;QACA,IAAI,UAAU,SAAS,EAAE;YACvB,QAAQ,MAAM,GAAG,UAAU,SAAS,CAAC,QAAQ,MAAM,EAAE;QACvD;IACF;IAEA;;;;GAIC,GACD,SAAS;QACP,MAAM,aAAa;QACnB,MAAM,gBAAgB,QAAQ,QAAQ;QACtC,MAAM,wBAAwB,QAAQ,gBAAgB;QACtD,MAAM,mBAAmB,QAAQ,MAAM,CAAC,MAAM;QAC9C,MAAM,aAAa,MAAM,IAAI,CAAC;QAC9B,OAAO;YACL;YACA,MAAM;QACR;QAEA;;;;KAIC,GACD,SAAS;YACP,QAAQ;YACR,QAAQ,QAAQ,GAAG;YACnB,QAAQ,gBAAgB,GAAG;YAC3B,QAAQ,MAAM,CAAC,MAAM,GAAG;YACxB,QAAQ;YACR;QACF;IACF;IAEA;;;;;GAKC,GACD,SAAS;QACP,IAAI,MAAM,IAAI,IAAI,eAAe,MAAM,MAAM,GAAG,GAAG;YACjD,MAAM,MAAM,GAAG,WAAW,CAAC,MAAM,IAAI,CAAC;YACtC,MAAM,MAAM,IAAI,WAAW,CAAC,MAAM,IAAI,CAAC,GAAG;QAC5C;IACF;AACF;AAEA;;;;;;CAMC,GACD,SAAS,YAAY,MAAM,EAAE,KAAK;IAChC,MAAM,aAAa,MAAM,KAAK,CAAC,MAAM;IACrC,MAAM,mBAAmB,MAAM,KAAK,CAAC,YAAY;IACjD,MAAM,WAAW,MAAM,GAAG,CAAC,MAAM;IACjC,MAAM,iBAAiB,MAAM,GAAG,CAAC,YAAY;IAC7C,yBAAyB,GACzB,IAAI;IACJ,IAAI,eAAe,UAAU;QAC3B,4DAA4D;QAC5D,OAAO;YAAC,MAAM,CAAC,WAAW,CAAC,KAAK,CAAC,kBAAkB;SAAgB;IACrE,OAAO;QACL,OAAO,OAAO,KAAK,CAAC,YAAY;QAChC,IAAI,mBAAmB,CAAC,GAAG;YACzB,MAAM,OAAO,IAAI,CAAC,EAAE;YACpB,IAAI,OAAO,SAAS,UAAU;gBAC5B,IAAI,CAAC,EAAE,GAAG,KAAK,KAAK,CAAC;YACvB,OAAO;gBACL,KAAK,KAAK;YACZ;QACF;QACA,IAAI,iBAAiB,GAAG;YACtB,4DAA4D;YAC5D,KAAK,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,GAAG;QACtC;IACF;IACA,OAAO;AACT;AAEA;;;;;;CAMC,GACD,SAAS,gBAAgB,MAAM,EAAE,UAAU;IACzC,IAAI,QAAQ,CAAC;IACb,0BAA0B,GAC1B,MAAM,SAAS,EAAE;IACjB,gCAAgC,GAChC,IAAI;IACJ,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;QAC9B,MAAM,QAAQ,MAAM,CAAC,MAAM;QAC3B,mBAAmB,GACnB,IAAI;QACJ,IAAI,OAAO,UAAU,UAAU;YAC7B,QAAQ;QACV,OACE,OAAQ;YACN,KAAK,CAAC;gBAAG;oBACP,QAAQ;oBACR;gBACF;YACA,KAAK,CAAC;gBAAG;oBACP,QAAQ;oBACR;gBACF;YACA,KAAK,CAAC;gBAAG;oBACP,QAAQ,OAAO;oBACf;gBACF;YACA,KAAK,CAAC;gBAAG;oBACP,QAAQ,aAAa,MAAM;oBAC3B;gBACF;YACA,KAAK,CAAC;gBAAG;oBACP,IAAI,CAAC,cAAc,OAAO;oBAC1B,QAAQ;oBACR;gBACF;YACA;gBAAS;oBACP,wCAAwC;oBACxC,QAAQ,OAAO,YAAY,CAAC;gBAC9B;QACF;QACF,QAAQ,UAAU,CAAC;QACnB,OAAO,IAAI,CAAC;IACd;IACA,OAAO,OAAO,IAAI,CAAC;AACrB"}},
    {"offset": {"line": 1012, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1017, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/initialize/flow.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {blankLine, content} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeFlow(effects) {\n  const self = this\n  const initial = effects.attempt(\n    // Try to parse a blank line.\n    blankLine,\n    atBlankEnding,\n    // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        'linePrefix'\n      )\n    )\n  )\n  return initial\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    self.currentConstruct = undefined\n    return initial\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;CAKC;;;;;;;;;;AAMM,MAAM,OAAO;IAClB,UAAU;AACZ;AAEA;;;CAGC,GACD,SAAS,eAAe,OAAO;IAC7B,MAAM,OAAO,IAAI;IACjB,MAAM,UAAU,QAAQ,OAAO,oPAG7B,eACA,sDAAsD;IACtD,QAAQ,OAAO,CACb,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,WAAW,EAClC,gBACA,iPACE,SACA,QAAQ,OAAO,CACb,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,IAAI,EAC3B,gBACA,QAAQ,OAAO,kPAAU,kBAE3B;IAIN,OAAO;IAEP,kBAAkB,GAClB,SAAS,cAAc,IAAI;QACzB,IAAI,SAAS,MAAM;YACjB,QAAQ,OAAO,CAAC;YAChB;QACF;QACA,QAAQ,KAAK,CAAC;QACd,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC;QACb,KAAK,gBAAgB,GAAG;QACxB,OAAO;IACT;IAEA,kBAAkB,GAClB,SAAS,eAAe,IAAI;QAC1B,IAAI,SAAS,MAAM;YACjB,QAAQ,OAAO,CAAC;YAChB;QACF;QACA,QAAQ,KAAK,CAAC;QACd,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC;QACb,KAAK,gBAAgB,GAAG;QACxB,OAAO;IACT;AACF"}},
    {"offset": {"line": 1066, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1071, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/initialize/document.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n}\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {Array<StackItem>} */\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext | undefined} */\n  let childFlow\n  /** @type {Token | undefined} */\n  let childToken\n  /** @type {number} */\n  let lineStartOffset\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    }\n\n    // Done.\n    return checkNewContainers(code)\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n      if (childFlow) {\n        closeFlow()\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      let index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n      return checkNewContainers(code)\n    }\n    return start(code)\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(\n        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack\n      )\n    }\n\n    // Check if there is a new container.\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++\n    stack.push([self.currentConstruct, self.containerState])\n    // Try another.\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n    return flowContinue(code)\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit('chunkFlow'), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit('chunkFlow'))\n      // Get ready for the next line.\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n    effects.consume(code)\n    return flowContinue\n  }\n\n  /**\n   * @param {Token} token\n   * @param {boolean | undefined} [eof]\n   * @returns {void}\n   */\n  function writeToChild(token, eof) {\n    const stream = self.sliceStream(token)\n    if (eof) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream)\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n      while (index--) {\n        if (\n          // The token starts before the line ending…\n          childFlow.events[index][1].start.offset < lineStartOffset &&\n          // …and either is not ended yet…\n          (!childFlow.events[index][1].end ||\n            // …or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean | undefined} */\n      let seen\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n          seen = true\n        }\n      }\n      exitContainers(continued)\n\n      // Fix positions.\n      index = indexBeforeExits\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n    }\n  }\n\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n  function exitContainers(size) {\n    let index = stack.length\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      entry[0].exit.call(self, effects)\n    }\n    stack.length = size\n  }\n  function closeFlow() {\n    childFlow.write([null])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4\n  )\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;CAUC,GAED;;CAEC;;;;;;;;;;AAMM,MAAM,WAAW;IACtB,UAAU;AACZ;AAEA,sBAAsB,GACtB,MAAM,qBAAqB;IACzB,UAAU;AACZ;AAEA;;;CAGC,GACD,SAAS,mBAAmB,OAAO;IACjC,MAAM,OAAO,IAAI;IACjB,6BAA6B,GAC7B,MAAM,QAAQ,EAAE;IAChB,IAAI,YAAY;IAChB,wCAAwC,GACxC,IAAI;IACJ,8BAA8B,GAC9B,IAAI;IACJ,mBAAmB,GACnB,IAAI;IACJ,OAAO;IAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;QACjB,mEAAmE;QACnE,uEAAuE;QACvE,SAAS;QACT,4EAA4E;QAC5E,kBAAkB;QAClB,uDAAuD;QACvD,yCAAyC;QACzC,kEAAkE;QAClE,uEAAuE;QACvE,qBAAqB;QACrB,IAAI,YAAY,MAAM,MAAM,EAAE;YAC5B,MAAM,OAAO,KAAK,CAAC,UAAU;YAC7B,KAAK,cAAc,GAAG,IAAI,CAAC,EAAE;YAC7B,OAAO,QAAQ,OAAO,CACpB,IAAI,CAAC,EAAE,CAAC,YAAY,EACpB,kBACA,oBACA;QACJ;QAEA,QAAQ;QACR,OAAO,mBAAmB;IAC5B;IAEA,kBAAkB,GAClB,SAAS,iBAAiB,IAAI;QAC5B;QAEA,yEAAyE;QACzE,wEAAwE;QACxE,cAAc;QACd,IAAI,KAAK,cAAc,CAAC,UAAU,EAAE;YAClC,KAAK,cAAc,CAAC,UAAU,GAAG;YACjC,IAAI,WAAW;gBACb;YACF;YAEA,kEAAkE;YAClE,4DAA4D;YAC5D,MAAM,mBAAmB,KAAK,MAAM,CAAC,MAAM;YAC3C,IAAI,kBAAkB;YACtB,8BAA8B,GAC9B,IAAI;YAEJ,uBAAuB;YACvB,MAAO,kBAAmB;gBACxB,IACE,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,KAAK,UACpC,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,IAAI,KAAK,aACzC;oBACA,QAAQ,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,GAAG;oBAC3C;gBACF;YACF;YACA,eAAe;YAEf,iBAAiB;YACjB,IAAI,QAAQ;YACZ,MAAO,QAAQ,KAAK,MAAM,CAAC,MAAM,CAAE;gBACjC,KAAK,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG;gBAC9C;YACF;YAEA,4DAA4D;YAC5D,yOACE,KAAK,MAAM,EACX,kBAAkB,GAClB,GACA,KAAK,MAAM,CAAC,KAAK,CAAC;YAGpB,+BAA+B;YAC/B,KAAK,MAAM,CAAC,MAAM,GAAG;YACrB,OAAO,mBAAmB;QAC5B;QACA,OAAO,MAAM;IACf;IAEA,kBAAkB,GAClB,SAAS,mBAAmB,IAAI;QAC9B,yEAAyE;QACzE,0DAA0D;QAC1D,sEAAsE;QACtE,sEAAsE;QACtE,SAAS;QACT,IAAI,cAAc,MAAM,MAAM,EAAE;YAC9B,sEAAsE;YACtE,iBAAiB;YACjB,qDAAqD;YACrD,IAAI,CAAC,WAAW;gBACd,OAAO,kBAAkB;YAC3B;YAEA,kEAAkE;YAClE,qEAAqE;YACrE,SAAS;YACT,IAAI,UAAU,gBAAgB,IAAI,UAAU,gBAAgB,CAAC,QAAQ,EAAE;gBACrE,OAAO,UAAU;YACnB;YAEA,sDAAsD;YACtD,sEAAsE;YACtE,aAAa;YACb,uEAAuE;YACvE,kDAAkD;YAClD,KAAK,SAAS,GAAG,QACf,UAAU,gBAAgB,IAAI,CAAC,UAAU,6BAA6B;QAE1E;QAEA,qCAAqC;QACrC,KAAK,cAAc,GAAG,CAAC;QACvB,OAAO,QAAQ,KAAK,CAClB,oBACA,sBACA,uBACA;IACJ;IAEA,kBAAkB,GAClB,SAAS,qBAAqB,IAAI;QAChC,IAAI,WAAW;QACf,eAAe;QACf,OAAO,kBAAkB;IAC3B;IAEA,kBAAkB,GAClB,SAAS,sBAAsB,IAAI;QACjC,KAAK,MAAM,CAAC,IAAI,CAAC,KAAK,GAAG,GAAG,IAAI,CAAC,GAAG,cAAc,MAAM,MAAM;QAC9D,kBAAkB,KAAK,GAAG,GAAG,MAAM;QACnC,OAAO,UAAU;IACnB;IAEA,kBAAkB,GAClB,SAAS,kBAAkB,IAAI;QAC7B,sBAAsB;QACtB,KAAK,cAAc,GAAG,CAAC;QACvB,OAAO,QAAQ,OAAO,CACpB,oBACA,mBACA,WACA;IACJ;IAEA,kBAAkB,GAClB,SAAS,kBAAkB,IAAI;QAC7B;QACA,MAAM,IAAI,CAAC;YAAC,KAAK,gBAAgB;YAAE,KAAK,cAAc;SAAC;QACvD,eAAe;QACf,OAAO,kBAAkB;IAC3B;IAEA,kBAAkB,GAClB,SAAS,UAAU,IAAI;QACrB,IAAI,SAAS,MAAM;YACjB,IAAI,WAAW;YACf,eAAe;YACf,QAAQ,OAAO,CAAC;YAChB;QACF;QACA,YAAY,aAAa,KAAK,MAAM,CAAC,IAAI,CAAC,KAAK,GAAG;QAClD,QAAQ,KAAK,CAAC,aAAa;YACzB,aAAa;YACb,UAAU;YACV,YAAY;QACd;QACA,OAAO,aAAa;IACtB;IAEA,kBAAkB,GAClB,SAAS,aAAa,IAAI;QACxB,IAAI,SAAS,MAAM;YACjB,aAAa,QAAQ,IAAI,CAAC,cAAc;YACxC,eAAe;YACf,QAAQ,OAAO,CAAC;YAChB;QACF;QACA,IAAI,yPAAmB,OAAO;YAC5B,QAAQ,OAAO,CAAC;YAChB,aAAa,QAAQ,IAAI,CAAC;YAC1B,+BAA+B;YAC/B,YAAY;YACZ,KAAK,SAAS,GAAG;YACjB,OAAO;QACT;QACA,QAAQ,OAAO,CAAC;QAChB,OAAO;IACT;IAEA;;;;GAIC,GACD,SAAS,aAAa,KAAK,EAAE,GAAG;QAC9B,MAAM,SAAS,KAAK,WAAW,CAAC;QAChC,IAAI,KAAK,OAAO,IAAI,CAAC;QACrB,MAAM,QAAQ,GAAG;QACjB,IAAI,YAAY,WAAW,IAAI,GAAG;QAClC,aAAa;QACb,UAAU,UAAU,CAAC,MAAM,KAAK;QAChC,UAAU,KAAK,CAAC;QAEhB,yCAAyC;QACzC,EAAE;QACF,cAAc;QACd,MAAM;QACN,KAAK;QACL,EAAE;QACF,MAAM;QACN,EAAE;QACF,SAAS;QACT,IAAI;QACJ,EAAE;QACF,MAAM;QACN,EAAE;QACF,UAAU;QACV,IAAI;QACJ,MAAM;QACN,EAAE;QACF,yEAAyE;QACzE,uEAAuE;QACvE,yCAAyC;QACzC,yEAAyE;QACzE,wDAAwD;QACxD,EAAE;QACF,qEAAqE;QACrE,qBAAqB;QACrB,oEAAoE;QACpE,uBAAuB;QACvB,yEAAyE;QACzE,8CAA8C;QAC9C,EAAE;QACF,sEAAsE;QACtE,kDAAkD;QAClD,yEAAyE;QACzE,IAAI,KAAK,MAAM,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,IAAI,CAAC,EAAE;YACtC,IAAI,QAAQ,UAAU,MAAM,CAAC,MAAM;YACnC,MAAO,QAAS;gBACd,IACE,2CAA2C;gBAC3C,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,KAAK,CAAC,MAAM,GAAG,mBAC1C,gCAAgC;gBAChC,CAAC,CAAC,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,IAC9B,qBAAqB;gBACrB,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,CAAC,MAAM,GAAG,eAAe,GACzD;oBACA,mEAAmE;oBACnE,qBAAqB;oBACrB;gBACF;YACF;YAEA,kEAAkE;YAClE,qDAAqD;YACrD,MAAM,mBAAmB,KAAK,MAAM,CAAC,MAAM;YAC3C,IAAI,kBAAkB;YACtB,gCAAgC,GAChC,IAAI;YACJ,8BAA8B,GAC9B,IAAI;YAEJ,0DAA0D;YAC1D,MAAO,kBAAmB;gBACxB,IACE,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,KAAK,UACpC,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,IAAI,KAAK,aACzC;oBACA,IAAI,MAAM;wBACR,QAAQ,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,GAAG;wBAC3C;oBACF;oBACA,OAAO;gBACT;YACF;YACA,eAAe;YAEf,iBAAiB;YACjB,QAAQ;YACR,MAAO,QAAQ,KAAK,MAAM,CAAC,MAAM,CAAE;gBACjC,KAAK,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG;gBAC9C;YACF;YAEA,4DAA4D;YAC5D,yOACE,KAAK,MAAM,EACX,kBAAkB,GAClB,GACA,KAAK,MAAM,CAAC,KAAK,CAAC;YAGpB,+BAA+B;YAC/B,KAAK,MAAM,CAAC,MAAM,GAAG;QACvB;IACF;IAEA;;;GAGC,GACD,SAAS,eAAe,IAAI;QAC1B,IAAI,QAAQ,MAAM,MAAM;QAExB,wBAAwB;QACxB,MAAO,UAAU,KAAM;YACrB,MAAM,QAAQ,KAAK,CAAC,MAAM;YAC1B,KAAK,cAAc,GAAG,KAAK,CAAC,EAAE;YAC9B,KAAK,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM;QAC3B;QACA,MAAM,MAAM,GAAG;IACjB;IACA,SAAS;QACP,UAAU,KAAK,CAAC;YAAC;SAAK;QACtB,aAAa;QACb,YAAY;QACZ,KAAK,cAAc,CAAC,UAAU,GAAG;IACnC;AACF;AAEA;;;CAGC,GACD,SAAS,kBAAkB,OAAO,EAAE,EAAE,EAAE,GAAG;IACzC,gCAAgC;IAEhC,OAAO,iPACL,SACA,QAAQ,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,QAAQ,EAAE,IAAI,MACrD,cACA,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,kBAAkB,YAAY;AAE/E"}},
    {"offset": {"line": 1368, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1373, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/initialize/content.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n  let previous\n  return contentStart\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, contentStart, 'linePrefix')\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter('paragraph')\n    return lineStart(code)\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous\n    })\n    if (previous) {\n      previous.next = token\n    }\n    previous = token\n    return data(code)\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText')\n      effects.exit('paragraph')\n      effects.consume(code)\n      return\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit('chunkText')\n      return lineStart\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;CAMC;;;;;;;;AAKM,MAAM,UAAU;IACrB,UAAU;AACZ;AAEA;;;CAGC,GACD,SAAS,kBAAkB,OAAO;IAChC,MAAM,eAAe,QAAQ,OAAO,CAClC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,cAAc,EACrC,4BACA;IAEF,kBAAkB,GAClB,IAAI;IACJ,OAAO;IAEP,kBAAkB,GAClB,SAAS,2BAA2B,IAAI;QACtC,IAAI,SAAS,MAAM;YACjB,QAAQ,OAAO,CAAC;YAChB;QACF;QACA,QAAQ,KAAK,CAAC;QACd,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC;QACb,OAAO,iPAAa,SAAS,cAAc;IAC7C;IAEA,kBAAkB,GAClB,SAAS,iBAAiB,IAAI;QAC5B,QAAQ,KAAK,CAAC;QACd,OAAO,UAAU;IACnB;IAEA,kBAAkB,GAClB,SAAS,UAAU,IAAI;QACrB,MAAM,QAAQ,QAAQ,KAAK,CAAC,aAAa;YACvC,aAAa;YACb;QACF;QACA,IAAI,UAAU;YACZ,SAAS,IAAI,GAAG;QAClB;QACA,WAAW;QACX,OAAO,KAAK;IACd;IAEA,kBAAkB,GAClB,SAAS,KAAK,IAAI;QAChB,IAAI,SAAS,MAAM;YACjB,QAAQ,IAAI,CAAC;YACb,QAAQ,IAAI,CAAC;YACb,QAAQ,OAAO,CAAC;YAChB;QACF;QACA,IAAI,yPAAmB,OAAO;YAC5B,QAAQ,OAAO,CAAC;YAChB,QAAQ,IAAI,CAAC;YACb,OAAO;QACT;QAEA,QAAQ;QACR,QAAQ,OAAO,CAAC;QAChB,OAAO;IACT;AACF"}},
    {"offset": {"line": 1439, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1444, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/lib/parse.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Create} Create\n * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n */\n\nimport {combineExtensions} from 'micromark-util-combine-extensions'\nimport {content} from './initialize/content.js'\nimport {document} from './initialize/document.js'\nimport {flow} from './initialize/flow.js'\nimport {text, string} from './initialize/text.js'\nimport {createTokenizer} from './create-tokenizer.js'\nimport * as defaultConstructs from './constructs.js'\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n * @returns {ParseContext}\n */\nexport function parse(options) {\n  const settings = options || {}\n  const constructs =\n    /** @type {FullNormalizedExtension} */\n    combineExtensions([defaultConstructs, ...(settings.extensions || [])])\n\n  /** @type {ParseContext} */\n  const parser = {\n    defined: [],\n    lazy: {},\n    constructs,\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(string),\n    text: create(text)\n  }\n  return parser\n\n  /**\n   * @param {InitialConstruct} initial\n   */\n  function create(initial) {\n    return creator\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from)\n    }\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;CAMC;;;;;;;;;;;;;;;;;;AAcM,SAAS,MAAM,OAAO;IAC3B,MAAM,WAAW,WAAW,CAAC;IAC7B,MAAM,aACJ,oCAAoC,GACpC,yQAAkB;;WAAwB,SAAS,UAAU,IAAI,EAAE;KAAE;IAEvE,yBAAyB,GACzB,MAAM,SAAS;QACb,SAAS,EAAE;QACX,MAAM,CAAC;QACP;QACA,SAAS;QACT,UAAU;QACV,MAAM;QACN,QAAQ;QACR,MAAM;IACR;IACA,OAAO;IAEP;;GAEC,GACD,SAAS,OAAO,OAAO;QACrB,OAAO;QACP,mBAAmB,GACnB,SAAS,QAAQ,IAAI;YACnB,OAAO,0NAAgB,QAAQ,SAAS;QAC1C;IACF;AACF"}},
    {"offset": {"line": 1494, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1499, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/initialize/text.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {constants} from 'micromark-util-symbol/constants.js'\nimport {types} from 'micromark-util-symbol/types.js'\nimport {ok as assert} from 'uvu/assert'\n\nexport const resolver = {resolveAll: createResolver()}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n\n/**\n * @param {'string' | 'text'} field\n * @returns {InitialConstruct}\n */\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n\n    return start\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === codes.eof) {\n        effects.consume(code)\n        return\n      }\n\n      effects.enter(types.data)\n      effects.consume(code)\n      return data\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit(types.data)\n        return text(code)\n      }\n\n      // Data.\n      effects.consume(code)\n      return data\n    }\n\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n    function atBreak(code) {\n      if (code === codes.eof) {\n        return true\n      }\n\n      const list = constructs[code]\n      let index = -1\n\n      if (list) {\n        // Always populated by defaults.\n        assert(Array.isArray(list), 'expected `disable.null` to be populated')\n\n        while (++index < list.length) {\n          const item = list[index]\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n\n      return false\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n * @returns {Resolver}\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number | undefined} */\n    let enter\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === types.data) {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== types.data) {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n\n        enter = undefined\n      }\n    }\n\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0 // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === types.lineEnding) &&\n      events[eventIndex - 1][1].type === types.data\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean | undefined} */\n      let tabs\n\n      while (index--) {\n        const chunk = chunks[index]\n\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n\n          while (chunk.charCodeAt(bufferIndex - 1) === codes.space) {\n            size++\n            bufferIndex--\n          }\n\n          if (bufferIndex) break\n          bufferIndex = -1\n        }\n        // Number\n        else if (chunk === codes.horizontalTab) {\n          tabs = true\n          size++\n        } else if (chunk === codes.virtualSpace) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length ||\n            tabs ||\n            size < constants.hardBreakPrefixSizeMin\n              ? types.lineSuffix\n              : types.hardBreakTrailing,\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        }\n\n        data.end = Object.assign({}, token.start)\n\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n\n      eventIndex++\n    }\n  }\n\n  return events\n}\n"],"names":[],"mappings":"AAAA;;;;;;;CAOC;;;;;;;;;;;;;;AAOM,MAAM,WAAW;IAAC,YAAY;AAAgB;AAC9C,MAAM,SAAS,kBAAkB;AACjC,MAAM,OAAO,kBAAkB;AAEtC;;;CAGC,GACD,SAAS,kBAAkB,KAAK;IAC9B,OAAO;QACL,UAAU;QACV,YAAY,eACV,UAAU,SAAS,yBAAyB;IAEhD;IAEA;;;GAGC,GACD,SAAS,eAAe,OAAO;QAC7B,MAAM,OAAO,IAAI;QACjB,MAAM,aAAa,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,MAAM;QAChD,MAAM,OAAO,QAAQ,OAAO,CAAC,YAAY,OAAO;QAEhD,OAAO;QAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;YACjB,OAAO,QAAQ,QAAQ,KAAK,QAAQ,QAAQ;QAC9C;QAEA,kBAAkB,GAClB,SAAS,QAAQ,IAAI;YACnB,IAAI,SAAS,+NAAM,GAAG,EAAE;gBACtB,QAAQ,OAAO,CAAC;gBAChB;YACF;YAEA,QAAQ,KAAK,CAAC,+NAAM,IAAI;YACxB,QAAQ,OAAO,CAAC;YAChB,OAAO;QACT;QAEA,kBAAkB,GAClB,SAAS,KAAK,IAAI;YAChB,IAAI,QAAQ,OAAO;gBACjB,QAAQ,IAAI,CAAC,+NAAM,IAAI;gBACvB,OAAO,KAAK;YACd;YAEA,QAAQ;YACR,QAAQ,OAAO,CAAC;YAChB,OAAO;QACT;QAEA;;;KAGC,GACD,SAAS,QAAQ,IAAI;YACnB,IAAI,SAAS,+NAAM,GAAG,EAAE;gBACtB,OAAO;YACT;YAEA,MAAM,OAAO,UAAU,CAAC,KAAK;YAC7B,IAAI,QAAQ,CAAC;YAEb,IAAI,MAAM;gBACR,gCAAgC;gBAChC,uLAAO,MAAM,OAAO,CAAC,OAAO;gBAE5B,MAAO,EAAE,QAAQ,KAAK,MAAM,CAAE;oBAC5B,MAAM,OAAO,IAAI,CAAC,MAAM;oBACxB,IAAI,CAAC,KAAK,QAAQ,IAAI,KAAK,QAAQ,CAAC,IAAI,CAAC,MAAM,KAAK,QAAQ,GAAG;wBAC7D,OAAO;oBACT;gBACF;YACF;YAEA,OAAO;QACT;IACF;AACF;AAEA;;;CAGC,GACD,SAAS,eAAe,aAAa;IACnC,OAAO;IAEP,qBAAqB,GACrB,SAAS,eAAe,MAAM,EAAE,OAAO;QACrC,IAAI,QAAQ,CAAC;QACb,+BAA+B,GAC/B,IAAI;QAEJ,sEAAsE;QACtE,kCAAkC;QAClC,MAAO,EAAE,SAAS,OAAO,MAAM,CAAE;YAC/B,IAAI,UAAU,WAAW;gBACvB,IAAI,MAAM,CAAC,MAAM,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,IAAI,EAAE;oBACzD,QAAQ;oBACR;gBACF;YACF,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,IAAI,EAAE;gBACjE,gDAAgD;gBAChD,IAAI,UAAU,QAAQ,GAAG;oBACvB,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,GAAG;oBAC/C,OAAO,MAAM,CAAC,QAAQ,GAAG,QAAQ,QAAQ;oBACzC,QAAQ,QAAQ;gBAClB;gBAEA,QAAQ;YACV;QACF;QAEA,OAAO,gBAAgB,cAAc,QAAQ,WAAW;IAC1D;AACF;AAEA;;;;;;;;;;CAUC,GACD,SAAS,uBAAuB,MAAM,EAAE,OAAO;IAC7C,IAAI,aAAa,EAAE,cAAc;;IAEjC,MAAO,EAAE,cAAc,OAAO,MAAM,CAAE;QACpC,IACE,CAAC,eAAe,OAAO,MAAM,IAC3B,MAAM,CAAC,WAAW,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,UAAU,KACjD,MAAM,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,IAAI,EAC7C;YACA,MAAM,OAAO,MAAM,CAAC,aAAa,EAAE,CAAC,EAAE;YACtC,MAAM,SAAS,QAAQ,WAAW,CAAC;YACnC,IAAI,QAAQ,OAAO,MAAM;YACzB,IAAI,cAAc,CAAC;YACnB,IAAI,OAAO;YACX,gCAAgC,GAChC,IAAI;YAEJ,MAAO,QAAS;gBACd,MAAM,QAAQ,MAAM,CAAC,MAAM;gBAE3B,IAAI,OAAO,UAAU,UAAU;oBAC7B,cAAc,MAAM,MAAM;oBAE1B,MAAO,MAAM,UAAU,CAAC,cAAc,OAAO,+NAAM,KAAK,CAAE;wBACxD;wBACA;oBACF;oBAEA,IAAI,aAAa;oBACjB,cAAc,CAAC;gBACjB,OAEK,IAAI,UAAU,+NAAM,aAAa,EAAE;oBACtC,OAAO;oBACP;gBACF,OAAO,IAAI,UAAU,+NAAM,YAAY,EAAE;gBACvC,QAAQ;gBACV,OAAO;oBACL,+BAA+B;oBAC/B;oBACA;gBACF;YACF;YAEA,IAAI,MAAM;gBACR,MAAM,QAAQ;oBACZ,MACE,eAAe,OAAO,MAAM,IAC5B,QACA,OAAO,uOAAU,sBAAsB,GACnC,+NAAM,UAAU,GAChB,+NAAM,iBAAiB;oBAC7B,OAAO;wBACL,MAAM,KAAK,GAAG,CAAC,IAAI;wBACnB,QAAQ,KAAK,GAAG,CAAC,MAAM,GAAG;wBAC1B,QAAQ,KAAK,GAAG,CAAC,MAAM,GAAG;wBAC1B,QAAQ,KAAK,KAAK,CAAC,MAAM,GAAG;wBAC5B,cAAc,QACV,cACA,KAAK,KAAK,CAAC,YAAY,GAAG;oBAChC;oBACA,KAAK,OAAO,MAAM,CAAC,CAAC,GAAG,KAAK,GAAG;gBACjC;gBAEA,KAAK,GAAG,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG,MAAM,KAAK;gBAExC,IAAI,KAAK,KAAK,CAAC,MAAM,KAAK,KAAK,GAAG,CAAC,MAAM,EAAE;oBACzC,OAAO,MAAM,CAAC,MAAM;gBACtB,OAAO;oBACL,OAAO,MAAM,CACX,YACA,GACA;wBAAC;wBAAS;wBAAO;qBAAQ,EACzB;wBAAC;wBAAQ;wBAAO;qBAAQ;oBAE1B,cAAc;gBAChB;YACF;YAEA;QACF;IACF;IAEA,OAAO;AACT"}},
    {"offset": {"line": 1689, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1694, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/constructs.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Extension} Extension\n */\n\nimport {\n  attention,\n  autolink,\n  blockQuote,\n  characterEscape,\n  characterReference,\n  codeFenced,\n  codeIndented,\n  codeText,\n  definition,\n  hardBreakEscape,\n  headingAtx,\n  htmlFlow,\n  htmlText,\n  labelEnd,\n  labelStartImage,\n  labelStartLink,\n  lineEnding,\n  list,\n  setextUnderline,\n  thematicBreak\n} from 'micromark-core-commonmark'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {resolver as resolveText} from './initialize/text.js'\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [codes.asterisk]: list,\n  [codes.plusSign]: list,\n  [codes.dash]: list,\n  [codes.digit0]: list,\n  [codes.digit1]: list,\n  [codes.digit2]: list,\n  [codes.digit3]: list,\n  [codes.digit4]: list,\n  [codes.digit5]: list,\n  [codes.digit6]: list,\n  [codes.digit7]: list,\n  [codes.digit8]: list,\n  [codes.digit9]: list,\n  [codes.greaterThan]: blockQuote\n}\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [codes.leftSquareBracket]: definition\n}\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [codes.horizontalTab]: codeIndented,\n  [codes.virtualSpace]: codeIndented,\n  [codes.space]: codeIndented\n}\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [codes.numberSign]: headingAtx,\n  [codes.asterisk]: thematicBreak,\n  [codes.dash]: [setextUnderline, thematicBreak],\n  [codes.lessThan]: htmlFlow,\n  [codes.equalsTo]: setextUnderline,\n  [codes.underscore]: thematicBreak,\n  [codes.graveAccent]: codeFenced,\n  [codes.tilde]: codeFenced\n}\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [codes.ampersand]: characterReference,\n  [codes.backslash]: characterEscape\n}\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [codes.carriageReturn]: lineEnding,\n  [codes.lineFeed]: lineEnding,\n  [codes.carriageReturnLineFeed]: lineEnding,\n  [codes.exclamationMark]: labelStartImage,\n  [codes.ampersand]: characterReference,\n  [codes.asterisk]: attention,\n  [codes.lessThan]: [autolink, htmlText],\n  [codes.leftSquareBracket]: labelStartLink,\n  [codes.backslash]: [hardBreakEscape, characterEscape],\n  [codes.rightSquareBracket]: labelEnd,\n  [codes.underscore]: attention,\n  [codes.graveAccent]: codeText\n}\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {null: [attention, resolveText]}\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {null: [codes.asterisk, codes.underscore]}\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {null: []}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;;;;;;;;;;;;;AA4BM,MAAM,WAAW;IACtB,CAAC,+NAAM,QAAQ,CAAC;IAChB,CAAC,+NAAM,QAAQ,CAAC;IAChB,CAAC,+NAAM,IAAI,CAAC;IACZ,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,MAAM,CAAC;IACd,CAAC,+NAAM,WAAW,CAAC;AACrB;AAGO,MAAM,iBAAiB;IAC5B,CAAC,+NAAM,iBAAiB,CAAC;AAC3B;AAGO,MAAM,cAAc;IACzB,CAAC,+NAAM,aAAa,CAAC;IACrB,CAAC,+NAAM,YAAY,CAAC;IACpB,CAAC,+NAAM,KAAK,CAAC;AACf;AAGO,MAAM,OAAO;IAClB,CAAC,+NAAM,UAAU,CAAC;IAClB,CAAC,+NAAM,QAAQ,CAAC;IAChB,CAAC,+NAAM,IAAI,CAAC,EAAE;;;KAAgC;IAC9C,CAAC,+NAAM,QAAQ,CAAC;IAChB,CAAC,+NAAM,QAAQ,CAAC;IAChB,CAAC,+NAAM,UAAU,CAAC;IAClB,CAAC,+NAAM,WAAW,CAAC;IACnB,CAAC,+NAAM,KAAK,CAAC;AACf;AAGO,MAAM,SAAS;IACpB,CAAC,+NAAM,SAAS,CAAC;IACjB,CAAC,+NAAM,SAAS,CAAC;AACnB;AAGO,MAAM,OAAO;IAClB,CAAC,+NAAM,cAAc,CAAC;IACtB,CAAC,+NAAM,QAAQ,CAAC;IAChB,CAAC,+NAAM,sBAAsB,CAAC;IAC9B,CAAC,+NAAM,eAAe,CAAC;IACvB,CAAC,+NAAM,SAAS,CAAC;IACjB,CAAC,+NAAM,QAAQ,CAAC;IAChB,CAAC,+NAAM,QAAQ,CAAC,EAAE;;;KAAoB;IACtC,CAAC,+NAAM,iBAAiB,CAAC;IACzB,CAAC,+NAAM,SAAS,CAAC,EAAE;;;KAAkC;IACrD,CAAC,+NAAM,kBAAkB,CAAC;IAC1B,CAAC,+NAAM,UAAU,CAAC;IAClB,CAAC,+NAAM,WAAW,CAAC;AACrB;AAGO,MAAM,aAAa;IAAC,MAAM;;;KAAwB;AAAA;AAGlD,MAAM,mBAAmB;IAAC,MAAM;QAAC,+NAAM,QAAQ;QAAE,+NAAM,UAAU;KAAC;AAAA;AAGlE,MAAM,UAAU;IAAC,MAAM,EAAE;AAAA"}},
    {"offset": {"line": 1790, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1795, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/create-tokenizer.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenType} TokenType\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * @callback Restore\n * @returns {void}\n *\n * @typedef Info\n * @property {Restore} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {void}\n */\n\nimport createDebug from 'debug'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {values} from 'micromark-util-symbol/values.js'\nimport {ok as assert} from 'uvu/assert'\n\nconst debug = createDebug('micromark')\n\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(\n    from ? Object.assign({}, from) : {line: 1, column: 1, offset: 0},\n    {_index: 0, _bufferIndex: -1}\n  )\n  /** @type {Record<string, number>} */\n  const columnStart = {}\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = []\n  /** @type {Array<Chunk>} */\n  let chunks = []\n  /** @type {Array<Token>} */\n  let stack = []\n  /** @type {boolean | undefined} */\n  let consumed = true\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {interrupt: true})\n  }\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    previous: codes.eof,\n    code: codes.eof,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  }\n\n  /**\n   * The state function.\n   *\n   * @type {State | void}\n   */\n  let state = initialize.tokenize.call(context, effects)\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n\n  return context\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice)\n\n    main()\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== codes.eof) {\n      return []\n    }\n\n    addResult(initialize, 0)\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n\n    return context.events\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {line, column, offset, _index, _bufferIndex} = point\n    return {line, column, offset, _index, _bufferIndex}\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n    debug('position: define skip: `%j`', point)\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {void}\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index]\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {void}\n   */\n  function go(code) {\n    assert(consumed === true, 'expected character to be consumed')\n    consumed = undefined\n    debug('main: passing `%s` to %s', code, state && state.name)\n    expectedCode = code\n    assert(typeof state === 'function', 'expected state')\n    state = state(code)\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    assert(code === expectedCode, 'expected given code to equal expected code')\n\n    debug('consume: `%s`', code)\n\n    assert(\n      consumed === undefined,\n      'expected code to not have been consumed: this might be because `return x(code)` instead of `return x` was used'\n    )\n    assert(\n      code === null\n        ? context.events.length === 0 ||\n            context.events[context.events.length - 1][0] === 'exit'\n        : context.events[context.events.length - 1][0] === 'enter',\n      'expected last token to be open'\n    )\n\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === codes.carriageReturnLineFeed ? 2 : 1\n      accountForPotentialSkip()\n      debug('position: after eol: `%j`', point)\n    } else if (code !== codes.virtualSpace) {\n      point.column++\n      point.offset++\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++\n\n      // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code\n\n    // Mark as consumed.\n    consumed = true\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n\n    assert(typeof type === 'string', 'expected string type')\n    assert(type.length > 0, 'expected non-empty string')\n    debug('enter: `%s`', type)\n\n    context.events.push(['enter', token, context])\n\n    stack.push(token)\n\n    return token\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    assert(typeof type === 'string', 'expected string type')\n    assert(type.length > 0, 'expected non-empty string')\n\n    const token = stack.pop()\n    assert(token, 'cannot close w/o open tokens')\n    token.end = now()\n\n    assert(type === token.type, 'expected exit token to match current token')\n\n    assert(\n      !(\n        token.start._index === token.end._index &&\n        token.start._bufferIndex === token.end._bufferIndex\n      ),\n      'expected non-empty token (`' + type + '`)'\n    )\n\n    debug('exit: `%s`', token.type)\n    context.events.push(['exit', token, context])\n\n    return token\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   */\n  function constructFactory(onreturn, fields) {\n    return hook\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | Construct | ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State | undefined} [bogusState]\n     * @returns {State}\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      let listOfConstructs\n      /** @type {number} */\n      let constructIndex\n      /** @type {Construct} */\n      let currentConstruct\n      /** @type {Info} */\n      let info\n\n      return Array.isArray(constructs)\n        ? /* c8 ignore next 1 */\n          handleListOfConstructs(constructs)\n        : 'tokenize' in constructs\n        ? // @ts-expect-error Looks like a construct.\n          handleListOfConstructs([constructs])\n        : handleMapOfConstructs(constructs)\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n      function handleMapOfConstructs(map) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          const def = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n            /* c8 ignore next 2 */\n            ...(Array.isArray(def) ? def : def ? [def] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n\n          return handleListOfConstructs(list)(code)\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n\n        if (list.length === 0) {\n          assert(bogusState, 'expected `bogusState` to be given')\n          return bogusState\n        }\n\n        return handleConstruct(list[constructIndex])\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n      function handleConstruct(construct) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          // Always populated by defaults.\n          assert(\n            context.parser.constructs.disable.null,\n            'expected `disable.null` to be populated'\n          )\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a “live binding”, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        assert(code === expectedCode, 'expected code')\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        assert(code === expectedCode, 'expected code')\n        consumed = true\n        info.restore()\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n\n        return bogusState\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {void}\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n\n    assert(\n      construct.partial ||\n        context.events.length === 0 ||\n        context.events[context.events.length - 1][0] === 'exit',\n      'expected last token to end'\n    )\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n\n    return {restore, from: startEventsIndex}\n\n    /**\n     * Restore state.\n     *\n     * @returns {void}\n     */\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n      debug('position: restore: `%j`', point)\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {void}\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'end' | 'start'>} token\n * @returns {Array<Chunk>}\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Array<Chunk>} */\n  let view\n\n  if (startIndex === endIndex) {\n    assert(endBufferIndex > -1, 'expected non-negative end buffer index')\n    assert(startBufferIndex > -1, 'expected non-negative start buffer index')\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n\n    if (startBufferIndex > -1) {\n      const head = view[0]\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex)\n      } else {\n        assert(startBufferIndex === 0, 'expected `startBufferIndex` to be `0`')\n        view.shift()\n      }\n    }\n\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n\n  return view\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean | undefined} [expandTabs=false]\n * @returns {string}\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {Array<string>} */\n  const result = []\n  /** @type {boolean | undefined} */\n  let atTab\n\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n    let value\n\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case codes.carriageReturn: {\n          value = values.cr\n\n          break\n        }\n\n        case codes.lineFeed: {\n          value = values.lf\n\n          break\n        }\n\n        case codes.carriageReturnLineFeed: {\n          value = values.cr + values.lf\n\n          break\n        }\n\n        case codes.horizontalTab: {\n          value = expandTabs ? values.space : values.ht\n\n          break\n        }\n\n        case codes.virtualSpace: {\n          if (!expandTabs && atTab) continue\n          value = values.space\n\n          break\n        }\n\n        default: {\n          assert(typeof chunk === 'number', 'expected number')\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n\n    atTab = chunk === codes.horizontalTab\n    result.push(value)\n  }\n\n  return result.join('')\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;CAaC,GAED;;;;;;;;;;;;;CAaC;;;;;;;;;;;;;;;;;;AAUD,MAAM,QAAQ,4LAAY;AAgBnB,SAAS,gBAAgB,MAAM,EAAE,UAAU,EAAE,IAAI;IACtD,kBAAkB,GAClB,IAAI,QAAQ,OAAO,MAAM,CACvB,OAAO,OAAO,MAAM,CAAC,CAAC,GAAG,QAAQ;QAAC,MAAM;QAAG,QAAQ;QAAG,QAAQ;IAAC,GAC/D;QAAC,QAAQ;QAAG,cAAc,CAAC;IAAC;IAE9B,mCAAmC,GACnC,MAAM,cAAc,CAAC;IACrB,6BAA6B,GAC7B,MAAM,uBAAuB,EAAE;IAC/B,yBAAyB,GACzB,IAAI,SAAS,EAAE;IACf,yBAAyB,GACzB,IAAI,QAAQ,EAAE;IACd,gCAAgC,GAChC,IAAI,WAAW;IAEf;;;;GAIC,GACD,MAAM,UAAU;QACd;QACA;QACA;QACA,SAAS,iBAAiB;QAC1B,OAAO,iBAAiB;QACxB,WAAW,iBAAiB,mBAAmB;YAAC,WAAW;QAAI;IACjE;IAEA;;;;GAIC,GACD,MAAM,UAAU;QACd,UAAU,+NAAM,GAAG;QACnB,MAAM,+NAAM,GAAG;QACf,gBAAgB,CAAC;QACjB,QAAQ,EAAE;QACV;QACA;QACA;QACA;QACA;QACA;IACF;IAEA;;;;GAIC,GACD,IAAI,QAAQ,WAAW,QAAQ,CAAC,IAAI,CAAC,SAAS;IAE9C;;;;GAIC,GACD,IAAI;IAEJ,IAAI,WAAW,UAAU,EAAE;QACzB,qBAAqB,IAAI,CAAC;IAC5B;IAEA,OAAO;IAEP,qCAAqC,GACrC,SAAS,MAAM,KAAK;QAClB,SAAS,uOAAK,QAAQ;QAEtB;QAEA,sDAAsD;QACtD,IAAI,MAAM,CAAC,OAAO,MAAM,GAAG,EAAE,KAAK,+NAAM,GAAG,EAAE;YAC3C,OAAO,EAAE;QACX;QAEA,UAAU,YAAY;QAEtB,gCAAgC;QAChC,QAAQ,MAAM,GAAG,oPAAW,sBAAsB,QAAQ,MAAM,EAAE;QAElE,OAAO,QAAQ,MAAM;IACvB;IAEA,EAAE;IACF,SAAS;IACT,EAAE;IAEF,8CAA8C,GAC9C,SAAS,eAAe,KAAK,EAAE,UAAU;QACvC,OAAO,gBAAgB,YAAY,QAAQ;IAC7C;IAEA,2CAA2C,GAC3C,SAAS,YAAY,KAAK;QACxB,OAAO,YAAY,QAAQ;IAC7B;IAEA,mCAAmC,GACnC,SAAS;QACP,iFAAiF;QACjF,MAAM,EAAC,IAAI,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,YAAY,EAAC,GAAG;QACrD,OAAO;YAAC;YAAM;YAAQ;YAAQ;YAAQ;QAAY;IACpD;IAEA,0CAA0C,GAC1C,SAAS,WAAW,KAAK;QACvB,WAAW,CAAC,MAAM,IAAI,CAAC,GAAG,MAAM,MAAM;QACtC;QACA,MAAM,+BAA+B;IACvC;IAEA,EAAE;IACF,oBAAoB;IACpB,EAAE;IAEF;;;;;;;;;GASC,GACD,SAAS;QACP,mBAAmB,GACnB,IAAI;QAEJ,MAAO,MAAM,MAAM,GAAG,OAAO,MAAM,CAAE;YACnC,MAAM,QAAQ,MAAM,CAAC,MAAM,MAAM,CAAC;YAElC,+CAA+C;YAC/C,IAAI,OAAO,UAAU,UAAU;gBAC7B,aAAa,MAAM,MAAM;gBAEzB,IAAI,MAAM,YAAY,GAAG,GAAG;oBAC1B,MAAM,YAAY,GAAG;gBACvB;gBAEA,MACE,MAAM,MAAM,KAAK,cACjB,MAAM,YAAY,GAAG,MAAM,MAAM,CACjC;oBACA,GAAG,MAAM,UAAU,CAAC,MAAM,YAAY;gBACxC;YACF,OAAO;gBACL,GAAG;YACL;QACF;IACF;IAEA;;;;;GAKC,GACD,SAAS,GAAG,IAAI;QACd,uLAAO,aAAa,MAAM;QAC1B,WAAW;QACX,MAAM,4BAA4B,MAAM,SAAS,MAAM,IAAI;QAC3D,eAAe;QACf,uLAAO,OAAO,UAAU,YAAY;QACpC,QAAQ,MAAM;IAChB;IAEA,+BAA+B,GAC/B,SAAS,QAAQ,IAAI;QACnB,uLAAO,SAAS,cAAc;QAE9B,MAAM,iBAAiB;QAEvB,uLACE,aAAa,WACb;QAEF,uLACE,SAAS,OACL,QAAQ,MAAM,CAAC,MAAM,KAAK,KACxB,QAAQ,MAAM,CAAC,QAAQ,MAAM,CAAC,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK,SACnD,QAAQ,MAAM,CAAC,QAAQ,MAAM,CAAC,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK,SACrD;QAGF,IAAI,yPAAmB,OAAO;YAC5B,MAAM,IAAI;YACV,MAAM,MAAM,GAAG;YACf,MAAM,MAAM,IAAI,SAAS,+NAAM,sBAAsB,GAAG,IAAI;YAC5D;YACA,MAAM,6BAA6B;QACrC,OAAO,IAAI,SAAS,+NAAM,YAAY,EAAE;YACtC,MAAM,MAAM;YACZ,MAAM,MAAM;QACd;QAEA,yBAAyB;QACzB,IAAI,MAAM,YAAY,GAAG,GAAG;YAC1B,MAAM,MAAM;QACd,OAAO;YACL,MAAM,YAAY;YAElB,0BAA0B;YAC1B,mEAAmE;YACnE,WAAW;YACX,IAAI,MAAM,YAAY,KAAK,MAAM,CAAC,MAAM,MAAM,CAAC,CAAC,MAAM,EAAE;gBACtD,MAAM,YAAY,GAAG,CAAC;gBACtB,MAAM,MAAM;YACd;QACF;QAEA,iCAAiC;QACjC,QAAQ,QAAQ,GAAG;QAEnB,oBAAoB;QACpB,WAAW;IACb;IAEA,6BAA6B,GAC7B,SAAS,MAAM,IAAI,EAAE,MAAM;QACzB,kBAAkB,GAClB,uEAAuE;QACvE,MAAM,QAAQ,UAAU,CAAC;QACzB,MAAM,IAAI,GAAG;QACb,MAAM,KAAK,GAAG;QAEd,uLAAO,OAAO,SAAS,UAAU;QACjC,uLAAO,KAAK,MAAM,GAAG,GAAG;QACxB,MAAM,eAAe;QAErB,QAAQ,MAAM,CAAC,IAAI,CAAC;YAAC;YAAS;YAAO;SAAQ;QAE7C,MAAM,IAAI,CAAC;QAEX,OAAO;IACT;IAEA,4BAA4B,GAC5B,SAAS,KAAK,IAAI;QAChB,uLAAO,OAAO,SAAS,UAAU;QACjC,uLAAO,KAAK,MAAM,GAAG,GAAG;QAExB,MAAM,QAAQ,MAAM,GAAG;QACvB,uLAAO,OAAO;QACd,MAAM,GAAG,GAAG;QAEZ,uLAAO,SAAS,MAAM,IAAI,EAAE;QAE5B,uLACE,CAAC,CACC,MAAM,KAAK,CAAC,MAAM,KAAK,MAAM,GAAG,CAAC,MAAM,IACvC,MAAM,KAAK,CAAC,YAAY,KAAK,MAAM,GAAG,CAAC,YAAY,AACrD,GACA,gCAAgC,OAAO;QAGzC,MAAM,cAAc,MAAM,IAAI;QAC9B,QAAQ,MAAM,CAAC,IAAI,CAAC;YAAC;YAAQ;YAAO;SAAQ;QAE5C,OAAO;IACT;IAEA;;;;GAIC,GACD,SAAS,sBAAsB,SAAS,EAAE,IAAI;QAC5C,UAAU,WAAW,KAAK,IAAI;IAChC;IAEA;;;;GAIC,GACD,SAAS,kBAAkB,CAAC,EAAE,IAAI;QAChC,KAAK,OAAO;IACd;IAEA;;;;;GAKC,GACD,SAAS,iBAAiB,QAAQ,EAAE,MAAM;QACxC,OAAO;QAEP;;;;;;;;KAQC,GACD,SAAS,KAAK,UAAU,EAAE,WAAW,EAAE,UAAU;YAC/C,6BAA6B,GAC7B,IAAI;YACJ,mBAAmB,GACnB,IAAI;YACJ,sBAAsB,GACtB,IAAI;YACJ,iBAAiB,GACjB,IAAI;YAEJ,OAAO,MAAM,OAAO,CAAC,cACjB,oBAAoB,GACpB,uBAAuB,cACvB,cAAc,aAEd,uBAAuB;gBAAC;aAAW,IACnC,sBAAsB;YAE1B;;;;;OAKC,GACD,SAAS,sBAAsB,GAAG;gBAChC,OAAO;gBAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;oBACjB,MAAM,MAAM,SAAS,QAAQ,GAAG,CAAC,KAAK;oBACtC,MAAM,MAAM,SAAS,QAAQ,IAAI,IAAI;oBACrC,MAAM,OAAO;wBACX,mCAAmC;wBACnC,oBAAoB,MAChB,MAAM,OAAO,CAAC,OAAO,MAAM,MAAM;4BAAC;yBAAI,GAAG,EAAE;2BAC3C,MAAM,OAAO,CAAC,OAAO,MAAM,MAAM;4BAAC;yBAAI,GAAG,EAAE;qBAChD;oBAED,OAAO,uBAAuB,MAAM;gBACtC;YACF;YAEA;;;;;OAKC,GACD,SAAS,uBAAuB,IAAI;gBAClC,mBAAmB;gBACnB,iBAAiB;gBAEjB,IAAI,KAAK,MAAM,KAAK,GAAG;oBACrB,uLAAO,YAAY;oBACnB,OAAO;gBACT;gBAEA,OAAO,gBAAgB,IAAI,CAAC,eAAe;YAC7C;YAEA;;;;;OAKC,GACD,SAAS,gBAAgB,SAAS;gBAChC,OAAO;gBAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;oBACjB,mEAAmE;oBACnE,oEAAoE;oBACpE,uEAAuE;oBACvE,kBAAkB;oBAClB,OAAO;oBACP,mBAAmB;oBAEnB,IAAI,CAAC,UAAU,OAAO,EAAE;wBACtB,QAAQ,gBAAgB,GAAG;oBAC7B;oBAEA,gCAAgC;oBAChC,uLACE,QAAQ,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,EACtC;oBAGF,IACE,UAAU,IAAI,IACd,QAAQ,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,IAAI,GAC9D;wBACA,OAAO,IAAI;oBACb;oBAEA,OAAO,UAAU,QAAQ,CAAC,IAAI,CAC5B,6DAA6D;oBAC7D,aAAa;oBACb,iEAAiE;oBACjE,SAAS,OAAO,MAAM,CAAC,OAAO,MAAM,CAAC,UAAU,UAAU,SACzD,SACA,IACA,KACA;gBACJ;YACF;YAEA,kBAAkB,GAClB,SAAS,GAAG,IAAI;gBACd,uLAAO,SAAS,cAAc;gBAC9B,WAAW;gBACX,SAAS,kBAAkB;gBAC3B,OAAO;YACT;YAEA,kBAAkB,GAClB,SAAS,IAAI,IAAI;gBACf,uLAAO,SAAS,cAAc;gBAC9B,WAAW;gBACX,KAAK,OAAO;gBAEZ,IAAI,EAAE,iBAAiB,iBAAiB,MAAM,EAAE;oBAC9C,OAAO,gBAAgB,gBAAgB,CAAC,eAAe;gBACzD;gBAEA,OAAO;YACT;QACF;IACF;IAEA;;;;GAIC,GACD,SAAS,UAAU,SAAS,EAAE,IAAI;QAChC,IAAI,UAAU,UAAU,IAAI,CAAC,qBAAqB,QAAQ,CAAC,YAAY;YACrE,qBAAqB,IAAI,CAAC;QAC5B;QAEA,IAAI,UAAU,OAAO,EAAE;YACrB,yOACE,QAAQ,MAAM,EACd,MACA,QAAQ,MAAM,CAAC,MAAM,GAAG,MACxB,UAAU,OAAO,CAAC,QAAQ,MAAM,CAAC,KAAK,CAAC,OAAO;QAElD;QAEA,IAAI,UAAU,SAAS,EAAE;YACvB,QAAQ,MAAM,GAAG,UAAU,SAAS,CAAC,QAAQ,MAAM,EAAE;QACvD;QAEA,uLACE,UAAU,OAAO,IACf,QAAQ,MAAM,CAAC,MAAM,KAAK,KAC1B,QAAQ,MAAM,CAAC,QAAQ,MAAM,CAAC,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK,QACnD;IAEJ;IAEA;;;;GAIC,GACD,SAAS;QACP,MAAM,aAAa;QACnB,MAAM,gBAAgB,QAAQ,QAAQ;QACtC,MAAM,wBAAwB,QAAQ,gBAAgB;QACtD,MAAM,mBAAmB,QAAQ,MAAM,CAAC,MAAM;QAC9C,MAAM,aAAa,MAAM,IAAI,CAAC;QAE9B,OAAO;YAAC;YAAS,MAAM;QAAgB;QAEvC;;;;KAIC,GACD,SAAS;YACP,QAAQ;YACR,QAAQ,QAAQ,GAAG;YACnB,QAAQ,gBAAgB,GAAG;YAC3B,QAAQ,MAAM,CAAC,MAAM,GAAG;YACxB,QAAQ;YACR;YACA,MAAM,2BAA2B;QACnC;IACF;IAEA;;;;;GAKC,GACD,SAAS;QACP,IAAI,MAAM,IAAI,IAAI,eAAe,MAAM,MAAM,GAAG,GAAG;YACjD,MAAM,MAAM,GAAG,WAAW,CAAC,MAAM,IAAI,CAAC;YACtC,MAAM,MAAM,IAAI,WAAW,CAAC,MAAM,IAAI,CAAC,GAAG;QAC5C;IACF;AACF;AAEA;;;;;;CAMC,GACD,SAAS,YAAY,MAAM,EAAE,KAAK;IAChC,MAAM,aAAa,MAAM,KAAK,CAAC,MAAM;IACrC,MAAM,mBAAmB,MAAM,KAAK,CAAC,YAAY;IACjD,MAAM,WAAW,MAAM,GAAG,CAAC,MAAM;IACjC,MAAM,iBAAiB,MAAM,GAAG,CAAC,YAAY;IAC7C,yBAAyB,GACzB,IAAI;IAEJ,IAAI,eAAe,UAAU;QAC3B,uLAAO,iBAAiB,CAAC,GAAG;QAC5B,uLAAO,mBAAmB,CAAC,GAAG;QAC9B,4DAA4D;QAC5D,OAAO;YAAC,MAAM,CAAC,WAAW,CAAC,KAAK,CAAC,kBAAkB;SAAgB;IACrE,OAAO;QACL,OAAO,OAAO,KAAK,CAAC,YAAY;QAEhC,IAAI,mBAAmB,CAAC,GAAG;YACzB,MAAM,OAAO,IAAI,CAAC,EAAE;YACpB,IAAI,OAAO,SAAS,UAAU;gBAC5B,IAAI,CAAC,EAAE,GAAG,KAAK,KAAK,CAAC;YACvB,OAAO;gBACL,uLAAO,qBAAqB,GAAG;gBAC/B,KAAK,KAAK;YACZ;QACF;QAEA,IAAI,iBAAiB,GAAG;YACtB,4DAA4D;YAC5D,KAAK,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,GAAG;QACtC;IACF;IAEA,OAAO;AACT;AAEA;;;;;;CAMC,GACD,SAAS,gBAAgB,MAAM,EAAE,UAAU;IACzC,IAAI,QAAQ,CAAC;IACb,0BAA0B,GAC1B,MAAM,SAAS,EAAE;IACjB,gCAAgC,GAChC,IAAI;IAEJ,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;QAC9B,MAAM,QAAQ,MAAM,CAAC,MAAM;QAC3B,mBAAmB,GACnB,IAAI;QAEJ,IAAI,OAAO,UAAU,UAAU;YAC7B,QAAQ;QACV,OACE,OAAQ;YACN,KAAK,+NAAM,cAAc;gBAAE;oBACzB,QAAQ,iOAAO,EAAE;oBAEjB;gBACF;YAEA,KAAK,+NAAM,QAAQ;gBAAE;oBACnB,QAAQ,iOAAO,EAAE;oBAEjB;gBACF;YAEA,KAAK,+NAAM,sBAAsB;gBAAE;oBACjC,QAAQ,iOAAO,EAAE,GAAG,iOAAO,EAAE;oBAE7B;gBACF;YAEA,KAAK,+NAAM,aAAa;gBAAE;oBACxB,QAAQ,aAAa,iOAAO,KAAK,GAAG,iOAAO,EAAE;oBAE7C;gBACF;YAEA,KAAK,+NAAM,YAAY;gBAAE;oBACvB,IAAI,CAAC,cAAc,OAAO;oBAC1B,QAAQ,iOAAO,KAAK;oBAEpB;gBACF;YAEA;gBAAS;oBACP,uLAAO,OAAO,UAAU,UAAU;oBAClC,wCAAwC;oBACxC,QAAQ,OAAO,YAAY,CAAC;gBAC9B;QACF;QAEF,QAAQ,UAAU,+NAAM,aAAa;QACrC,OAAO,IAAI,CAAC;IACd;IAEA,OAAO,OAAO,IAAI,CAAC;AACrB"}},
    {"offset": {"line": 2308, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2313, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/initialize/flow.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {blankLine, content} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {types} from 'micromark-util-symbol/types.js'\nimport {ok as assert} from 'uvu/assert'\n\n/** @type {InitialConstruct} */\nexport const flow = {tokenize: initializeFlow}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeFlow(effects) {\n  const self = this\n  const initial = effects.attempt(\n    // Try to parse a blank line.\n    blankLine,\n    atBlankEnding,\n    // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        types.linePrefix\n      )\n    )\n  )\n\n  return initial\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    assert(\n      code === codes.eof || markdownLineEnding(code),\n      'expected eol or eof'\n    )\n\n    if (code === codes.eof) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter(types.lineEndingBlank)\n    effects.consume(code)\n    effects.exit(types.lineEndingBlank)\n    self.currentConstruct = undefined\n    return initial\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    assert(\n      code === codes.eof || markdownLineEnding(code),\n      'expected eol or eof'\n    )\n\n    if (code === codes.eof) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter(types.lineEnding)\n    effects.consume(code)\n    effects.exit(types.lineEnding)\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;CAKC;;;;;;;;;;;;;;;;AAUM,MAAM,OAAO;IAAC,UAAU;AAAc;AAE7C;;;CAGC,GACD,SAAS,eAAe,OAAO;IAC7B,MAAM,OAAO,IAAI;IACjB,MAAM,UAAU,QAAQ,OAAO,oPAG7B,eACA,sDAAsD;IACtD,QAAQ,OAAO,CACb,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,WAAW,EAClC,gBACA,iPACE,SACA,QAAQ,OAAO,CACb,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,IAAI,EAC3B,gBACA,QAAQ,OAAO,kPAAU,kBAE3B,+NAAM,UAAU;IAKtB,OAAO;IAEP,kBAAkB,GAClB,SAAS,cAAc,IAAI;QACzB,uLACE,SAAS,+NAAM,GAAG,IAAI,yPAAmB,OACzC;QAGF,IAAI,SAAS,+NAAM,GAAG,EAAE;YACtB,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,QAAQ,KAAK,CAAC,+NAAM,eAAe;QACnC,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC,+NAAM,eAAe;QAClC,KAAK,gBAAgB,GAAG;QACxB,OAAO;IACT;IAEA,kBAAkB,GAClB,SAAS,eAAe,IAAI;QAC1B,uLACE,SAAS,+NAAM,GAAG,IAAI,yPAAmB,OACzC;QAGF,IAAI,SAAS,+NAAM,GAAG,EAAE;YACtB,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,QAAQ,KAAK,CAAC,+NAAM,UAAU;QAC9B,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC,+NAAM,UAAU;QAC7B,KAAK,gBAAgB,GAAG;QACxB,OAAO;IACT;AACF"}},
    {"offset": {"line": 2370, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2375, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/initialize/document.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {constants} from 'micromark-util-symbol/constants.js'\nimport {types} from 'micromark-util-symbol/types.js'\nimport {ok as assert} from 'uvu/assert'\n\n/** @type {InitialConstruct} */\nexport const document = {tokenize: initializeDocument}\n\n/** @type {Construct} */\nconst containerConstruct = {tokenize: tokenizeContainer}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {Array<StackItem>} */\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext | undefined} */\n  let childFlow\n  /** @type {Token | undefined} */\n  let childToken\n  /** @type {number} */\n  let lineStartOffset\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      assert(\n        item[0].continuation,\n        'expected `continuation` to be defined on container construct'\n      )\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    }\n\n    // Done.\n    return checkNewContainers(code)\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    assert(\n      self.containerState,\n      'expected `containerState` to be defined after continuation'\n    )\n\n    continued++\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n\n      if (childFlow) {\n        closeFlow()\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === types.chunkFlow\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n\n      assert(point, 'could not find previous flow chunk')\n\n      exitContainers(continued)\n\n      // Fix positions.\n      let index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n\n      return checkNewContainers(code)\n    }\n\n    return start(code)\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(\n        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack\n      )\n    }\n\n    // Check if there is a new container.\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    assert(\n      self.currentConstruct,\n      'expected `currentConstruct` to be defined on tokenizer'\n    )\n    assert(\n      self.containerState,\n      'expected `containerState` to be defined on tokenizer'\n    )\n    continued++\n    stack.push([self.currentConstruct, self.containerState])\n    // Try another.\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === codes.eof) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter(types.chunkFlow, {\n      contentType: constants.contentTypeFlow,\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n\n    return flowContinue(code)\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === codes.eof) {\n      writeToChild(effects.exit(types.chunkFlow), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit(types.chunkFlow))\n      // Get ready for the next line.\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n\n    effects.consume(code)\n    return flowContinue\n  }\n\n  /**\n   * @param {Token} token\n   * @param {boolean | undefined} [eof]\n   * @returns {void}\n   */\n  function writeToChild(token, eof) {\n    assert(childFlow, 'expected `childFlow` to be defined when continuing')\n    const stream = self.sliceStream(token)\n    if (eof) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream)\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n\n      while (index--) {\n        if (\n          // The token starts before the line ending…\n          childFlow.events[index][1].start.offset < lineStartOffset &&\n          // …and either is not ended yet…\n          (!childFlow.events[index][1].end ||\n            // …or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean | undefined} */\n      let seen\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === types.chunkFlow\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n\n          seen = true\n        }\n      }\n\n      assert(point, 'could not find previous flow chunk')\n\n      exitContainers(continued)\n\n      // Fix positions.\n      index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n    }\n  }\n\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n  function exitContainers(size) {\n    let index = stack.length\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      assert(\n        entry[0].exit,\n        'expected `exit` to be defined on container construct'\n      )\n      entry[0].exit.call(self, effects)\n    }\n\n    stack.length = size\n  }\n\n  function closeFlow() {\n    assert(\n      self.containerState,\n      'expected `containerState` to be defined when closing flow'\n    )\n    assert(childFlow, 'expected `childFlow` to be defined when closing it')\n    childFlow.write([codes.eof])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n  assert(\n    this.parser.constructs.disable.null,\n    'expected `disable.null` to be populated'\n  )\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    types.linePrefix,\n    this.parser.constructs.disable.null.includes('codeIndented')\n      ? undefined\n      : constants.tabSize\n  )\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;CAUC,GAED;;CAEC;;;;;;;;;;;;;;;;;;AAWM,MAAM,WAAW;IAAC,UAAU;AAAkB;AAErD,sBAAsB,GACtB,MAAM,qBAAqB;IAAC,UAAU;AAAiB;AAEvD;;;CAGC,GACD,SAAS,mBAAmB,OAAO;IACjC,MAAM,OAAO,IAAI;IACjB,6BAA6B,GAC7B,MAAM,QAAQ,EAAE;IAChB,IAAI,YAAY;IAChB,wCAAwC,GACxC,IAAI;IACJ,8BAA8B,GAC9B,IAAI;IACJ,mBAAmB,GACnB,IAAI;IAEJ,OAAO;IAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;QACjB,mEAAmE;QACnE,uEAAuE;QACvE,SAAS;QACT,4EAA4E;QAC5E,kBAAkB;QAClB,uDAAuD;QACvD,yCAAyC;QACzC,kEAAkE;QAClE,uEAAuE;QACvE,qBAAqB;QACrB,IAAI,YAAY,MAAM,MAAM,EAAE;YAC5B,MAAM,OAAO,KAAK,CAAC,UAAU;YAC7B,KAAK,cAAc,GAAG,IAAI,CAAC,EAAE;YAC7B,uLACE,IAAI,CAAC,EAAE,CAAC,YAAY,EACpB;YAEF,OAAO,QAAQ,OAAO,CACpB,IAAI,CAAC,EAAE,CAAC,YAAY,EACpB,kBACA,oBACA;QACJ;QAEA,QAAQ;QACR,OAAO,mBAAmB;IAC5B;IAEA,kBAAkB,GAClB,SAAS,iBAAiB,IAAI;QAC5B,uLACE,KAAK,cAAc,EACnB;QAGF;QAEA,yEAAyE;QACzE,wEAAwE;QACxE,cAAc;QACd,IAAI,KAAK,cAAc,CAAC,UAAU,EAAE;YAClC,KAAK,cAAc,CAAC,UAAU,GAAG;YAEjC,IAAI,WAAW;gBACb;YACF;YAEA,kEAAkE;YAClE,4DAA4D;YAC5D,MAAM,mBAAmB,KAAK,MAAM,CAAC,MAAM;YAC3C,IAAI,kBAAkB;YACtB,8BAA8B,GAC9B,IAAI;YAEJ,uBAAuB;YACvB,MAAO,kBAAmB;gBACxB,IACE,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,KAAK,UACpC,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,SAAS,EACxD;oBACA,QAAQ,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,GAAG;oBAC3C;gBACF;YACF;YAEA,uLAAO,OAAO;YAEd,eAAe;YAEf,iBAAiB;YACjB,IAAI,QAAQ;YAEZ,MAAO,QAAQ,KAAK,MAAM,CAAC,MAAM,CAAE;gBACjC,KAAK,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG;gBAC9C;YACF;YAEA,4DAA4D;YAC5D,yOACE,KAAK,MAAM,EACX,kBAAkB,GAClB,GACA,KAAK,MAAM,CAAC,KAAK,CAAC;YAGpB,+BAA+B;YAC/B,KAAK,MAAM,CAAC,MAAM,GAAG;YAErB,OAAO,mBAAmB;QAC5B;QAEA,OAAO,MAAM;IACf;IAEA,kBAAkB,GAClB,SAAS,mBAAmB,IAAI;QAC9B,yEAAyE;QACzE,0DAA0D;QAC1D,sEAAsE;QACtE,sEAAsE;QACtE,SAAS;QACT,IAAI,cAAc,MAAM,MAAM,EAAE;YAC9B,sEAAsE;YACtE,iBAAiB;YACjB,qDAAqD;YACrD,IAAI,CAAC,WAAW;gBACd,OAAO,kBAAkB;YAC3B;YAEA,kEAAkE;YAClE,qEAAqE;YACrE,SAAS;YACT,IAAI,UAAU,gBAAgB,IAAI,UAAU,gBAAgB,CAAC,QAAQ,EAAE;gBACrE,OAAO,UAAU;YACnB;YAEA,sDAAsD;YACtD,sEAAsE;YACtE,aAAa;YACb,uEAAuE;YACvE,kDAAkD;YAClD,KAAK,SAAS,GAAG,QACf,UAAU,gBAAgB,IAAI,CAAC,UAAU,6BAA6B;QAE1E;QAEA,qCAAqC;QACrC,KAAK,cAAc,GAAG,CAAC;QACvB,OAAO,QAAQ,KAAK,CAClB,oBACA,sBACA,uBACA;IACJ;IAEA,kBAAkB,GAClB,SAAS,qBAAqB,IAAI;QAChC,IAAI,WAAW;QACf,eAAe;QACf,OAAO,kBAAkB;IAC3B;IAEA,kBAAkB,GAClB,SAAS,sBAAsB,IAAI;QACjC,KAAK,MAAM,CAAC,IAAI,CAAC,KAAK,GAAG,GAAG,IAAI,CAAC,GAAG,cAAc,MAAM,MAAM;QAC9D,kBAAkB,KAAK,GAAG,GAAG,MAAM;QACnC,OAAO,UAAU;IACnB;IAEA,kBAAkB,GAClB,SAAS,kBAAkB,IAAI;QAC7B,sBAAsB;QACtB,KAAK,cAAc,GAAG,CAAC;QACvB,OAAO,QAAQ,OAAO,CACpB,oBACA,mBACA,WACA;IACJ;IAEA,kBAAkB,GAClB,SAAS,kBAAkB,IAAI;QAC7B,uLACE,KAAK,gBAAgB,EACrB;QAEF,uLACE,KAAK,cAAc,EACnB;QAEF;QACA,MAAM,IAAI,CAAC;YAAC,KAAK,gBAAgB;YAAE,KAAK,cAAc;SAAC;QACvD,eAAe;QACf,OAAO,kBAAkB;IAC3B;IAEA,kBAAkB,GAClB,SAAS,UAAU,IAAI;QACrB,IAAI,SAAS,+NAAM,GAAG,EAAE;YACtB,IAAI,WAAW;YACf,eAAe;YACf,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,YAAY,aAAa,KAAK,MAAM,CAAC,IAAI,CAAC,KAAK,GAAG;QAClD,QAAQ,KAAK,CAAC,+NAAM,SAAS,EAAE;YAC7B,aAAa,uOAAU,eAAe;YACtC,UAAU;YACV,YAAY;QACd;QAEA,OAAO,aAAa;IACtB;IAEA,kBAAkB,GAClB,SAAS,aAAa,IAAI;QACxB,IAAI,SAAS,+NAAM,GAAG,EAAE;YACtB,aAAa,QAAQ,IAAI,CAAC,+NAAM,SAAS,GAAG;YAC5C,eAAe;YACf,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,IAAI,yPAAmB,OAAO;YAC5B,QAAQ,OAAO,CAAC;YAChB,aAAa,QAAQ,IAAI,CAAC,+NAAM,SAAS;YACzC,+BAA+B;YAC/B,YAAY;YACZ,KAAK,SAAS,GAAG;YACjB,OAAO;QACT;QAEA,QAAQ,OAAO,CAAC;QAChB,OAAO;IACT;IAEA;;;;GAIC,GACD,SAAS,aAAa,KAAK,EAAE,GAAG;QAC9B,uLAAO,WAAW;QAClB,MAAM,SAAS,KAAK,WAAW,CAAC;QAChC,IAAI,KAAK,OAAO,IAAI,CAAC;QACrB,MAAM,QAAQ,GAAG;QACjB,IAAI,YAAY,WAAW,IAAI,GAAG;QAClC,aAAa;QACb,UAAU,UAAU,CAAC,MAAM,KAAK;QAChC,UAAU,KAAK,CAAC;QAEhB,yCAAyC;QACzC,EAAE;QACF,cAAc;QACd,MAAM;QACN,KAAK;QACL,EAAE;QACF,MAAM;QACN,EAAE;QACF,SAAS;QACT,IAAI;QACJ,EAAE;QACF,MAAM;QACN,EAAE;QACF,UAAU;QACV,IAAI;QACJ,MAAM;QACN,EAAE;QACF,yEAAyE;QACzE,uEAAuE;QACvE,yCAAyC;QACzC,yEAAyE;QACzE,wDAAwD;QACxD,EAAE;QACF,qEAAqE;QACrE,qBAAqB;QACrB,oEAAoE;QACpE,uBAAuB;QACvB,yEAAyE;QACzE,8CAA8C;QAC9C,EAAE;QACF,sEAAsE;QACtE,kDAAkD;QAClD,yEAAyE;QACzE,IAAI,KAAK,MAAM,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,IAAI,CAAC,EAAE;YACtC,IAAI,QAAQ,UAAU,MAAM,CAAC,MAAM;YAEnC,MAAO,QAAS;gBACd,IACE,2CAA2C;gBAC3C,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,KAAK,CAAC,MAAM,GAAG,mBAC1C,gCAAgC;gBAChC,CAAC,CAAC,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,IAC9B,qBAAqB;gBACrB,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,CAAC,MAAM,GAAG,eAAe,GACzD;oBACA,mEAAmE;oBACnE,qBAAqB;oBACrB;gBACF;YACF;YAEA,kEAAkE;YAClE,qDAAqD;YACrD,MAAM,mBAAmB,KAAK,MAAM,CAAC,MAAM;YAC3C,IAAI,kBAAkB;YACtB,gCAAgC,GAChC,IAAI;YACJ,8BAA8B,GAC9B,IAAI;YAEJ,0DAA0D;YAC1D,MAAO,kBAAmB;gBACxB,IACE,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,KAAK,UACpC,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,SAAS,EACxD;oBACA,IAAI,MAAM;wBACR,QAAQ,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,GAAG;wBAC3C;oBACF;oBAEA,OAAO;gBACT;YACF;YAEA,uLAAO,OAAO;YAEd,eAAe;YAEf,iBAAiB;YACjB,QAAQ;YAER,MAAO,QAAQ,KAAK,MAAM,CAAC,MAAM,CAAE;gBACjC,KAAK,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG;gBAC9C;YACF;YAEA,4DAA4D;YAC5D,yOACE,KAAK,MAAM,EACX,kBAAkB,GAClB,GACA,KAAK,MAAM,CAAC,KAAK,CAAC;YAGpB,+BAA+B;YAC/B,KAAK,MAAM,CAAC,MAAM,GAAG;QACvB;IACF;IAEA;;;GAGC,GACD,SAAS,eAAe,IAAI;QAC1B,IAAI,QAAQ,MAAM,MAAM;QAExB,wBAAwB;QACxB,MAAO,UAAU,KAAM;YACrB,MAAM,QAAQ,KAAK,CAAC,MAAM;YAC1B,KAAK,cAAc,GAAG,KAAK,CAAC,EAAE;YAC9B,uLACE,KAAK,CAAC,EAAE,CAAC,IAAI,EACb;YAEF,KAAK,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM;QAC3B;QAEA,MAAM,MAAM,GAAG;IACjB;IAEA,SAAS;QACP,uLACE,KAAK,cAAc,EACnB;QAEF,uLAAO,WAAW;QAClB,UAAU,KAAK,CAAC;YAAC,+NAAM,GAAG;SAAC;QAC3B,aAAa;QACb,YAAY;QACZ,KAAK,cAAc,CAAC,UAAU,GAAG;IACnC;AACF;AAEA;;;CAGC,GACD,SAAS,kBAAkB,OAAO,EAAE,EAAE,EAAE,GAAG;IACzC,gCAAgC;IAChC,uLACE,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,EACnC;IAEF,OAAO,iPACL,SACA,QAAQ,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,QAAQ,EAAE,IAAI,MACrD,+NAAM,UAAU,EAChB,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,kBACzC,YACA,uOAAU,OAAO;AAEzB"}},
    {"offset": {"line": 2691, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2696, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/initialize/content.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {constants} from 'micromark-util-symbol/constants.js'\nimport {types} from 'micromark-util-symbol/types.js'\nimport {ok as assert} from 'uvu/assert'\n\n/** @type {InitialConstruct} */\nexport const content = {tokenize: initializeContent}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n  let previous\n\n  return contentStart\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    assert(\n      code === codes.eof || markdownLineEnding(code),\n      'expected eol or eof'\n    )\n\n    if (code === codes.eof) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter(types.lineEnding)\n    effects.consume(code)\n    effects.exit(types.lineEnding)\n    return factorySpace(effects, contentStart, types.linePrefix)\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    assert(\n      code !== codes.eof && !markdownLineEnding(code),\n      'expected anything other than a line ending or EOF'\n    )\n    effects.enter(types.paragraph)\n    return lineStart(code)\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter(types.chunkText, {\n      contentType: constants.contentTypeText,\n      previous\n    })\n\n    if (previous) {\n      previous.next = token\n    }\n\n    previous = token\n\n    return data(code)\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === codes.eof) {\n      effects.exit(types.chunkText)\n      effects.exit(types.paragraph)\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit(types.chunkText)\n      return lineStart\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;CAMC;;;;;;;;;;;;;;;;AAUM,MAAM,UAAU;IAAC,UAAU;AAAiB;AAEnD;;;CAGC,GACD,SAAS,kBAAkB,OAAO;IAChC,MAAM,eAAe,QAAQ,OAAO,CAClC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,cAAc,EACrC,4BACA;IAEF,kBAAkB,GAClB,IAAI;IAEJ,OAAO;IAEP,kBAAkB,GAClB,SAAS,2BAA2B,IAAI;QACtC,uLACE,SAAS,+NAAM,GAAG,IAAI,yPAAmB,OACzC;QAGF,IAAI,SAAS,+NAAM,GAAG,EAAE;YACtB,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,QAAQ,KAAK,CAAC,+NAAM,UAAU;QAC9B,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC,+NAAM,UAAU;QAC7B,OAAO,iPAAa,SAAS,cAAc,+NAAM,UAAU;IAC7D;IAEA,kBAAkB,GAClB,SAAS,iBAAiB,IAAI;QAC5B,uLACE,SAAS,+NAAM,GAAG,IAAI,CAAC,yPAAmB,OAC1C;QAEF,QAAQ,KAAK,CAAC,+NAAM,SAAS;QAC7B,OAAO,UAAU;IACnB;IAEA,kBAAkB,GAClB,SAAS,UAAU,IAAI;QACrB,MAAM,QAAQ,QAAQ,KAAK,CAAC,+NAAM,SAAS,EAAE;YAC3C,aAAa,uOAAU,eAAe;YACtC;QACF;QAEA,IAAI,UAAU;YACZ,SAAS,IAAI,GAAG;QAClB;QAEA,WAAW;QAEX,OAAO,KAAK;IACd;IAEA,kBAAkB,GAClB,SAAS,KAAK,IAAI;QAChB,IAAI,SAAS,+NAAM,GAAG,EAAE;YACtB,QAAQ,IAAI,CAAC,+NAAM,SAAS;YAC5B,QAAQ,IAAI,CAAC,+NAAM,SAAS;YAC5B,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,IAAI,yPAAmB,OAAO;YAC5B,QAAQ,OAAO,CAAC;YAChB,QAAQ,IAAI,CAAC,+NAAM,SAAS;YAC5B,OAAO;QACT;QAEA,QAAQ;QACR,QAAQ,OAAO,CAAC;QAChB,OAAO;IACT;AACF"}},
    {"offset": {"line": 2772, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2777, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/parse.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Create} Create\n * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n */\n\nimport {combineExtensions} from 'micromark-util-combine-extensions'\nimport {content} from './initialize/content.js'\nimport {document} from './initialize/document.js'\nimport {flow} from './initialize/flow.js'\nimport {text, string} from './initialize/text.js'\nimport {createTokenizer} from './create-tokenizer.js'\nimport * as defaultConstructs from './constructs.js'\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n * @returns {ParseContext}\n */\nexport function parse(options) {\n  const settings = options || {}\n  const constructs = /** @type {FullNormalizedExtension} */ (\n    combineExtensions([defaultConstructs, ...(settings.extensions || [])])\n  )\n\n  /** @type {ParseContext} */\n  const parser = {\n    defined: [],\n    lazy: {},\n    constructs,\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(string),\n    text: create(text)\n  }\n\n  return parser\n\n  /**\n   * @param {InitialConstruct} initial\n   */\n  function create(initial) {\n    return creator\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from)\n    }\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;CAMC;;;;;;;;;;;;;;;;;;AAcM,SAAS,MAAM,OAAO;IAC3B,MAAM,WAAW,WAAW,CAAC;IAC7B,MAAM,aACJ,yQAAkB;;WAAwB,SAAS,UAAU,IAAI,EAAE;KAAE;IAGvE,yBAAyB,GACzB,MAAM,SAAS;QACb,SAAS,EAAE;QACX,MAAM,CAAC;QACP;QACA,SAAS;QACT,UAAU;QACV,MAAM;QACN,QAAQ;QACR,MAAM;IACR;IAEA,OAAO;IAEP;;GAEC,GACD,SAAS,OAAO,OAAO;QACrB,OAAO;QACP,mBAAmB,GACnB,SAAS,QAAQ,IAAI;YACnB,OAAO,iOAAgB,QAAQ,SAAS;QAC1C;IACF;AACF"}},
    {"offset": {"line": 2827, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2832, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/lib/compile.js"],"sourcesContent":["/**\n * While micromark is a lexer/tokenizer, the common case of going from markdown\n * to html is currently built in as this module, even though the parts can be\n * used separately to build ASTs, CSTs, or many other output formats.\n *\n * Having an HTML compiler built in is useful because it allows us to check for\n * compliancy to CommonMark, the de facto norm of markdown, specified in roughly\n * 600 input/output cases.\n *\n * This module has an interface that accepts lists of events instead of the\n * whole at once, however, because markdown can’t be truly streaming, we buffer\n * events before processing and outputting the final result.\n */\n\n/**\n * @typedef {import('micromark-util-types').Compile} Compile\n * @typedef {import('micromark-util-types').CompileContext} CompileContext\n * @typedef {import('micromark-util-types').CompileData} CompileData\n * @typedef {import('micromark-util-types').CompileOptions} CompileOptions\n * @typedef {import('micromark-util-types').Definition} Definition\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Handle} Handle\n * @typedef {import('micromark-util-types').HtmlExtension} HtmlExtension\n * @typedef {import('micromark-util-types').NormalizedHtmlExtension} NormalizedHtmlExtension\n * @typedef {import('micromark-util-types').Token} Token\n */\n\n/**\n * @typedef Media\n * @property {boolean | undefined} [image]\n * @property {string | undefined} [labelId]\n * @property {string | undefined} [label]\n * @property {string | undefined} [referenceId]\n * @property {string | undefined} [destination]\n * @property {string | undefined} [title]\n */\n\nimport {decodeNamedCharacterReference} from 'decode-named-character-reference'\nimport {push} from 'micromark-util-chunked'\nimport {combineHtmlExtensions} from 'micromark-util-combine-extensions'\nimport {decodeNumericCharacterReference} from 'micromark-util-decode-numeric-character-reference'\nimport {encode as _encode} from 'micromark-util-encode'\nimport {normalizeIdentifier} from 'micromark-util-normalize-identifier'\nimport {sanitizeUri} from 'micromark-util-sanitize-uri'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {constants} from 'micromark-util-symbol/constants.js'\nimport {types} from 'micromark-util-symbol/types.js'\nimport {ok as assert} from 'uvu/assert'\n\nconst hasOwnProperty = {}.hasOwnProperty\n\n/**\n * These two are allowlists of safe protocols for full URLs in respectively the\n * `href` (on `<a>`) and `src` (on `<img>`) attributes.\n * They are based on what is allowed on GitHub,\n * <https://github.com/syntax-tree/hast-util-sanitize/blob/9275b21/lib/github.json#L31>\n */\nconst protocolHref = /^(https?|ircs?|mailto|xmpp)$/i\nconst protocolSrc = /^https?$/i\n\n/**\n * @param {CompileOptions | null | undefined} [options]\n * @returns {Compile}\n */\nexport function compile(options) {\n  const settings = options || {}\n\n  /**\n   * Tags is needed because according to markdown, links and emphasis and\n   * whatnot can exist in images, however, as HTML doesn’t allow content in\n   * images, the tags are ignored in the `alt` attribute, but the content\n   * remains.\n   *\n   * @type {boolean | undefined}\n   */\n  let tags = true\n\n  /**\n   * An object to track identifiers to media (URLs and titles) defined with\n   * definitions.\n   *\n   * @type {Record<string, Definition>}\n   */\n  const definitions = {}\n\n  /**\n   * A lot of the handlers need to capture some of the output data, modify it\n   * somehow, and then deal with it.\n   * We do that by tracking a stack of buffers, that can be opened (with\n   * `buffer`) and closed (with `resume`) to access them.\n   *\n   * @type {Array<Array<string>>}\n   */\n  const buffers = [[]]\n\n  /**\n   * As we can have links in images and the other way around, where the deepest\n   * ones are closed first, we need to track which one we’re in.\n   *\n   * @type {Array<Media>}\n   */\n  const mediaStack = []\n\n  /**\n   * Same as `mediaStack` for tightness, which is specific to lists.\n   * We need to track if we’re currently in a tight or loose container.\n   *\n   * @type {Array<boolean>}\n   */\n  const tightStack = []\n\n  /** @type {HtmlExtension} */\n  const defaultHandlers = {\n    enter: {\n      blockQuote: onenterblockquote,\n      codeFenced: onentercodefenced,\n      codeFencedFenceInfo: buffer,\n      codeFencedFenceMeta: buffer,\n      codeIndented: onentercodeindented,\n      codeText: onentercodetext,\n      content: onentercontent,\n      definition: onenterdefinition,\n      definitionDestinationString: onenterdefinitiondestinationstring,\n      definitionLabelString: buffer,\n      definitionTitleString: buffer,\n      emphasis: onenteremphasis,\n      htmlFlow: onenterhtmlflow,\n      htmlText: onenterhtml,\n      image: onenterimage,\n      label: buffer,\n      link: onenterlink,\n      listItemMarker: onenterlistitemmarker,\n      listItemValue: onenterlistitemvalue,\n      listOrdered: onenterlistordered,\n      listUnordered: onenterlistunordered,\n      paragraph: onenterparagraph,\n      reference: buffer,\n      resource: onenterresource,\n      resourceDestinationString: onenterresourcedestinationstring,\n      resourceTitleString: buffer,\n      setextHeading: onentersetextheading,\n      strong: onenterstrong\n    },\n    exit: {\n      atxHeading: onexitatxheading,\n      atxHeadingSequence: onexitatxheadingsequence,\n      autolinkEmail: onexitautolinkemail,\n      autolinkProtocol: onexitautolinkprotocol,\n      blockQuote: onexitblockquote,\n      characterEscapeValue: onexitdata,\n      characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,\n      characterReferenceMarkerNumeric: onexitcharacterreferencemarker,\n      characterReferenceValue: onexitcharacterreferencevalue,\n      codeFenced: onexitflowcode,\n      codeFencedFence: onexitcodefencedfence,\n      codeFencedFenceInfo: onexitcodefencedfenceinfo,\n      codeFencedFenceMeta: resume,\n      codeFlowValue: onexitcodeflowvalue,\n      codeIndented: onexitflowcode,\n      codeText: onexitcodetext,\n      codeTextData: onexitdata,\n      data: onexitdata,\n      definition: onexitdefinition,\n      definitionDestinationString: onexitdefinitiondestinationstring,\n      definitionLabelString: onexitdefinitionlabelstring,\n      definitionTitleString: onexitdefinitiontitlestring,\n      emphasis: onexitemphasis,\n      hardBreakEscape: onexithardbreak,\n      hardBreakTrailing: onexithardbreak,\n      htmlFlow: onexithtml,\n      htmlFlowData: onexitdata,\n      htmlText: onexithtml,\n      htmlTextData: onexitdata,\n      image: onexitmedia,\n      label: onexitlabel,\n      labelText: onexitlabeltext,\n      lineEnding: onexitlineending,\n      link: onexitmedia,\n      listOrdered: onexitlistordered,\n      listUnordered: onexitlistunordered,\n      paragraph: onexitparagraph,\n      reference: resume,\n      referenceString: onexitreferencestring,\n      resource: resume,\n      resourceDestinationString: onexitresourcedestinationstring,\n      resourceTitleString: onexitresourcetitlestring,\n      setextHeading: onexitsetextheading,\n      setextHeadingLineSequence: onexitsetextheadinglinesequence,\n      setextHeadingText: onexitsetextheadingtext,\n      strong: onexitstrong,\n      thematicBreak: onexitthematicbreak\n    }\n  }\n\n  /**\n   * Combine the HTML extensions with the default handlers.\n   * An HTML extension is an object whose fields are either `enter` or `exit`\n   * (reflecting whether a token is entered or exited).\n   * The values at such objects are names of tokens mapping to handlers.\n   * Handlers are called, respectively when a token is opener or closed, with\n   * that token, and a context as `this`.\n   */\n  const handlers = /** @type {NormalizedHtmlExtension} */ (\n    combineHtmlExtensions(\n      [defaultHandlers].concat(settings.htmlExtensions || [])\n    )\n  )\n\n  /**\n   * Handlers do often need to keep track of some state.\n   * That state is provided here as a key-value store (an object).\n   *\n   * @type {CompileData}\n   */\n  const data = {\n    tightStack,\n    definitions\n  }\n\n  /**\n   * The context for handlers references a couple of useful functions.\n   * In handlers from extensions, those can be accessed at `this`.\n   * For the handlers here, they can be accessed directly.\n   *\n   * @type {Omit<CompileContext, 'sliceSerialize'>}\n   */\n  const context = {\n    lineEndingIfNeeded,\n    options: settings,\n    encode,\n    raw,\n    tag,\n    buffer,\n    resume,\n    setData,\n    getData\n  }\n\n  /**\n   * Generally, micromark copies line endings (`'\\r'`, `'\\n'`, `'\\r\\n'`) in the\n   * markdown document over to the compiled HTML.\n   * In some cases, such as `> a`, CommonMark requires that extra line endings\n   * are added: `<blockquote>\\n<p>a</p>\\n</blockquote>`.\n   * This variable hold the default line ending when given (or `undefined`),\n   * and in the latter case will be updated to the first found line ending if\n   * there is one.\n   */\n  let lineEndingStyle = settings.defaultLineEnding\n\n  // Return the function that handles a slice of events.\n  return compile\n\n  /**\n   * Deal w/ a slice of events.\n   * Return either the empty string if there’s nothing of note to return, or the\n   * result when done.\n   *\n   * @param {Array<Event>} events\n   * @returns {string}\n   */\n  function compile(events) {\n    let index = -1\n    let start = 0\n    /** @type {Array<number>} */\n    const listStack = []\n    // As definitions can come after references, we need to figure out the media\n    // (urls and titles) defined by them before handling the references.\n    // So, we do sort of what HTML does: put metadata at the start (in head), and\n    // then put content after (`body`).\n    /** @type {Array<Event>} */\n    let head = []\n    /** @type {Array<Event>} */\n    let body = []\n\n    while (++index < events.length) {\n      // Figure out the line ending style used in the document.\n      if (\n        !lineEndingStyle &&\n        (events[index][1].type === types.lineEnding ||\n          events[index][1].type === types.lineEndingBlank)\n      ) {\n        // @ts-expect-error Hush, it’s a line ending.\n        lineEndingStyle = events[index][2].sliceSerialize(events[index][1])\n      }\n\n      // Preprocess lists to infer whether the list is loose or not.\n      if (\n        events[index][1].type === types.listOrdered ||\n        events[index][1].type === types.listUnordered\n      ) {\n        if (events[index][0] === 'enter') {\n          listStack.push(index)\n        } else {\n          prepareList(events.slice(listStack.pop(), index))\n        }\n      }\n\n      // Move definitions to the front.\n      if (events[index][1].type === types.definition) {\n        if (events[index][0] === 'enter') {\n          body = push(body, events.slice(start, index))\n          start = index\n        } else {\n          head = push(head, events.slice(start, index + 1))\n          start = index + 1\n        }\n      }\n    }\n\n    head = push(head, body)\n    head = push(head, events.slice(start))\n    index = -1\n    const result = head\n\n    // Handle the start of the document, if defined.\n    if (handlers.enter.null) {\n      handlers.enter.null.call(context)\n    }\n\n    // Handle all events.\n    while (++index < events.length) {\n      const handles = handlers[result[index][0]]\n      const kind = result[index][1].type\n      const handle = handles[kind]\n\n      if (hasOwnProperty.call(handles, kind) && handle) {\n        handle.call(\n          Object.assign(\n            {sliceSerialize: result[index][2].sliceSerialize},\n            context\n          ),\n          result[index][1]\n        )\n      }\n    }\n\n    // Handle the end of the document, if defined.\n    if (handlers.exit.null) {\n      handlers.exit.null.call(context)\n    }\n\n    return buffers[0].join('')\n  }\n\n  /**\n   * Figure out whether lists are loose or not.\n   *\n   * @param {Array<Event>} slice\n   * @returns {void}\n   */\n  function prepareList(slice) {\n    const length = slice.length\n    let index = 0 // Skip open.\n    let containerBalance = 0\n    let loose = false\n    /** @type {boolean | undefined} */\n    let atMarker\n\n    while (++index < length) {\n      const event = slice[index]\n\n      if (event[1]._container) {\n        atMarker = undefined\n\n        if (event[0] === 'enter') {\n          containerBalance++\n        } else {\n          containerBalance--\n        }\n      } else\n        switch (event[1].type) {\n          case types.listItemPrefix: {\n            if (event[0] === 'exit') {\n              atMarker = true\n            }\n\n            break\n          }\n\n          case types.linePrefix: {\n            // Ignore\n\n            break\n          }\n\n          case types.lineEndingBlank: {\n            if (event[0] === 'enter' && !containerBalance) {\n              if (atMarker) {\n                atMarker = undefined\n              } else {\n                loose = true\n              }\n            }\n\n            break\n          }\n\n          default: {\n            atMarker = undefined\n          }\n        }\n    }\n\n    slice[0][1]._loose = loose\n  }\n\n  /**\n   * @type {CompileContext['setData']}\n   */\n  function setData(key, value) {\n    // @ts-expect-error: assume `value` is omitted (`undefined` is passed) only\n    // if allowed.\n    data[key] = value\n  }\n\n  /**\n   * @type {CompileContext['getData']}\n   */\n  function getData(key) {\n    return data[key]\n  }\n\n  /** @type {CompileContext['buffer']} */\n  function buffer() {\n    buffers.push([])\n  }\n\n  /** @type {CompileContext['resume']} */\n  function resume() {\n    const buf = buffers.pop()\n    assert(buf !== undefined, 'Cannot resume w/o buffer')\n    return buf.join('')\n  }\n\n  /** @type {CompileContext['tag']} */\n  function tag(value) {\n    if (!tags) return\n    setData('lastWasTag', true)\n    buffers[buffers.length - 1].push(value)\n  }\n\n  /** @type {CompileContext['raw']} */\n  function raw(value) {\n    setData('lastWasTag')\n    buffers[buffers.length - 1].push(value)\n  }\n\n  /**\n   * Output an extra line ending.\n   *\n   * @returns {void}\n   */\n  function lineEnding() {\n    raw(lineEndingStyle || '\\n')\n  }\n\n  /** @type {CompileContext['lineEndingIfNeeded']} */\n  function lineEndingIfNeeded() {\n    const buffer = buffers[buffers.length - 1]\n    const slice = buffer[buffer.length - 1]\n    const previous = slice ? slice.charCodeAt(slice.length - 1) : codes.eof\n\n    if (\n      previous === codes.lf ||\n      previous === codes.cr ||\n      previous === codes.eof\n    ) {\n      return\n    }\n\n    lineEnding()\n  }\n\n  /** @type {CompileContext['encode']} */\n  function encode(value) {\n    return getData('ignoreEncode') ? value : _encode(value)\n  }\n\n  //\n  // Handlers.\n  //\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistordered(token) {\n    tightStack.push(!token._loose)\n    lineEndingIfNeeded()\n    tag('<ol')\n    setData('expectFirstItem', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistunordered(token) {\n    tightStack.push(!token._loose)\n    lineEndingIfNeeded()\n    tag('<ul')\n    setData('expectFirstItem', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistitemvalue(token) {\n    if (getData('expectFirstItem')) {\n      const value = Number.parseInt(\n        this.sliceSerialize(token),\n        constants.numericBaseDecimal\n      )\n\n      if (value !== 1) {\n        tag(' start=\"' + encode(String(value)) + '\"')\n      }\n    }\n  }\n\n  function onenterlistitemmarker() {\n    if (getData('expectFirstItem')) {\n      tag('>')\n    } else {\n      onexitlistitem()\n    }\n\n    lineEndingIfNeeded()\n    tag('<li>')\n    setData('expectFirstItem')\n    // “Hack” to prevent a line ending from showing up if the item is empty.\n    setData('lastWasTag')\n  }\n\n  function onexitlistordered() {\n    onexitlistitem()\n    tightStack.pop()\n    lineEnding()\n    tag('</ol>')\n  }\n\n  function onexitlistunordered() {\n    onexitlistitem()\n    tightStack.pop()\n    lineEnding()\n    tag('</ul>')\n  }\n\n  function onexitlistitem() {\n    if (getData('lastWasTag') && !getData('slurpAllLineEndings')) {\n      lineEndingIfNeeded()\n    }\n\n    tag('</li>')\n    setData('slurpAllLineEndings')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterblockquote() {\n    tightStack.push(false)\n    lineEndingIfNeeded()\n    tag('<blockquote>')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitblockquote() {\n    tightStack.pop()\n    lineEndingIfNeeded()\n    tag('</blockquote>')\n    setData('slurpAllLineEndings')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterparagraph() {\n    if (!tightStack[tightStack.length - 1]) {\n      lineEndingIfNeeded()\n      tag('<p>')\n    }\n\n    setData('slurpAllLineEndings')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitparagraph() {\n    if (tightStack[tightStack.length - 1]) {\n      setData('slurpAllLineEndings', true)\n    } else {\n      tag('</p>')\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentercodefenced() {\n    lineEndingIfNeeded()\n    tag('<pre><code')\n    setData('fencesCount', 0)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfenceinfo() {\n    const value = resume()\n    tag(' class=\"language-' + value + '\"')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfence() {\n    const count = getData('fencesCount') || 0\n\n    if (!count) {\n      tag('>')\n      setData('slurpOneLineEnding', true)\n    }\n\n    setData('fencesCount', count + 1)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentercodeindented() {\n    lineEndingIfNeeded()\n    tag('<pre><code>')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitflowcode() {\n    const count = getData('fencesCount')\n\n    // One special case is if we are inside a container, and the fenced code was\n    // not closed (meaning it runs to the end).\n    // In that case, the following line ending, is considered *outside* the\n    // fenced code and block quote by micromark, but CM wants to treat that\n    // ending as part of the code.\n    if (\n      count !== undefined &&\n      count < 2 &&\n      data.tightStack.length > 0 &&\n      !getData('lastWasTag')\n    ) {\n      lineEnding()\n    }\n\n    // But in most cases, it’s simpler: when we’ve seen some data, emit an extra\n    // line ending when needed.\n    if (getData('flowCodeSeenData')) {\n      lineEndingIfNeeded()\n    }\n\n    tag('</code></pre>')\n    if (count !== undefined && count < 2) lineEndingIfNeeded()\n    setData('flowCodeSeenData')\n    setData('fencesCount')\n    setData('slurpOneLineEnding')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterimage() {\n    mediaStack.push({image: true})\n    tags = undefined // Disallow tags.\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlink() {\n    mediaStack.push({})\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitlabeltext(token) {\n    mediaStack[mediaStack.length - 1].labelId = this.sliceSerialize(token)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitlabel() {\n    mediaStack[mediaStack.length - 1].label = resume()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitreferencestring(token) {\n    mediaStack[mediaStack.length - 1].referenceId = this.sliceSerialize(token)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterresource() {\n    buffer() // We can have line endings in the resource, ignore them.\n    mediaStack[mediaStack.length - 1].destination = ''\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterresourcedestinationstring() {\n    buffer()\n    // Ignore encoding the result, as we’ll first percent encode the url and\n    // encode manually after.\n    setData('ignoreEncode', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitresourcedestinationstring() {\n    mediaStack[mediaStack.length - 1].destination = resume()\n    setData('ignoreEncode')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitresourcetitlestring() {\n    mediaStack[mediaStack.length - 1].title = resume()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitmedia() {\n    let index = mediaStack.length - 1 // Skip current.\n    const media = mediaStack[index]\n    const id = media.referenceId || media.labelId\n    assert(id !== undefined, 'media should have `referenceId` or `labelId`')\n    assert(media.label !== undefined, 'media should have `label`')\n    const context =\n      media.destination === undefined\n        ? definitions[normalizeIdentifier(id)]\n        : media\n\n    tags = true\n\n    while (index--) {\n      if (mediaStack[index].image) {\n        tags = undefined\n        break\n      }\n    }\n\n    if (media.image) {\n      tag(\n        '<img src=\"' +\n          sanitizeUri(\n            context.destination,\n            settings.allowDangerousProtocol ? undefined : protocolSrc\n          ) +\n          '\" alt=\"'\n      )\n      raw(media.label)\n      tag('\"')\n    } else {\n      tag(\n        '<a href=\"' +\n          sanitizeUri(\n            context.destination,\n            settings.allowDangerousProtocol ? undefined : protocolHref\n          ) +\n          '\"'\n      )\n    }\n\n    tag(context.title ? ' title=\"' + context.title + '\"' : '')\n\n    if (media.image) {\n      tag(' />')\n    } else {\n      tag('>')\n      raw(media.label)\n      tag('</a>')\n    }\n\n    mediaStack.pop()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterdefinition() {\n    buffer()\n    mediaStack.push({})\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitionlabelstring(token) {\n    // Discard label, use the source content instead.\n    resume()\n    mediaStack[mediaStack.length - 1].labelId = this.sliceSerialize(token)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterdefinitiondestinationstring() {\n    buffer()\n    setData('ignoreEncode', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiondestinationstring() {\n    mediaStack[mediaStack.length - 1].destination = resume()\n    setData('ignoreEncode')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiontitlestring() {\n    mediaStack[mediaStack.length - 1].title = resume()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinition() {\n    const media = mediaStack[mediaStack.length - 1]\n    assert(media.labelId !== undefined, 'media should have `labelId`')\n    const id = normalizeIdentifier(media.labelId)\n\n    resume()\n\n    if (!hasOwnProperty.call(definitions, id)) {\n      definitions[id] = mediaStack[mediaStack.length - 1]\n    }\n\n    mediaStack.pop()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentercontent() {\n    setData('slurpAllLineEndings', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitatxheadingsequence(token) {\n    // Exit for further sequences.\n    if (getData('headingRank')) return\n    setData('headingRank', this.sliceSerialize(token).length)\n    lineEndingIfNeeded()\n    tag('<h' + getData('headingRank') + '>')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentersetextheading() {\n    buffer()\n    setData('slurpAllLineEndings')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadingtext() {\n    setData('slurpAllLineEndings', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitatxheading() {\n    tag('</h' + getData('headingRank') + '>')\n    setData('headingRank')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadinglinesequence(token) {\n    setData(\n      'headingRank',\n      this.sliceSerialize(token).charCodeAt(0) === codes.equalsTo ? 1 : 2\n    )\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheading() {\n    const value = resume()\n    lineEndingIfNeeded()\n    tag('<h' + getData('headingRank') + '>')\n    raw(value)\n    tag('</h' + getData('headingRank') + '>')\n    setData('slurpAllLineEndings')\n    setData('headingRank')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdata(token) {\n    raw(encode(this.sliceSerialize(token)))\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitlineending(token) {\n    if (getData('slurpAllLineEndings')) {\n      return\n    }\n\n    if (getData('slurpOneLineEnding')) {\n      setData('slurpOneLineEnding')\n      return\n    }\n\n    if (getData('inCodeText')) {\n      raw(' ')\n      return\n    }\n\n    raw(encode(this.sliceSerialize(token)))\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodeflowvalue(token) {\n    raw(encode(this.sliceSerialize(token)))\n    setData('flowCodeSeenData', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexithardbreak() {\n    tag('<br />')\n  }\n\n  function onenterhtmlflow() {\n    lineEndingIfNeeded()\n    onenterhtml()\n  }\n\n  function onexithtml() {\n    setData('ignoreEncode')\n  }\n\n  function onenterhtml() {\n    if (settings.allowDangerousHtml) {\n      setData('ignoreEncode', true)\n    }\n  }\n\n  function onenteremphasis() {\n    tag('<em>')\n  }\n\n  function onenterstrong() {\n    tag('<strong>')\n  }\n\n  function onentercodetext() {\n    setData('inCodeText', true)\n    tag('<code>')\n  }\n\n  function onexitcodetext() {\n    setData('inCodeText')\n    tag('</code>')\n  }\n\n  function onexitemphasis() {\n    tag('</em>')\n  }\n\n  function onexitstrong() {\n    tag('</strong>')\n  }\n\n  function onexitthematicbreak() {\n    lineEndingIfNeeded()\n    tag('<hr />')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @param {Token} token\n   */\n  function onexitcharacterreferencemarker(token) {\n    setData('characterReferenceType', token.type)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcharacterreferencevalue(token) {\n    let value = this.sliceSerialize(token)\n\n    // @ts-expect-error `decodeNamedCharacterReference` can return false for\n    // invalid named character references, but everything we’ve tokenized is\n    // valid.\n    value = getData('characterReferenceType')\n      ? decodeNumericCharacterReference(\n          value,\n          getData('characterReferenceType') ===\n            types.characterReferenceMarkerNumeric\n            ? constants.numericBaseDecimal\n            : constants.numericBaseHexadecimal\n        )\n      : decodeNamedCharacterReference(value)\n\n    raw(encode(value))\n    setData('characterReferenceType')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkprotocol(token) {\n    const uri = this.sliceSerialize(token)\n    tag(\n      '<a href=\"' +\n        sanitizeUri(\n          uri,\n          settings.allowDangerousProtocol ? undefined : protocolHref\n        ) +\n        '\">'\n    )\n    raw(encode(uri))\n    tag('</a>')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkemail(token) {\n    const uri = this.sliceSerialize(token)\n    tag('<a href=\"' + sanitizeUri('mailto:' + uri) + '\">')\n    raw(encode(uri))\n    tag('</a>')\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;CAYC,GAED;;;;;;;;;;;CAWC,GAED;;;;;;;;CAQC;;;;;;;;;;;;;;;;;;;;;;;;;;AAcD,MAAM,iBAAiB,CAAC,EAAE,cAAc;AAExC;;;;;CAKC,GACD,MAAM,eAAe;AACrB,MAAM,cAAc;AAMb,SAAS,QAAQ,OAAO;IAC7B,MAAM,WAAW,WAAW,CAAC;IAE7B;;;;;;;GAOC,GACD,IAAI,OAAO;IAEX;;;;;GAKC,GACD,MAAM,cAAc,CAAC;IAErB;;;;;;;GAOC,GACD,MAAM,UAAU;QAAC,EAAE;KAAC;IAEpB;;;;;GAKC,GACD,MAAM,aAAa,EAAE;IAErB;;;;;GAKC,GACD,MAAM,aAAa,EAAE;IAErB,0BAA0B,GAC1B,MAAM,kBAAkB;QACtB,OAAO;YACL,YAAY;YACZ,YAAY;YACZ,qBAAqB;YACrB,qBAAqB;YACrB,cAAc;YACd,UAAU;YACV,SAAS;YACT,YAAY;YACZ,6BAA6B;YAC7B,uBAAuB;YACvB,uBAAuB;YACvB,UAAU;YACV,UAAU;YACV,UAAU;YACV,OAAO;YACP,OAAO;YACP,MAAM;YACN,gBAAgB;YAChB,eAAe;YACf,aAAa;YACb,eAAe;YACf,WAAW;YACX,WAAW;YACX,UAAU;YACV,2BAA2B;YAC3B,qBAAqB;YACrB,eAAe;YACf,QAAQ;QACV;QACA,MAAM;YACJ,YAAY;YACZ,oBAAoB;YACpB,eAAe;YACf,kBAAkB;YAClB,YAAY;YACZ,sBAAsB;YACtB,qCAAqC;YACrC,iCAAiC;YACjC,yBAAyB;YACzB,YAAY;YACZ,iBAAiB;YACjB,qBAAqB;YACrB,qBAAqB;YACrB,eAAe;YACf,cAAc;YACd,UAAU;YACV,cAAc;YACd,MAAM;YACN,YAAY;YACZ,6BAA6B;YAC7B,uBAAuB;YACvB,uBAAuB;YACvB,UAAU;YACV,iBAAiB;YACjB,mBAAmB;YACnB,UAAU;YACV,cAAc;YACd,UAAU;YACV,cAAc;YACd,OAAO;YACP,OAAO;YACP,WAAW;YACX,YAAY;YACZ,MAAM;YACN,aAAa;YACb,eAAe;YACf,WAAW;YACX,WAAW;YACX,iBAAiB;YACjB,UAAU;YACV,2BAA2B;YAC3B,qBAAqB;YACrB,eAAe;YACf,2BAA2B;YAC3B,mBAAmB;YACnB,QAAQ;YACR,eAAe;QACjB;IACF;IAEA;;;;;;;GAOC,GACD,MAAM,WACJ,6QACE;QAAC;KAAgB,CAAC,MAAM,CAAC,SAAS,cAAc,IAAI,EAAE;IAI1D;;;;;GAKC,GACD,MAAM,OAAO;QACX;QACA;IACF;IAEA;;;;;;GAMC,GACD,MAAM,UAAU;QACd;QACA,SAAS;QACT;QACA;QACA;QACA;QACA;QACA;QACA;IACF;IAEA;;;;;;;;GAQC,GACD,IAAI,kBAAkB,SAAS,iBAAiB;IAEhD,sDAAsD;IACtD,OAAO;IAEP;;;;;;;GAOC,GACD,SAAS,QAAQ,MAAM;QACrB,IAAI,QAAQ,CAAC;QACb,IAAI,QAAQ;QACZ,0BAA0B,GAC1B,MAAM,YAAY,EAAE;QACpB,4EAA4E;QAC5E,oEAAoE;QACpE,6EAA6E;QAC7E,mCAAmC;QACnC,yBAAyB,GACzB,IAAI,OAAO,EAAE;QACb,yBAAyB,GACzB,IAAI,OAAO,EAAE;QAEb,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;YAC9B,yDAAyD;YACzD,IACE,CAAC,mBACD,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,UAAU,IACzC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,eAAe,GACjD;gBACA,6CAA6C;gBAC7C,kBAAkB,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,cAAc,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE;YACpE;YAEA,8DAA8D;YAC9D,IACE,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,WAAW,IAC3C,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,aAAa,EAC7C;gBACA,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,KAAK,SAAS;oBAChC,UAAU,IAAI,CAAC;gBACjB,OAAO;oBACL,YAAY,OAAO,KAAK,CAAC,UAAU,GAAG,IAAI;gBAC5C;YACF;YAEA,iCAAiC;YACjC,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,+NAAM,UAAU,EAAE;gBAC9C,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,KAAK,SAAS;oBAChC,OAAO,uOAAK,MAAM,OAAO,KAAK,CAAC,OAAO;oBACtC,QAAQ;gBACV,OAAO;oBACL,OAAO,uOAAK,MAAM,OAAO,KAAK,CAAC,OAAO,QAAQ;oBAC9C,QAAQ,QAAQ;gBAClB;YACF;QACF;QAEA,OAAO,uOAAK,MAAM;QAClB,OAAO,uOAAK,MAAM,OAAO,KAAK,CAAC;QAC/B,QAAQ,CAAC;QACT,MAAM,SAAS;QAEf,gDAAgD;QAChD,IAAI,SAAS,KAAK,CAAC,IAAI,EAAE;YACvB,SAAS,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC;QAC3B;QAEA,qBAAqB;QACrB,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;YAC9B,MAAM,UAAU,QAAQ,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC;YAC1C,MAAM,OAAO,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI;YAClC,MAAM,SAAS,OAAO,CAAC,KAAK;YAE5B,IAAI,eAAe,IAAI,CAAC,SAAS,SAAS,QAAQ;gBAChD,OAAO,IAAI,CACT,OAAO,MAAM,CACX;oBAAC,gBAAgB,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,cAAc;gBAAA,GAChD,UAEF,MAAM,CAAC,MAAM,CAAC,EAAE;YAEpB;QACF;QAEA,8CAA8C;QAC9C,IAAI,SAAS,IAAI,CAAC,IAAI,EAAE;YACtB,SAAS,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;QAC1B;QAEA,OAAO,OAAO,CAAC,EAAE,CAAC,IAAI,CAAC;IACzB;IAEA;;;;;GAKC,GACD,SAAS,YAAY,KAAK;QACxB,MAAM,SAAS,MAAM,MAAM;QAC3B,IAAI,QAAQ,EAAE,aAAa;;QAC3B,IAAI,mBAAmB;QACvB,IAAI,QAAQ;QACZ,gCAAgC,GAChC,IAAI;QAEJ,MAAO,EAAE,QAAQ,OAAQ;YACvB,MAAM,QAAQ,KAAK,CAAC,MAAM;YAE1B,IAAI,KAAK,CAAC,EAAE,CAAC,UAAU,EAAE;gBACvB,WAAW;gBAEX,IAAI,KAAK,CAAC,EAAE,KAAK,SAAS;oBACxB;gBACF,OAAO;oBACL;gBACF;YACF,OACE,OAAQ,KAAK,CAAC,EAAE,CAAC,IAAI;gBACnB,KAAK,+NAAM,cAAc;oBAAE;wBACzB,IAAI,KAAK,CAAC,EAAE,KAAK,QAAQ;4BACvB,WAAW;wBACb;wBAEA;oBACF;gBAEA,KAAK,+NAAM,UAAU;oBAAE;wBAGrB;oBACF;gBAEA,KAAK,+NAAM,eAAe;oBAAE;wBAC1B,IAAI,KAAK,CAAC,EAAE,KAAK,WAAW,CAAC,kBAAkB;4BAC7C,IAAI,UAAU;gCACZ,WAAW;4BACb,OAAO;gCACL,QAAQ;4BACV;wBACF;wBAEA;oBACF;gBAEA;oBAAS;wBACP,WAAW;oBACb;YACF;QACJ;QAEA,KAAK,CAAC,EAAE,CAAC,EAAE,CAAC,MAAM,GAAG;IACvB;IAEA;;GAEC,GACD,SAAS,QAAQ,GAAG,EAAE,KAAK;QACzB,2EAA2E;QAC3E,cAAc;QACd,IAAI,CAAC,IAAI,GAAG;IACd;IAEA;;GAEC,GACD,SAAS,QAAQ,GAAG;QAClB,OAAO,IAAI,CAAC,IAAI;IAClB;IAEA,qCAAqC,GACrC,SAAS;QACP,QAAQ,IAAI,CAAC,EAAE;IACjB;IAEA,qCAAqC,GACrC,SAAS;QACP,MAAM,MAAM,QAAQ,GAAG;QACvB,uLAAO,QAAQ,WAAW;QAC1B,OAAO,IAAI,IAAI,CAAC;IAClB;IAEA,kCAAkC,GAClC,SAAS,IAAI,KAAK;QAChB,IAAI,CAAC,MAAM;QACX,QAAQ,cAAc;QACtB,OAAO,CAAC,QAAQ,MAAM,GAAG,EAAE,CAAC,IAAI,CAAC;IACnC;IAEA,kCAAkC,GAClC,SAAS,IAAI,KAAK;QAChB,QAAQ;QACR,OAAO,CAAC,QAAQ,MAAM,GAAG,EAAE,CAAC,IAAI,CAAC;IACnC;IAEA;;;;GAIC,GACD,SAAS;QACP,IAAI,mBAAmB;IACzB;IAEA,iDAAiD,GACjD,SAAS;QACP,MAAM,SAAS,OAAO,CAAC,QAAQ,MAAM,GAAG,EAAE;QAC1C,MAAM,QAAQ,MAAM,CAAC,OAAO,MAAM,GAAG,EAAE;QACvC,MAAM,WAAW,QAAQ,MAAM,UAAU,CAAC,MAAM,MAAM,GAAG,KAAK,+NAAM,GAAG;QAEvE,IACE,aAAa,+NAAM,EAAE,IACrB,aAAa,+NAAM,EAAE,IACrB,aAAa,+NAAM,GAAG,EACtB;YACA;QACF;QAEA;IACF;IAEA,qCAAqC,GACrC,SAAS,OAAO,KAAK;QACnB,OAAO,QAAQ,kBAAkB,QAAQ,gOAAQ;IACnD;IAEA,EAAE;IACF,YAAY;IACZ,EAAE;IAEF;;;GAGC,GACD,SAAS,mBAAmB,KAAK;QAC/B,WAAW,IAAI,CAAC,CAAC,MAAM,MAAM;QAC7B;QACA,IAAI;QACJ,QAAQ,mBAAmB;IAC7B;IAEA;;;GAGC,GACD,SAAS,qBAAqB,KAAK;QACjC,WAAW,IAAI,CAAC,CAAC,MAAM,MAAM;QAC7B;QACA,IAAI;QACJ,QAAQ,mBAAmB;IAC7B;IAEA;;;GAGC,GACD,SAAS,qBAAqB,KAAK;QACjC,IAAI,QAAQ,oBAAoB;YAC9B,MAAM,QAAQ,OAAO,QAAQ,CAC3B,IAAI,CAAC,cAAc,CAAC,QACpB,uOAAU,kBAAkB;YAG9B,IAAI,UAAU,GAAG;gBACf,IAAI,aAAa,OAAO,OAAO,UAAU;YAC3C;QACF;IACF;IAEA,SAAS;QACP,IAAI,QAAQ,oBAAoB;YAC9B,IAAI;QACN,OAAO;YACL;QACF;QAEA;QACA,IAAI;QACJ,QAAQ;QACR,wEAAwE;QACxE,QAAQ;IACV;IAEA,SAAS;QACP;QACA,WAAW,GAAG;QACd;QACA,IAAI;IACN;IAEA,SAAS;QACP;QACA,WAAW,GAAG;QACd;QACA,IAAI;IACN;IAEA,SAAS;QACP,IAAI,QAAQ,iBAAiB,CAAC,QAAQ,wBAAwB;YAC5D;QACF;QAEA,IAAI;QACJ,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,WAAW,IAAI,CAAC;QAChB;QACA,IAAI;IACN;IAEA;;;GAGC,GACD,SAAS;QACP,WAAW,GAAG;QACd;QACA,IAAI;QACJ,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,CAAC,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,EAAE;YACtC;YACA,IAAI;QACN;QAEA,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,EAAE;YACrC,QAAQ,uBAAuB;QACjC,OAAO;YACL,IAAI;QACN;IACF;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,IAAI;QACJ,QAAQ,eAAe;IACzB;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ;QACd,IAAI,sBAAsB,QAAQ;IACpC;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ,QAAQ,kBAAkB;QAExC,IAAI,CAAC,OAAO;YACV,IAAI;YACJ,QAAQ,sBAAsB;QAChC;QAEA,QAAQ,eAAe,QAAQ;IACjC;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,IAAI;IACN;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ,QAAQ;QAEtB,4EAA4E;QAC5E,2CAA2C;QAC3C,uEAAuE;QACvE,uEAAuE;QACvE,8BAA8B;QAC9B,IACE,UAAU,aACV,QAAQ,KACR,KAAK,UAAU,CAAC,MAAM,GAAG,KACzB,CAAC,QAAQ,eACT;YACA;QACF;QAEA,4EAA4E;QAC5E,2BAA2B;QAC3B,IAAI,QAAQ,qBAAqB;YAC/B;QACF;QAEA,IAAI;QACJ,IAAI,UAAU,aAAa,QAAQ,GAAG;QACtC,QAAQ;QACR,QAAQ;QACR,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,WAAW,IAAI,CAAC;YAAC,OAAO;QAAI;QAC5B,OAAO,UAAU,iBAAiB;;IACpC;IAEA;;;GAGC,GACD,SAAS;QACP,WAAW,IAAI,CAAC,CAAC;IACnB;IAEA;;;GAGC,GACD,SAAS,gBAAgB,KAAK;QAC5B,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,OAAO,GAAG,IAAI,CAAC,cAAc,CAAC;IAClE;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,KAAK,GAAG;IAC5C;IAEA;;;GAGC,GACD,SAAS,sBAAsB,KAAK;QAClC,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,WAAW,GAAG,IAAI,CAAC,cAAc,CAAC;IACtE;IAEA;;;GAGC,GACD,SAAS;QACP,SAAS,yDAAyD;;QAClE,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,WAAW,GAAG;IAClD;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,wEAAwE;QACxE,yBAAyB;QACzB,QAAQ,gBAAgB;IAC1B;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,WAAW,GAAG;QAChD,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,KAAK,GAAG;IAC5C;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,QAAQ,WAAW,MAAM,GAAG,EAAE,gBAAgB;;QAClD,MAAM,QAAQ,UAAU,CAAC,MAAM;QAC/B,MAAM,KAAK,MAAM,WAAW,IAAI,MAAM,OAAO;QAC7C,uLAAO,OAAO,WAAW;QACzB,uLAAO,MAAM,KAAK,KAAK,WAAW;QAClC,MAAM,UACJ,MAAM,WAAW,KAAK,YAClB,WAAW,CAAC,sRAAoB,IAAI,GACpC;QAEN,OAAO;QAEP,MAAO,QAAS;YACd,IAAI,UAAU,CAAC,MAAM,CAAC,KAAK,EAAE;gBAC3B,OAAO;gBACP;YACF;QACF;QAEA,IAAI,MAAM,KAAK,EAAE;YACf,IACE,eACE,8PACE,QAAQ,WAAW,EACnB,SAAS,sBAAsB,GAAG,YAAY,eAEhD;YAEJ,IAAI,MAAM,KAAK;YACf,IAAI;QACN,OAAO;YACL,IACE,cACE,8PACE,QAAQ,WAAW,EACnB,SAAS,sBAAsB,GAAG,YAAY,gBAEhD;QAEN;QAEA,IAAI,QAAQ,KAAK,GAAG,aAAa,QAAQ,KAAK,GAAG,MAAM;QAEvD,IAAI,MAAM,KAAK,EAAE;YACf,IAAI;QACN,OAAO;YACL,IAAI;YACJ,IAAI,MAAM,KAAK;YACf,IAAI;QACN;QAEA,WAAW,GAAG;IAChB;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,WAAW,IAAI,CAAC,CAAC;IACnB;IAEA;;;GAGC,GACD,SAAS,4BAA4B,KAAK;QACxC,iDAAiD;QACjD;QACA,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,OAAO,GAAG,IAAI,CAAC,cAAc,CAAC;IAClE;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,QAAQ,gBAAgB;IAC1B;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,WAAW,GAAG;QAChD,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,KAAK,GAAG;IAC5C;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE;QAC/C,uLAAO,MAAM,OAAO,KAAK,WAAW;QACpC,MAAM,KAAK,sRAAoB,MAAM,OAAO;QAE5C;QAEA,IAAI,CAAC,eAAe,IAAI,CAAC,aAAa,KAAK;YACzC,WAAW,CAAC,GAAG,GAAG,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE;QACrD;QAEA,WAAW,GAAG;IAChB;IAEA;;;GAGC,GACD,SAAS;QACP,QAAQ,uBAAuB;IACjC;IAEA;;;GAGC,GACD,SAAS,yBAAyB,KAAK;QACrC,8BAA8B;QAC9B,IAAI,QAAQ,gBAAgB;QAC5B,QAAQ,eAAe,IAAI,CAAC,cAAc,CAAC,OAAO,MAAM;QACxD;QACA,IAAI,OAAO,QAAQ,iBAAiB;IACtC;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,QAAQ,uBAAuB;IACjC;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,QAAQ,QAAQ,iBAAiB;QACrC,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS,gCAAgC,KAAK;QAC5C,QACE,eACA,IAAI,CAAC,cAAc,CAAC,OAAO,UAAU,CAAC,OAAO,+NAAM,QAAQ,GAAG,IAAI;IAEtE;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ;QACd;QACA,IAAI,OAAO,QAAQ,iBAAiB;QACpC,IAAI;QACJ,IAAI,QAAQ,QAAQ,iBAAiB;QACrC,QAAQ;QACR,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS,WAAW,KAAK;QACvB,IAAI,OAAO,IAAI,CAAC,cAAc,CAAC;IACjC;IAEA;;;GAGC,GACD,SAAS,iBAAiB,KAAK;QAC7B,IAAI,QAAQ,wBAAwB;YAClC;QACF;QAEA,IAAI,QAAQ,uBAAuB;YACjC,QAAQ;YACR;QACF;QAEA,IAAI,QAAQ,eAAe;YACzB,IAAI;YACJ;QACF;QAEA,IAAI,OAAO,IAAI,CAAC,cAAc,CAAC;IACjC;IAEA;;;GAGC,GACD,SAAS,oBAAoB,KAAK;QAChC,IAAI,OAAO,IAAI,CAAC,cAAc,CAAC;QAC/B,QAAQ,oBAAoB;IAC9B;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI;IACN;IAEA,SAAS;QACP;QACA;IACF;IAEA,SAAS;QACP,QAAQ;IACV;IAEA,SAAS;QACP,IAAI,SAAS,kBAAkB,EAAE;YAC/B,QAAQ,gBAAgB;QAC1B;IACF;IAEA,SAAS;QACP,IAAI;IACN;IAEA,SAAS;QACP,IAAI;IACN;IAEA,SAAS;QACP,QAAQ,cAAc;QACtB,IAAI;IACN;IAEA,SAAS;QACP,QAAQ;QACR,IAAI;IACN;IAEA,SAAS;QACP,IAAI;IACN;IAEA,SAAS;QACP,IAAI;IACN;IAEA,SAAS;QACP;QACA,IAAI;IACN;IAEA;;;GAGC,GACD,SAAS,+BAA+B,KAAK;QAC3C,QAAQ,0BAA0B,MAAM,IAAI;IAC9C;IAEA;;;GAGC,GACD,SAAS,8BAA8B,KAAK;QAC1C,IAAI,QAAQ,IAAI,CAAC,cAAc,CAAC;QAEhC,wEAAwE;QACxE,wEAAwE;QACxE,SAAS;QACT,QAAQ,QAAQ,4BACZ,0UACE,OACA,QAAQ,8BACN,+NAAM,+BAA+B,GACnC,uOAAU,kBAAkB,GAC5B,uOAAU,sBAAsB,IAEtC,mRAA8B;QAElC,IAAI,OAAO;QACX,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS,uBAAuB,KAAK;QACnC,MAAM,MAAM,IAAI,CAAC,cAAc,CAAC;QAChC,IACE,cACE,8PACE,KACA,SAAS,sBAAsB,GAAG,YAAY,gBAEhD;QAEJ,IAAI,OAAO;QACX,IAAI;IACN;IAEA;;;GAGC,GACD,SAAS,oBAAoB,KAAK;QAChC,MAAM,MAAM,IAAI,CAAC,cAAc,CAAC;QAChC,IAAI,cAAc,8PAAY,YAAY,OAAO;QACjD,IAAI,OAAO;QACX,IAAI;IACN;AACF"}},
    {"offset": {"line": 3697, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3702, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@3.2.0/node_modules/micromark/dev/index.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Options} Options\n * @typedef {import('micromark-util-types').Value} Value\n */\n\nimport {compile} from './lib/compile.js'\nimport {parse} from './lib/parse.js'\nimport {postprocess} from './lib/postprocess.js'\nimport {preprocess} from './lib/preprocess.js'\n\n/**\n * Compile markdown to HTML.\n *\n * @overload\n * @param {Value} value\n *   Markdown to parse (`string` or `Buffer`).\n * @param {Encoding | null | undefined} encoding\n *   Character encoding to understand `value` as when it’s a `Buffer`\n *   (`string`, default: `'utf8'`).\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {string}\n *   Compiled HTML.\n *\n * @overload\n * @param {Value} value\n *   Markdown to parse (`string` or `Buffer`).\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {string}\n *   Compiled HTML.\n *\n * @param {Value} value\n *   Markdown to parse (`string` or `Buffer`).\n * @param {Options | Encoding | null | undefined} [encoding]\n *   Character encoding to understand `value` as when it’s a `Buffer`\n *   (`string`, default: `'utf8'`).\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {string}\n *   Compiled HTML.\n */\nexport function micromark(value, encoding, options) {\n  if (typeof encoding !== 'string') {\n    options = encoding\n    encoding = undefined\n  }\n\n  return compile(options)(\n    postprocess(\n      parse(options).document().write(preprocess()(value, encoding, true))\n    )\n  )\n}\n"],"names":[],"mappings":"AAAA;;;;CAIC;;;;;;;;;;;;AAuCM,SAAS,UAAU,KAAK,EAAE,QAAQ,EAAE,OAAO;IAChD,IAAI,OAAO,aAAa,UAAU;QAChC,UAAU;QACV,WAAW;IACb;IAEA,OAAO,6MAAQ,SACb,qNACE,yMAAM,SAAS,QAAQ,GAAG,KAAK,CAAC,qNAAa,OAAO,UAAU;AAGpE"}},
    {"offset": {"line": 3725, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3730, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/preprocess.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Value} Value\n */\n\n/**\n * @callback Preprocessor\n * @param {Value} value\n * @param {Encoding | null | undefined} [encoding]\n * @param {boolean | null | undefined} [end=false]\n * @returns {Array<Chunk>}\n */\n\nimport {codes, constants} from 'micromark-util-symbol'\n\nconst search = /[\\0\\t\\n\\r]/g\n\n/**\n * @returns {Preprocessor}\n */\nexport function preprocess() {\n  let column = 1\n  let buffer = ''\n  /** @type {boolean | undefined} */\n  let start = true\n  /** @type {boolean | undefined} */\n  let atCarriageReturn\n\n  return preprocessor\n\n  /** @type {Preprocessor} */\n  // eslint-disable-next-line complexity\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = []\n    /** @type {RegExpMatchArray | null} */\n    let match\n    /** @type {number} */\n    let next\n    /** @type {number} */\n    let startPosition\n    /** @type {number} */\n    let endPosition\n    /** @type {Code} */\n    let code\n\n    value =\n      buffer +\n      (typeof value === 'string'\n        ? value.toString()\n        : new TextDecoder(encoding || undefined).decode(value))\n\n    startPosition = 0\n    buffer = ''\n\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === codes.byteOrderMarker) {\n        startPosition++\n      }\n\n      start = undefined\n    }\n\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition =\n        match && match.index !== undefined ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n\n      if (\n        code === codes.lf &&\n        startPosition === endPosition &&\n        atCarriageReturn\n      ) {\n        chunks.push(codes.carriageReturnLineFeed)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(codes.carriageReturn)\n          atCarriageReturn = undefined\n        }\n\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n\n        switch (code) {\n          case codes.nul: {\n            chunks.push(codes.replacementCharacter)\n            column++\n\n            break\n          }\n\n          case codes.ht: {\n            next = Math.ceil(column / constants.tabSize) * constants.tabSize\n            chunks.push(codes.horizontalTab)\n            while (column++ < next) chunks.push(codes.virtualSpace)\n\n            break\n          }\n\n          case codes.lf: {\n            chunks.push(codes.lineFeed)\n            column = 1\n\n            break\n          }\n\n          default: {\n            atCarriageReturn = true\n            column = 1\n          }\n        }\n      }\n\n      startPosition = endPosition + 1\n    }\n\n    if (end) {\n      if (atCarriageReturn) chunks.push(codes.carriageReturn)\n      if (buffer) chunks.push(buffer)\n      chunks.push(codes.eof)\n    }\n\n    return chunks\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;CAKC,GAED;;;;;;CAMC;;;;;;AAID,MAAM,SAAS;AAKR,SAAS;IACd,IAAI,SAAS;IACb,IAAI,SAAS;IACb,gCAAgC,GAChC,IAAI,QAAQ;IACZ,gCAAgC,GAChC,IAAI;IAEJ,OAAO;IAEP,yBAAyB,GACzB,sCAAsC;IACtC,SAAS,aAAa,KAAK,EAAE,QAAQ,EAAE,GAAG;QACxC,yBAAyB,GACzB,MAAM,SAAS,EAAE;QACjB,oCAAoC,GACpC,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,mBAAmB,GACnB,IAAI;QACJ,iBAAiB,GACjB,IAAI;QAEJ,QACE,SACA,CAAC,OAAO,UAAU,WACd,MAAM,QAAQ,KACd,IAAI,YAAY,YAAY,WAAW,MAAM,CAAC,MAAM;QAE1D,gBAAgB;QAChB,SAAS;QAET,IAAI,OAAO;YACT,+DAA+D;YAC/D,IAAI,MAAM,UAAU,CAAC,OAAO,wOAAM,eAAe,EAAE;gBACjD;YACF;YAEA,QAAQ;QACV;QAEA,MAAO,gBAAgB,MAAM,MAAM,CAAE;YACnC,OAAO,SAAS,GAAG;YACnB,QAAQ,OAAO,IAAI,CAAC;YACpB,cACE,SAAS,MAAM,KAAK,KAAK,YAAY,MAAM,KAAK,GAAG,MAAM,MAAM;YACjE,OAAO,MAAM,UAAU,CAAC;YAExB,IAAI,CAAC,OAAO;gBACV,SAAS,MAAM,KAAK,CAAC;gBACrB;YACF;YAEA,IACE,SAAS,wOAAM,EAAE,IACjB,kBAAkB,eAClB,kBACA;gBACA,OAAO,IAAI,CAAC,wOAAM,sBAAsB;gBACxC,mBAAmB;YACrB,OAAO;gBACL,IAAI,kBAAkB;oBACpB,OAAO,IAAI,CAAC,wOAAM,cAAc;oBAChC,mBAAmB;gBACrB;gBAEA,IAAI,gBAAgB,aAAa;oBAC/B,OAAO,IAAI,CAAC,MAAM,KAAK,CAAC,eAAe;oBACvC,UAAU,cAAc;gBAC1B;gBAEA,OAAQ;oBACN,KAAK,wOAAM,GAAG;wBAAE;4BACd,OAAO,IAAI,CAAC,wOAAM,oBAAoB;4BACtC;4BAEA;wBACF;oBAEA,KAAK,wOAAM,EAAE;wBAAE;4BACb,OAAO,KAAK,IAAI,CAAC,SAAS,4OAAU,OAAO,IAAI,4OAAU,OAAO;4BAChE,OAAO,IAAI,CAAC,wOAAM,aAAa;4BAC/B,MAAO,WAAW,KAAM,OAAO,IAAI,CAAC,wOAAM,YAAY;4BAEtD;wBACF;oBAEA,KAAK,wOAAM,EAAE;wBAAE;4BACb,OAAO,IAAI,CAAC,wOAAM,QAAQ;4BAC1B,SAAS;4BAET;wBACF;oBAEA;wBAAS;4BACP,mBAAmB;4BACnB,SAAS;wBACX;gBACF;YACF;YAEA,gBAAgB,cAAc;QAChC;QAEA,IAAI,KAAK;YACP,IAAI,kBAAkB,OAAO,IAAI,CAAC,wOAAM,cAAc;YACtD,IAAI,QAAQ,OAAO,IAAI,CAAC;YACxB,OAAO,IAAI,CAAC,wOAAM,GAAG;QACvB;QAEA,OAAO;IACT;AACF"}},
    {"offset": {"line": 3830, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3835, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/postprocess.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Event} Event\n */\n\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * @param {Array<Event>} events\n * @returns {Array<Event>}\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n\n  return events\n}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;AAQM,SAAS,YAAY,MAAM;IAChC,MAAO,CAAC,sPAAY,QAAS;IAC3B,QAAQ;IACV;IAEA,OAAO;AACT"}},
    {"offset": {"line": 3849, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3854, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/initialize/text.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {codes, constants, types} from 'micromark-util-symbol'\nimport {ok as assert} from 'devlop'\n\nexport const resolver = {resolveAll: createResolver()}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n\n/**\n * @param {'string' | 'text'} field\n * @returns {InitialConstruct}\n */\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n\n  /**\n   * @this {TokenizeContext}\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n\n    return start\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === codes.eof) {\n        effects.consume(code)\n        return\n      }\n\n      effects.enter(types.data)\n      effects.consume(code)\n      return data\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit(types.data)\n        return text(code)\n      }\n\n      // Data.\n      effects.consume(code)\n      return data\n    }\n\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n    function atBreak(code) {\n      if (code === codes.eof) {\n        return true\n      }\n\n      const list = constructs[code]\n      let index = -1\n\n      if (list) {\n        // Always populated by defaults.\n        assert(Array.isArray(list), 'expected `disable.null` to be populated')\n\n        while (++index < list.length) {\n          const item = list[index]\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n\n      return false\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n * @returns {Resolver}\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number | undefined} */\n    let enter\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === types.data) {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== types.data) {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n\n        enter = undefined\n      }\n    }\n\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0 // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === types.lineEnding) &&\n      events[eventIndex - 1][1].type === types.data\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean | undefined} */\n      let tabs\n\n      while (index--) {\n        const chunk = chunks[index]\n\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n\n          while (chunk.charCodeAt(bufferIndex - 1) === codes.space) {\n            size++\n            bufferIndex--\n          }\n\n          if (bufferIndex) break\n          bufferIndex = -1\n        }\n        // Number\n        else if (chunk === codes.horizontalTab) {\n          tabs = true\n          size++\n        } else if (chunk === codes.virtualSpace) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length ||\n            tabs ||\n            size < constants.hardBreakPrefixSizeMin\n              ? types.lineSuffix\n              : types.hardBreakTrailing,\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        }\n\n        data.end = Object.assign({}, token.start)\n\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n\n      eventIndex++\n    }\n  }\n\n  return events\n}\n"],"names":[],"mappings":"AAAA;;;;;;;CAOC;;;;;;;;;;AAKM,MAAM,WAAW;IAAC,YAAY;AAAgB;AAC9C,MAAM,SAAS,kBAAkB;AACjC,MAAM,OAAO,kBAAkB;AAEtC;;;CAGC,GACD,SAAS,kBAAkB,KAAK;IAC9B,OAAO;QACL,UAAU;QACV,YAAY,eACV,UAAU,SAAS,yBAAyB;IAEhD;IAEA;;;GAGC,GACD,SAAS,eAAe,OAAO;QAC7B,MAAM,OAAO,IAAI;QACjB,MAAM,aAAa,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,MAAM;QAChD,MAAM,OAAO,QAAQ,OAAO,CAAC,YAAY,OAAO;QAEhD,OAAO;QAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;YACjB,OAAO,QAAQ,QAAQ,KAAK,QAAQ,QAAQ;QAC9C;QAEA,kBAAkB,GAClB,SAAS,QAAQ,IAAI;YACnB,IAAI,SAAS,wOAAM,GAAG,EAAE;gBACtB,QAAQ,OAAO,CAAC;gBAChB;YACF;YAEA,QAAQ,KAAK,CAAC,wOAAM,IAAI;YACxB,QAAQ,OAAO,CAAC;YAChB,OAAO;QACT;QAEA,kBAAkB,GAClB,SAAS,KAAK,IAAI;YAChB,IAAI,QAAQ,OAAO;gBACjB,QAAQ,IAAI,CAAC,wOAAM,IAAI;gBACvB,OAAO,KAAK;YACd;YAEA,QAAQ;YACR,QAAQ,OAAO,CAAC;YAChB,OAAO;QACT;QAEA;;;KAGC,GACD,SAAS,QAAQ,IAAI;YACnB,IAAI,SAAS,wOAAM,GAAG,EAAE;gBACtB,OAAO;YACT;YAEA,MAAM,OAAO,UAAU,CAAC,KAAK;YAC7B,IAAI,QAAQ,CAAC;YAEb,IAAI,MAAM;gBACR,gCAAgC;gBAChC,+LAAO,MAAM,OAAO,CAAC,OAAO;gBAE5B,MAAO,EAAE,QAAQ,KAAK,MAAM,CAAE;oBAC5B,MAAM,OAAO,IAAI,CAAC,MAAM;oBACxB,IAAI,CAAC,KAAK,QAAQ,IAAI,KAAK,QAAQ,CAAC,IAAI,CAAC,MAAM,KAAK,QAAQ,GAAG;wBAC7D,OAAO;oBACT;gBACF;YACF;YAEA,OAAO;QACT;IACF;AACF;AAEA;;;CAGC,GACD,SAAS,eAAe,aAAa;IACnC,OAAO;IAEP,qBAAqB,GACrB,SAAS,eAAe,MAAM,EAAE,OAAO;QACrC,IAAI,QAAQ,CAAC;QACb,+BAA+B,GAC/B,IAAI;QAEJ,sEAAsE;QACtE,kCAAkC;QAClC,MAAO,EAAE,SAAS,OAAO,MAAM,CAAE;YAC/B,IAAI,UAAU,WAAW;gBACvB,IAAI,MAAM,CAAC,MAAM,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,IAAI,EAAE;oBACzD,QAAQ;oBACR;gBACF;YACF,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,IAAI,EAAE;gBACjE,gDAAgD;gBAChD,IAAI,UAAU,QAAQ,GAAG;oBACvB,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,MAAM,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,GAAG;oBAC/C,OAAO,MAAM,CAAC,QAAQ,GAAG,QAAQ,QAAQ;oBACzC,QAAQ,QAAQ;gBAClB;gBAEA,QAAQ;YACV;QACF;QAEA,OAAO,gBAAgB,cAAc,QAAQ,WAAW;IAC1D;AACF;AAEA;;;;;;;;;;CAUC,GACD,SAAS,uBAAuB,MAAM,EAAE,OAAO;IAC7C,IAAI,aAAa,EAAE,cAAc;;IAEjC,MAAO,EAAE,cAAc,OAAO,MAAM,CAAE;QACpC,IACE,CAAC,eAAe,OAAO,MAAM,IAC3B,MAAM,CAAC,WAAW,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,UAAU,KACjD,MAAM,CAAC,aAAa,EAAE,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,IAAI,EAC7C;YACA,MAAM,OAAO,MAAM,CAAC,aAAa,EAAE,CAAC,EAAE;YACtC,MAAM,SAAS,QAAQ,WAAW,CAAC;YACnC,IAAI,QAAQ,OAAO,MAAM;YACzB,IAAI,cAAc,CAAC;YACnB,IAAI,OAAO;YACX,gCAAgC,GAChC,IAAI;YAEJ,MAAO,QAAS;gBACd,MAAM,QAAQ,MAAM,CAAC,MAAM;gBAE3B,IAAI,OAAO,UAAU,UAAU;oBAC7B,cAAc,MAAM,MAAM;oBAE1B,MAAO,MAAM,UAAU,CAAC,cAAc,OAAO,wOAAM,KAAK,CAAE;wBACxD;wBACA;oBACF;oBAEA,IAAI,aAAa;oBACjB,cAAc,CAAC;gBACjB,OAEK,IAAI,UAAU,wOAAM,aAAa,EAAE;oBACtC,OAAO;oBACP;gBACF,OAAO,IAAI,UAAU,wOAAM,YAAY,EAAE;gBACvC,QAAQ;gBACV,OAAO;oBACL,+BAA+B;oBAC/B;oBACA;gBACF;YACF;YAEA,IAAI,MAAM;gBACR,MAAM,QAAQ;oBACZ,MACE,eAAe,OAAO,MAAM,IAC5B,QACA,OAAO,4OAAU,sBAAsB,GACnC,wOAAM,UAAU,GAChB,wOAAM,iBAAiB;oBAC7B,OAAO;wBACL,MAAM,KAAK,GAAG,CAAC,IAAI;wBACnB,QAAQ,KAAK,GAAG,CAAC,MAAM,GAAG;wBAC1B,QAAQ,KAAK,GAAG,CAAC,MAAM,GAAG;wBAC1B,QAAQ,KAAK,KAAK,CAAC,MAAM,GAAG;wBAC5B,cAAc,QACV,cACA,KAAK,KAAK,CAAC,YAAY,GAAG;oBAChC;oBACA,KAAK,OAAO,MAAM,CAAC,CAAC,GAAG,KAAK,GAAG;gBACjC;gBAEA,KAAK,GAAG,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG,MAAM,KAAK;gBAExC,IAAI,KAAK,KAAK,CAAC,MAAM,KAAK,KAAK,GAAG,CAAC,MAAM,EAAE;oBACzC,OAAO,MAAM,CAAC,MAAM;gBACtB,OAAO;oBACL,OAAO,MAAM,CACX,YACA,GACA;wBAAC;wBAAS;wBAAO;qBAAQ,EACzB;wBAAC;wBAAQ;wBAAO;qBAAQ;oBAE1B,cAAc;gBAChB;YACF;YAEA;QACF;IACF;IAEA,OAAO;AACT"}},
    {"offset": {"line": 4040, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4045, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/constructs.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Extension} Extension\n */\n\nimport {\n  attention,\n  autolink,\n  blockQuote,\n  characterEscape,\n  characterReference,\n  codeFenced,\n  codeIndented,\n  codeText,\n  definition,\n  hardBreakEscape,\n  headingAtx,\n  htmlFlow,\n  htmlText,\n  labelEnd,\n  labelStartImage,\n  labelStartLink,\n  lineEnding,\n  list,\n  setextUnderline,\n  thematicBreak\n} from 'micromark-core-commonmark'\nimport {codes} from 'micromark-util-symbol'\nimport {resolver as resolveText} from './initialize/text.js'\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [codes.asterisk]: list,\n  [codes.plusSign]: list,\n  [codes.dash]: list,\n  [codes.digit0]: list,\n  [codes.digit1]: list,\n  [codes.digit2]: list,\n  [codes.digit3]: list,\n  [codes.digit4]: list,\n  [codes.digit5]: list,\n  [codes.digit6]: list,\n  [codes.digit7]: list,\n  [codes.digit8]: list,\n  [codes.digit9]: list,\n  [codes.greaterThan]: blockQuote\n}\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [codes.leftSquareBracket]: definition\n}\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [codes.horizontalTab]: codeIndented,\n  [codes.virtualSpace]: codeIndented,\n  [codes.space]: codeIndented\n}\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [codes.numberSign]: headingAtx,\n  [codes.asterisk]: thematicBreak,\n  [codes.dash]: [setextUnderline, thematicBreak],\n  [codes.lessThan]: htmlFlow,\n  [codes.equalsTo]: setextUnderline,\n  [codes.underscore]: thematicBreak,\n  [codes.graveAccent]: codeFenced,\n  [codes.tilde]: codeFenced\n}\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [codes.ampersand]: characterReference,\n  [codes.backslash]: characterEscape\n}\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [codes.carriageReturn]: lineEnding,\n  [codes.lineFeed]: lineEnding,\n  [codes.carriageReturnLineFeed]: lineEnding,\n  [codes.exclamationMark]: labelStartImage,\n  [codes.ampersand]: characterReference,\n  [codes.asterisk]: attention,\n  [codes.lessThan]: [autolink, htmlText],\n  [codes.leftSquareBracket]: labelStartLink,\n  [codes.backslash]: [hardBreakEscape, characterEscape],\n  [codes.rightSquareBracket]: labelEnd,\n  [codes.underscore]: attention,\n  [codes.graveAccent]: codeText\n}\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {null: [attention, resolveText]}\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {null: [codes.asterisk, codes.underscore]}\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {null: []}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;;;;;;;;;;;;;AA4BM,MAAM,WAAW;IACtB,CAAC,wOAAM,QAAQ,CAAC;IAChB,CAAC,wOAAM,QAAQ,CAAC;IAChB,CAAC,wOAAM,IAAI,CAAC;IACZ,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,MAAM,CAAC;IACd,CAAC,wOAAM,WAAW,CAAC;AACrB;AAGO,MAAM,iBAAiB;IAC5B,CAAC,wOAAM,iBAAiB,CAAC;AAC3B;AAGO,MAAM,cAAc;IACzB,CAAC,wOAAM,aAAa,CAAC;IACrB,CAAC,wOAAM,YAAY,CAAC;IACpB,CAAC,wOAAM,KAAK,CAAC;AACf;AAGO,MAAM,OAAO;IAClB,CAAC,wOAAM,UAAU,CAAC;IAClB,CAAC,wOAAM,QAAQ,CAAC;IAChB,CAAC,wOAAM,IAAI,CAAC,EAAE;;;KAAgC;IAC9C,CAAC,wOAAM,QAAQ,CAAC;IAChB,CAAC,wOAAM,QAAQ,CAAC;IAChB,CAAC,wOAAM,UAAU,CAAC;IAClB,CAAC,wOAAM,WAAW,CAAC;IACnB,CAAC,wOAAM,KAAK,CAAC;AACf;AAGO,MAAM,SAAS;IACpB,CAAC,wOAAM,SAAS,CAAC;IACjB,CAAC,wOAAM,SAAS,CAAC;AACnB;AAGO,MAAM,OAAO;IAClB,CAAC,wOAAM,cAAc,CAAC;IACtB,CAAC,wOAAM,QAAQ,CAAC;IAChB,CAAC,wOAAM,sBAAsB,CAAC;IAC9B,CAAC,wOAAM,eAAe,CAAC;IACvB,CAAC,wOAAM,SAAS,CAAC;IACjB,CAAC,wOAAM,QAAQ,CAAC;IAChB,CAAC,wOAAM,QAAQ,CAAC,EAAE;;;KAAoB;IACtC,CAAC,wOAAM,iBAAiB,CAAC;IACzB,CAAC,wOAAM,SAAS,CAAC,EAAE;;;KAAkC;IACrD,CAAC,wOAAM,kBAAkB,CAAC;IAC1B,CAAC,wOAAM,UAAU,CAAC;IAClB,CAAC,wOAAM,WAAW,CAAC;AACrB;AAGO,MAAM,aAAa;IAAC,MAAM;;;KAAwB;AAAA;AAGlD,MAAM,mBAAmB;IAAC,MAAM;QAAC,wOAAM,QAAQ;QAAE,wOAAM,UAAU;KAAC;AAAA;AAGlE,MAAM,UAAU;IAAC,MAAM,EAAE;AAAA"}},
    {"offset": {"line": 4141, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4146, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/create-tokenizer.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenType} TokenType\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\n/**\n * @callback Restore\n * @returns {undefined}\n *\n * @typedef Info\n * @property {Restore} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {undefined}\n */\n\nimport createDebug from 'debug'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\nimport {codes, values} from 'micromark-util-symbol'\nimport {ok as assert} from 'devlop'\n\nconst debug = createDebug('micromark')\n\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(\n    from ? Object.assign({}, from) : {line: 1, column: 1, offset: 0},\n    {_index: 0, _bufferIndex: -1}\n  )\n  /** @type {Record<string, number>} */\n  const columnStart = {}\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = []\n  /** @type {Array<Chunk>} */\n  let chunks = []\n  /** @type {Array<Token>} */\n  let stack = []\n  /** @type {boolean | undefined} */\n  let consumed = true\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {interrupt: true})\n  }\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    previous: codes.eof,\n    code: codes.eof,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  }\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  let state = initialize.tokenize.call(context, effects)\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n\n  return context\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice)\n\n    main()\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== codes.eof) {\n      return []\n    }\n\n    addResult(initialize, 0)\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n\n    return context.events\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {line, column, offset, _index, _bufferIndex} = point\n    return {line, column, offset, _index, _bufferIndex}\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n    debug('position: define skip: `%j`', point)\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index]\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {undefined}\n   */\n  function go(code) {\n    assert(consumed === true, 'expected character to be consumed')\n    consumed = undefined\n    debug('main: passing `%s` to %s', code, state && state.name)\n    expectedCode = code\n    assert(typeof state === 'function', 'expected state')\n    state = state(code)\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    assert(code === expectedCode, 'expected given code to equal expected code')\n\n    debug('consume: `%s`', code)\n\n    assert(\n      consumed === undefined,\n      'expected code to not have been consumed: this might be because `return x(code)` instead of `return x` was used'\n    )\n    assert(\n      code === null\n        ? context.events.length === 0 ||\n            context.events[context.events.length - 1][0] === 'exit'\n        : context.events[context.events.length - 1][0] === 'enter',\n      'expected last token to be open'\n    )\n\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === codes.carriageReturnLineFeed ? 2 : 1\n      accountForPotentialSkip()\n      debug('position: after eol: `%j`', point)\n    } else if (code !== codes.virtualSpace) {\n      point.column++\n      point.offset++\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++\n\n      // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code\n\n    // Mark as consumed.\n    consumed = true\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n\n    assert(typeof type === 'string', 'expected string type')\n    assert(type.length > 0, 'expected non-empty string')\n    debug('enter: `%s`', type)\n\n    context.events.push(['enter', token, context])\n\n    stack.push(token)\n\n    return token\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    assert(typeof type === 'string', 'expected string type')\n    assert(type.length > 0, 'expected non-empty string')\n\n    const token = stack.pop()\n    assert(token, 'cannot close w/o open tokens')\n    token.end = now()\n\n    assert(type === token.type, 'expected exit token to match current token')\n\n    assert(\n      !(\n        token.start._index === token.end._index &&\n        token.start._bufferIndex === token.end._bufferIndex\n      ),\n      'expected non-empty token (`' + type + '`)'\n    )\n\n    debug('exit: `%s`', token.type)\n    context.events.push(['exit', token, context])\n\n    return token\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   */\n  function constructFactory(onreturn, fields) {\n    return hook\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | Construct | ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State | undefined} [bogusState]\n     * @returns {State}\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Array<Construct>} */\n      let listOfConstructs\n      /** @type {number} */\n      let constructIndex\n      /** @type {Construct} */\n      let currentConstruct\n      /** @type {Info} */\n      let info\n\n      return Array.isArray(constructs)\n        ? /* c8 ignore next 1 */\n          handleListOfConstructs(constructs)\n        : 'tokenize' in constructs\n        ? // @ts-expect-error Looks like a construct.\n          handleListOfConstructs([constructs])\n        : handleMapOfConstructs(constructs)\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n      function handleMapOfConstructs(map) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          const def = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n            /* c8 ignore next 2 */\n            ...(Array.isArray(def) ? def : def ? [def] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n\n          return handleListOfConstructs(list)(code)\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Array<Construct>} list\n       * @returns {State}\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n\n        if (list.length === 0) {\n          assert(bogusState, 'expected `bogusState` to be given')\n          return bogusState\n        }\n\n        return handleConstruct(list[constructIndex])\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n      function handleConstruct(construct) {\n        return start\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          // Always populated by defaults.\n          assert(\n            context.parser.constructs.disable.null,\n            'expected `disable.null` to be populated'\n          )\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a “live binding”, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        assert(code === expectedCode, 'expected code')\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        assert(code === expectedCode, 'expected code')\n        consumed = true\n        info.restore()\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n\n        return bogusState\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {undefined}\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n\n    assert(\n      construct.partial ||\n        context.events.length === 0 ||\n        context.events[context.events.length - 1][0] === 'exit',\n      'expected last token to end'\n    )\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n\n    return {restore, from: startEventsIndex}\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     */\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n      debug('position: restore: `%j`', point)\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {undefined}\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Array<Chunk>} chunks\n * @param {Pick<Token, 'end' | 'start'>} token\n * @returns {Array<Chunk>}\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Array<Chunk>} */\n  let view\n\n  if (startIndex === endIndex) {\n    assert(endBufferIndex > -1, 'expected non-negative end buffer index')\n    assert(startBufferIndex > -1, 'expected non-negative start buffer index')\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n\n    if (startBufferIndex > -1) {\n      const head = view[0]\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex)\n      } else {\n        assert(startBufferIndex === 0, 'expected `startBufferIndex` to be `0`')\n        view.shift()\n      }\n    }\n\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n\n  return view\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Array<Chunk>} chunks\n * @param {boolean | undefined} [expandTabs=false]\n * @returns {string}\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {Array<string>} */\n  const result = []\n  /** @type {boolean | undefined} */\n  let atTab\n\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n    let value\n\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case codes.carriageReturn: {\n          value = values.cr\n\n          break\n        }\n\n        case codes.lineFeed: {\n          value = values.lf\n\n          break\n        }\n\n        case codes.carriageReturnLineFeed: {\n          value = values.cr + values.lf\n\n          break\n        }\n\n        case codes.horizontalTab: {\n          value = expandTabs ? values.space : values.ht\n\n          break\n        }\n\n        case codes.virtualSpace: {\n          if (!expandTabs && atTab) continue\n          value = values.space\n\n          break\n        }\n\n        default: {\n          assert(typeof chunk === 'number', 'expected number')\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n\n    atTab = chunk === codes.horizontalTab\n    result.push(value)\n  }\n\n  return result.join('')\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;CAaC,GAED;;;;;;;;;;;;;CAaC;;;;;;;;;;;;;;;;AASD,MAAM,QAAQ,4LAAY;AAgBnB,SAAS,gBAAgB,MAAM,EAAE,UAAU,EAAE,IAAI;IACtD,kBAAkB,GAClB,IAAI,QAAQ,OAAO,MAAM,CACvB,OAAO,OAAO,MAAM,CAAC,CAAC,GAAG,QAAQ;QAAC,MAAM;QAAG,QAAQ;QAAG,QAAQ;IAAC,GAC/D;QAAC,QAAQ;QAAG,cAAc,CAAC;IAAC;IAE9B,mCAAmC,GACnC,MAAM,cAAc,CAAC;IACrB,6BAA6B,GAC7B,MAAM,uBAAuB,EAAE;IAC/B,yBAAyB,GACzB,IAAI,SAAS,EAAE;IACf,yBAAyB,GACzB,IAAI,QAAQ,EAAE;IACd,gCAAgC,GAChC,IAAI,WAAW;IAEf;;;;GAIC,GACD,MAAM,UAAU;QACd;QACA;QACA;QACA,SAAS,iBAAiB;QAC1B,OAAO,iBAAiB;QACxB,WAAW,iBAAiB,mBAAmB;YAAC,WAAW;QAAI;IACjE;IAEA;;;;GAIC,GACD,MAAM,UAAU;QACd,UAAU,wOAAM,GAAG;QACnB,MAAM,wOAAM,GAAG;QACf,gBAAgB,CAAC;QACjB,QAAQ,EAAE;QACV;QACA;QACA;QACA;QACA;QACA;IACF;IAEA;;;;GAIC,GACD,IAAI,QAAQ,WAAW,QAAQ,CAAC,IAAI,CAAC,SAAS;IAE9C;;;;GAIC,GACD,IAAI;IAEJ,IAAI,WAAW,UAAU,EAAE;QACzB,qBAAqB,IAAI,CAAC;IAC5B;IAEA,OAAO;IAEP,qCAAqC,GACrC,SAAS,MAAM,KAAK;QAClB,SAAS,uOAAK,QAAQ;QAEtB;QAEA,sDAAsD;QACtD,IAAI,MAAM,CAAC,OAAO,MAAM,GAAG,EAAE,KAAK,wOAAM,GAAG,EAAE;YAC3C,OAAO,EAAE;QACX;QAEA,UAAU,YAAY;QAEtB,gCAAgC;QAChC,QAAQ,MAAM,GAAG,oPAAW,sBAAsB,QAAQ,MAAM,EAAE;QAElE,OAAO,QAAQ,MAAM;IACvB;IAEA,EAAE;IACF,SAAS;IACT,EAAE;IAEF,8CAA8C,GAC9C,SAAS,eAAe,KAAK,EAAE,UAAU;QACvC,OAAO,gBAAgB,YAAY,QAAQ;IAC7C;IAEA,2CAA2C,GAC3C,SAAS,YAAY,KAAK;QACxB,OAAO,YAAY,QAAQ;IAC7B;IAEA,mCAAmC,GACnC,SAAS;QACP,iFAAiF;QACjF,MAAM,EAAC,IAAI,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,YAAY,EAAC,GAAG;QACrD,OAAO;YAAC;YAAM;YAAQ;YAAQ;YAAQ;QAAY;IACpD;IAEA,0CAA0C,GAC1C,SAAS,WAAW,KAAK;QACvB,WAAW,CAAC,MAAM,IAAI,CAAC,GAAG,MAAM,MAAM;QACtC;QACA,MAAM,+BAA+B;IACvC;IAEA,EAAE;IACF,oBAAoB;IACpB,EAAE;IAEF;;;;;;;;;GASC,GACD,SAAS;QACP,mBAAmB,GACnB,IAAI;QAEJ,MAAO,MAAM,MAAM,GAAG,OAAO,MAAM,CAAE;YACnC,MAAM,QAAQ,MAAM,CAAC,MAAM,MAAM,CAAC;YAElC,+CAA+C;YAC/C,IAAI,OAAO,UAAU,UAAU;gBAC7B,aAAa,MAAM,MAAM;gBAEzB,IAAI,MAAM,YAAY,GAAG,GAAG;oBAC1B,MAAM,YAAY,GAAG;gBACvB;gBAEA,MACE,MAAM,MAAM,KAAK,cACjB,MAAM,YAAY,GAAG,MAAM,MAAM,CACjC;oBACA,GAAG,MAAM,UAAU,CAAC,MAAM,YAAY;gBACxC;YACF,OAAO;gBACL,GAAG;YACL;QACF;IACF;IAEA;;;;;GAKC,GACD,SAAS,GAAG,IAAI;QACd,+LAAO,aAAa,MAAM;QAC1B,WAAW;QACX,MAAM,4BAA4B,MAAM,SAAS,MAAM,IAAI;QAC3D,eAAe;QACf,+LAAO,OAAO,UAAU,YAAY;QACpC,QAAQ,MAAM;IAChB;IAEA,+BAA+B,GAC/B,SAAS,QAAQ,IAAI;QACnB,+LAAO,SAAS,cAAc;QAE9B,MAAM,iBAAiB;QAEvB,+LACE,aAAa,WACb;QAEF,+LACE,SAAS,OACL,QAAQ,MAAM,CAAC,MAAM,KAAK,KACxB,QAAQ,MAAM,CAAC,QAAQ,MAAM,CAAC,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK,SACnD,QAAQ,MAAM,CAAC,QAAQ,MAAM,CAAC,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK,SACrD;QAGF,IAAI,yPAAmB,OAAO;YAC5B,MAAM,IAAI;YACV,MAAM,MAAM,GAAG;YACf,MAAM,MAAM,IAAI,SAAS,wOAAM,sBAAsB,GAAG,IAAI;YAC5D;YACA,MAAM,6BAA6B;QACrC,OAAO,IAAI,SAAS,wOAAM,YAAY,EAAE;YACtC,MAAM,MAAM;YACZ,MAAM,MAAM;QACd;QAEA,yBAAyB;QACzB,IAAI,MAAM,YAAY,GAAG,GAAG;YAC1B,MAAM,MAAM;QACd,OAAO;YACL,MAAM,YAAY;YAElB,0BAA0B;YAC1B,mEAAmE;YACnE,WAAW;YACX,IAAI,MAAM,YAAY,KAAK,MAAM,CAAC,MAAM,MAAM,CAAC,CAAC,MAAM,EAAE;gBACtD,MAAM,YAAY,GAAG,CAAC;gBACtB,MAAM,MAAM;YACd;QACF;QAEA,iCAAiC;QACjC,QAAQ,QAAQ,GAAG;QAEnB,oBAAoB;QACpB,WAAW;IACb;IAEA,6BAA6B,GAC7B,SAAS,MAAM,IAAI,EAAE,MAAM;QACzB,kBAAkB,GAClB,uEAAuE;QACvE,MAAM,QAAQ,UAAU,CAAC;QACzB,MAAM,IAAI,GAAG;QACb,MAAM,KAAK,GAAG;QAEd,+LAAO,OAAO,SAAS,UAAU;QACjC,+LAAO,KAAK,MAAM,GAAG,GAAG;QACxB,MAAM,eAAe;QAErB,QAAQ,MAAM,CAAC,IAAI,CAAC;YAAC;YAAS;YAAO;SAAQ;QAE7C,MAAM,IAAI,CAAC;QAEX,OAAO;IACT;IAEA,4BAA4B,GAC5B,SAAS,KAAK,IAAI;QAChB,+LAAO,OAAO,SAAS,UAAU;QACjC,+LAAO,KAAK,MAAM,GAAG,GAAG;QAExB,MAAM,QAAQ,MAAM,GAAG;QACvB,+LAAO,OAAO;QACd,MAAM,GAAG,GAAG;QAEZ,+LAAO,SAAS,MAAM,IAAI,EAAE;QAE5B,+LACE,CAAC,CACC,MAAM,KAAK,CAAC,MAAM,KAAK,MAAM,GAAG,CAAC,MAAM,IACvC,MAAM,KAAK,CAAC,YAAY,KAAK,MAAM,GAAG,CAAC,YAAY,AACrD,GACA,gCAAgC,OAAO;QAGzC,MAAM,cAAc,MAAM,IAAI;QAC9B,QAAQ,MAAM,CAAC,IAAI,CAAC;YAAC;YAAQ;YAAO;SAAQ;QAE5C,OAAO;IACT;IAEA;;;;GAIC,GACD,SAAS,sBAAsB,SAAS,EAAE,IAAI;QAC5C,UAAU,WAAW,KAAK,IAAI;IAChC;IAEA;;;;GAIC,GACD,SAAS,kBAAkB,CAAC,EAAE,IAAI;QAChC,KAAK,OAAO;IACd;IAEA;;;;;GAKC,GACD,SAAS,iBAAiB,QAAQ,EAAE,MAAM;QACxC,OAAO;QAEP;;;;;;;;KAQC,GACD,SAAS,KAAK,UAAU,EAAE,WAAW,EAAE,UAAU;YAC/C,6BAA6B,GAC7B,IAAI;YACJ,mBAAmB,GACnB,IAAI;YACJ,sBAAsB,GACtB,IAAI;YACJ,iBAAiB,GACjB,IAAI;YAEJ,OAAO,MAAM,OAAO,CAAC,cACjB,oBAAoB,GACpB,uBAAuB,cACvB,cAAc,aAEd,uBAAuB;gBAAC;aAAW,IACnC,sBAAsB;YAE1B;;;;;OAKC,GACD,SAAS,sBAAsB,GAAG;gBAChC,OAAO;gBAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;oBACjB,MAAM,MAAM,SAAS,QAAQ,GAAG,CAAC,KAAK;oBACtC,MAAM,MAAM,SAAS,QAAQ,IAAI,IAAI;oBACrC,MAAM,OAAO;wBACX,mCAAmC;wBACnC,oBAAoB,MAChB,MAAM,OAAO,CAAC,OAAO,MAAM,MAAM;4BAAC;yBAAI,GAAG,EAAE;2BAC3C,MAAM,OAAO,CAAC,OAAO,MAAM,MAAM;4BAAC;yBAAI,GAAG,EAAE;qBAChD;oBAED,OAAO,uBAAuB,MAAM;gBACtC;YACF;YAEA;;;;;OAKC,GACD,SAAS,uBAAuB,IAAI;gBAClC,mBAAmB;gBACnB,iBAAiB;gBAEjB,IAAI,KAAK,MAAM,KAAK,GAAG;oBACrB,+LAAO,YAAY;oBACnB,OAAO;gBACT;gBAEA,OAAO,gBAAgB,IAAI,CAAC,eAAe;YAC7C;YAEA;;;;;OAKC,GACD,SAAS,gBAAgB,SAAS;gBAChC,OAAO;gBAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;oBACjB,mEAAmE;oBACnE,oEAAoE;oBACpE,uEAAuE;oBACvE,kBAAkB;oBAClB,OAAO;oBACP,mBAAmB;oBAEnB,IAAI,CAAC,UAAU,OAAO,EAAE;wBACtB,QAAQ,gBAAgB,GAAG;oBAC7B;oBAEA,gCAAgC;oBAChC,+LACE,QAAQ,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,EACtC;oBAGF,IACE,UAAU,IAAI,IACd,QAAQ,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,UAAU,IAAI,GAC9D;wBACA,OAAO,IAAI;oBACb;oBAEA,OAAO,UAAU,QAAQ,CAAC,IAAI,CAC5B,6DAA6D;oBAC7D,aAAa;oBACb,iEAAiE;oBACjE,SAAS,OAAO,MAAM,CAAC,OAAO,MAAM,CAAC,UAAU,UAAU,SACzD,SACA,IACA,KACA;gBACJ;YACF;YAEA,kBAAkB,GAClB,SAAS,GAAG,IAAI;gBACd,+LAAO,SAAS,cAAc;gBAC9B,WAAW;gBACX,SAAS,kBAAkB;gBAC3B,OAAO;YACT;YAEA,kBAAkB,GAClB,SAAS,IAAI,IAAI;gBACf,+LAAO,SAAS,cAAc;gBAC9B,WAAW;gBACX,KAAK,OAAO;gBAEZ,IAAI,EAAE,iBAAiB,iBAAiB,MAAM,EAAE;oBAC9C,OAAO,gBAAgB,gBAAgB,CAAC,eAAe;gBACzD;gBAEA,OAAO;YACT;QACF;IACF;IAEA;;;;GAIC,GACD,SAAS,UAAU,SAAS,EAAE,IAAI;QAChC,IAAI,UAAU,UAAU,IAAI,CAAC,qBAAqB,QAAQ,CAAC,YAAY;YACrE,qBAAqB,IAAI,CAAC;QAC5B;QAEA,IAAI,UAAU,OAAO,EAAE;YACrB,yOACE,QAAQ,MAAM,EACd,MACA,QAAQ,MAAM,CAAC,MAAM,GAAG,MACxB,UAAU,OAAO,CAAC,QAAQ,MAAM,CAAC,KAAK,CAAC,OAAO;QAElD;QAEA,IAAI,UAAU,SAAS,EAAE;YACvB,QAAQ,MAAM,GAAG,UAAU,SAAS,CAAC,QAAQ,MAAM,EAAE;QACvD;QAEA,+LACE,UAAU,OAAO,IACf,QAAQ,MAAM,CAAC,MAAM,KAAK,KAC1B,QAAQ,MAAM,CAAC,QAAQ,MAAM,CAAC,MAAM,GAAG,EAAE,CAAC,EAAE,KAAK,QACnD;IAEJ;IAEA;;;;GAIC,GACD,SAAS;QACP,MAAM,aAAa;QACnB,MAAM,gBAAgB,QAAQ,QAAQ;QACtC,MAAM,wBAAwB,QAAQ,gBAAgB;QACtD,MAAM,mBAAmB,QAAQ,MAAM,CAAC,MAAM;QAC9C,MAAM,aAAa,MAAM,IAAI,CAAC;QAE9B,OAAO;YAAC;YAAS,MAAM;QAAgB;QAEvC;;;;KAIC,GACD,SAAS;YACP,QAAQ;YACR,QAAQ,QAAQ,GAAG;YACnB,QAAQ,gBAAgB,GAAG;YAC3B,QAAQ,MAAM,CAAC,MAAM,GAAG;YACxB,QAAQ;YACR;YACA,MAAM,2BAA2B;QACnC;IACF;IAEA;;;;;GAKC,GACD,SAAS;QACP,IAAI,MAAM,IAAI,IAAI,eAAe,MAAM,MAAM,GAAG,GAAG;YACjD,MAAM,MAAM,GAAG,WAAW,CAAC,MAAM,IAAI,CAAC;YACtC,MAAM,MAAM,IAAI,WAAW,CAAC,MAAM,IAAI,CAAC,GAAG;QAC5C;IACF;AACF;AAEA;;;;;;CAMC,GACD,SAAS,YAAY,MAAM,EAAE,KAAK;IAChC,MAAM,aAAa,MAAM,KAAK,CAAC,MAAM;IACrC,MAAM,mBAAmB,MAAM,KAAK,CAAC,YAAY;IACjD,MAAM,WAAW,MAAM,GAAG,CAAC,MAAM;IACjC,MAAM,iBAAiB,MAAM,GAAG,CAAC,YAAY;IAC7C,yBAAyB,GACzB,IAAI;IAEJ,IAAI,eAAe,UAAU;QAC3B,+LAAO,iBAAiB,CAAC,GAAG;QAC5B,+LAAO,mBAAmB,CAAC,GAAG;QAC9B,4DAA4D;QAC5D,OAAO;YAAC,MAAM,CAAC,WAAW,CAAC,KAAK,CAAC,kBAAkB;SAAgB;IACrE,OAAO;QACL,OAAO,OAAO,KAAK,CAAC,YAAY;QAEhC,IAAI,mBAAmB,CAAC,GAAG;YACzB,MAAM,OAAO,IAAI,CAAC,EAAE;YACpB,IAAI,OAAO,SAAS,UAAU;gBAC5B,IAAI,CAAC,EAAE,GAAG,KAAK,KAAK,CAAC;YACvB,OAAO;gBACL,+LAAO,qBAAqB,GAAG;gBAC/B,KAAK,KAAK;YACZ;QACF;QAEA,IAAI,iBAAiB,GAAG;YACtB,4DAA4D;YAC5D,KAAK,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,GAAG;QACtC;IACF;IAEA,OAAO;AACT;AAEA;;;;;;CAMC,GACD,SAAS,gBAAgB,MAAM,EAAE,UAAU;IACzC,IAAI,QAAQ,CAAC;IACb,0BAA0B,GAC1B,MAAM,SAAS,EAAE;IACjB,gCAAgC,GAChC,IAAI;IAEJ,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;QAC9B,MAAM,QAAQ,MAAM,CAAC,MAAM;QAC3B,mBAAmB,GACnB,IAAI;QAEJ,IAAI,OAAO,UAAU,UAAU;YAC7B,QAAQ;QACV,OACE,OAAQ;YACN,KAAK,wOAAM,cAAc;gBAAE;oBACzB,QAAQ,yOAAO,EAAE;oBAEjB;gBACF;YAEA,KAAK,wOAAM,QAAQ;gBAAE;oBACnB,QAAQ,yOAAO,EAAE;oBAEjB;gBACF;YAEA,KAAK,wOAAM,sBAAsB;gBAAE;oBACjC,QAAQ,yOAAO,EAAE,GAAG,yOAAO,EAAE;oBAE7B;gBACF;YAEA,KAAK,wOAAM,aAAa;gBAAE;oBACxB,QAAQ,aAAa,yOAAO,KAAK,GAAG,yOAAO,EAAE;oBAE7C;gBACF;YAEA,KAAK,wOAAM,YAAY;gBAAE;oBACvB,IAAI,CAAC,cAAc,OAAO;oBAC1B,QAAQ,yOAAO,KAAK;oBAEpB;gBACF;YAEA;gBAAS;oBACP,+LAAO,OAAO,UAAU,UAAU;oBAClC,wCAAwC;oBACxC,QAAQ,OAAO,YAAY,CAAC;gBAC9B;QACF;QAEF,QAAQ,UAAU,wOAAM,aAAa;QACrC,OAAO,IAAI,CAAC;IACd;IAEA,OAAO,OAAO,IAAI,CAAC;AACrB"}},
    {"offset": {"line": 4657, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4662, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/initialize/flow.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {blankLine, content} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {codes, types} from 'micromark-util-symbol'\nimport {ok as assert} from 'devlop'\n\n/** @type {InitialConstruct} */\nexport const flow = {tokenize: initializeFlow}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeFlow(effects) {\n  const self = this\n  const initial = effects.attempt(\n    // Try to parse a blank line.\n    blankLine,\n    atBlankEnding,\n    // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        types.linePrefix\n      )\n    )\n  )\n\n  return initial\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    assert(\n      code === codes.eof || markdownLineEnding(code),\n      'expected eol or eof'\n    )\n\n    if (code === codes.eof) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter(types.lineEndingBlank)\n    effects.consume(code)\n    effects.exit(types.lineEndingBlank)\n    self.currentConstruct = undefined\n    return initial\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    assert(\n      code === codes.eof || markdownLineEnding(code),\n      'expected eol or eof'\n    )\n\n    if (code === codes.eof) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter(types.lineEnding)\n    effects.consume(code)\n    effects.exit(types.lineEnding)\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;CAKC;;;;;;;;;;;;;;AASM,MAAM,OAAO;IAAC,UAAU;AAAc;AAE7C;;;CAGC,GACD,SAAS,eAAe,OAAO;IAC7B,MAAM,OAAO,IAAI;IACjB,MAAM,UAAU,QAAQ,OAAO,oPAG7B,eACA,sDAAsD;IACtD,QAAQ,OAAO,CACb,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,WAAW,EAClC,gBACA,iPACE,SACA,QAAQ,OAAO,CACb,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,IAAI,EAC3B,gBACA,QAAQ,OAAO,kPAAU,kBAE3B,wOAAM,UAAU;IAKtB,OAAO;IAEP,kBAAkB,GAClB,SAAS,cAAc,IAAI;QACzB,+LACE,SAAS,wOAAM,GAAG,IAAI,yPAAmB,OACzC;QAGF,IAAI,SAAS,wOAAM,GAAG,EAAE;YACtB,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,QAAQ,KAAK,CAAC,wOAAM,eAAe;QACnC,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC,wOAAM,eAAe;QAClC,KAAK,gBAAgB,GAAG;QACxB,OAAO;IACT;IAEA,kBAAkB,GAClB,SAAS,eAAe,IAAI;QAC1B,+LACE,SAAS,wOAAM,GAAG,IAAI,yPAAmB,OACzC;QAGF,IAAI,SAAS,wOAAM,GAAG,EAAE;YACtB,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,QAAQ,KAAK,CAAC,wOAAM,UAAU;QAC9B,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC,wOAAM,UAAU;QAC7B,KAAK,gBAAgB,GAAG;QACxB,OAAO;IACT;AACF"}},
    {"offset": {"line": 4717, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4722, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/initialize/document.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').ContainerState} ContainerState\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\nimport {codes, constants, types} from 'micromark-util-symbol'\nimport {ok as assert} from 'devlop'\n\n/** @type {InitialConstruct} */\nexport const document = {tokenize: initializeDocument}\n\n/** @type {Construct} */\nconst containerConstruct = {tokenize: tokenizeContainer}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {Array<StackItem>} */\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext | undefined} */\n  let childFlow\n  /** @type {Token | undefined} */\n  let childToken\n  /** @type {number} */\n  let lineStartOffset\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      assert(\n        item[0].continuation,\n        'expected `continuation` to be defined on container construct'\n      )\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    }\n\n    // Done.\n    return checkNewContainers(code)\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    assert(\n      self.containerState,\n      'expected `containerState` to be defined after continuation'\n    )\n\n    continued++\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n\n      if (childFlow) {\n        closeFlow()\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === types.chunkFlow\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n\n      assert(point, 'could not find previous flow chunk')\n\n      exitContainers(continued)\n\n      // Fix positions.\n      let index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n\n      return checkNewContainers(code)\n    }\n\n    return start(code)\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(\n        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack\n      )\n    }\n\n    // Check if there is a new container.\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    assert(\n      self.currentConstruct,\n      'expected `currentConstruct` to be defined on tokenizer'\n    )\n    assert(\n      self.containerState,\n      'expected `containerState` to be defined on tokenizer'\n    )\n    continued++\n    stack.push([self.currentConstruct, self.containerState])\n    // Try another.\n    return documentContinued(code)\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === codes.eof) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter(types.chunkFlow, {\n      contentType: constants.contentTypeFlow,\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n\n    return flowContinue(code)\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === codes.eof) {\n      writeToChild(effects.exit(types.chunkFlow), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit(types.chunkFlow))\n      // Get ready for the next line.\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n\n    effects.consume(code)\n    return flowContinue\n  }\n\n  /**\n   * @param {Token} token\n   * @param {boolean | undefined} [eof]\n   * @returns {undefined}\n   */\n  function writeToChild(token, eof) {\n    assert(childFlow, 'expected `childFlow` to be defined when continuing')\n    const stream = self.sliceStream(token)\n    if (eof) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream)\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n\n      while (index--) {\n        if (\n          // The token starts before the line ending…\n          childFlow.events[index][1].start.offset < lineStartOffset &&\n          // …and either is not ended yet…\n          (!childFlow.events[index][1].end ||\n            // …or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean | undefined} */\n      let seen\n      /** @type {Point | undefined} */\n      let point\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === types.chunkFlow\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n\n          seen = true\n        }\n      }\n\n      assert(point, 'could not find previous flow chunk')\n\n      exitContainers(continued)\n\n      // Fix positions.\n      index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      )\n\n      // Discard the duplicate exits.\n      self.events.length = index\n    }\n  }\n\n  /**\n   * @param {number} size\n   * @returns {undefined}\n   */\n  function exitContainers(size) {\n    let index = stack.length\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      assert(\n        entry[0].exit,\n        'expected `exit` to be defined on container construct'\n      )\n      entry[0].exit.call(self, effects)\n    }\n\n    stack.length = size\n  }\n\n  function closeFlow() {\n    assert(\n      self.containerState,\n      'expected `containerState` to be defined when closing flow'\n    )\n    assert(childFlow, 'expected `childFlow` to be defined when closing it')\n    childFlow.write([codes.eof])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n  assert(\n    this.parser.constructs.disable.null,\n    'expected `disable.null` to be populated'\n  )\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    types.linePrefix,\n    this.parser.constructs.disable.null.includes('codeIndented')\n      ? undefined\n      : constants.tabSize\n  )\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;CAUC,GAED;;CAEC;;;;;;;;;;;;;;AASM,MAAM,WAAW;IAAC,UAAU;AAAkB;AAErD,sBAAsB,GACtB,MAAM,qBAAqB;IAAC,UAAU;AAAiB;AAEvD;;;CAGC,GACD,SAAS,mBAAmB,OAAO;IACjC,MAAM,OAAO,IAAI;IACjB,6BAA6B,GAC7B,MAAM,QAAQ,EAAE;IAChB,IAAI,YAAY;IAChB,wCAAwC,GACxC,IAAI;IACJ,8BAA8B,GAC9B,IAAI;IACJ,mBAAmB,GACnB,IAAI;IAEJ,OAAO;IAEP,kBAAkB,GAClB,SAAS,MAAM,IAAI;QACjB,mEAAmE;QACnE,uEAAuE;QACvE,SAAS;QACT,4EAA4E;QAC5E,kBAAkB;QAClB,uDAAuD;QACvD,yCAAyC;QACzC,kEAAkE;QAClE,uEAAuE;QACvE,qBAAqB;QACrB,IAAI,YAAY,MAAM,MAAM,EAAE;YAC5B,MAAM,OAAO,KAAK,CAAC,UAAU;YAC7B,KAAK,cAAc,GAAG,IAAI,CAAC,EAAE;YAC7B,+LACE,IAAI,CAAC,EAAE,CAAC,YAAY,EACpB;YAEF,OAAO,QAAQ,OAAO,CACpB,IAAI,CAAC,EAAE,CAAC,YAAY,EACpB,kBACA,oBACA;QACJ;QAEA,QAAQ;QACR,OAAO,mBAAmB;IAC5B;IAEA,kBAAkB,GAClB,SAAS,iBAAiB,IAAI;QAC5B,+LACE,KAAK,cAAc,EACnB;QAGF;QAEA,yEAAyE;QACzE,wEAAwE;QACxE,cAAc;QACd,IAAI,KAAK,cAAc,CAAC,UAAU,EAAE;YAClC,KAAK,cAAc,CAAC,UAAU,GAAG;YAEjC,IAAI,WAAW;gBACb;YACF;YAEA,kEAAkE;YAClE,4DAA4D;YAC5D,MAAM,mBAAmB,KAAK,MAAM,CAAC,MAAM;YAC3C,IAAI,kBAAkB;YACtB,8BAA8B,GAC9B,IAAI;YAEJ,uBAAuB;YACvB,MAAO,kBAAmB;gBACxB,IACE,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,KAAK,UACpC,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,SAAS,EACxD;oBACA,QAAQ,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,GAAG;oBAC3C;gBACF;YACF;YAEA,+LAAO,OAAO;YAEd,eAAe;YAEf,iBAAiB;YACjB,IAAI,QAAQ;YAEZ,MAAO,QAAQ,KAAK,MAAM,CAAC,MAAM,CAAE;gBACjC,KAAK,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG;gBAC9C;YACF;YAEA,4DAA4D;YAC5D,yOACE,KAAK,MAAM,EACX,kBAAkB,GAClB,GACA,KAAK,MAAM,CAAC,KAAK,CAAC;YAGpB,+BAA+B;YAC/B,KAAK,MAAM,CAAC,MAAM,GAAG;YAErB,OAAO,mBAAmB;QAC5B;QAEA,OAAO,MAAM;IACf;IAEA,kBAAkB,GAClB,SAAS,mBAAmB,IAAI;QAC9B,yEAAyE;QACzE,0DAA0D;QAC1D,sEAAsE;QACtE,sEAAsE;QACtE,SAAS;QACT,IAAI,cAAc,MAAM,MAAM,EAAE;YAC9B,sEAAsE;YACtE,iBAAiB;YACjB,qDAAqD;YACrD,IAAI,CAAC,WAAW;gBACd,OAAO,kBAAkB;YAC3B;YAEA,kEAAkE;YAClE,qEAAqE;YACrE,SAAS;YACT,IAAI,UAAU,gBAAgB,IAAI,UAAU,gBAAgB,CAAC,QAAQ,EAAE;gBACrE,OAAO,UAAU;YACnB;YAEA,sDAAsD;YACtD,sEAAsE;YACtE,aAAa;YACb,uEAAuE;YACvE,kDAAkD;YAClD,KAAK,SAAS,GAAG,QACf,UAAU,gBAAgB,IAAI,CAAC,UAAU,6BAA6B;QAE1E;QAEA,qCAAqC;QACrC,KAAK,cAAc,GAAG,CAAC;QACvB,OAAO,QAAQ,KAAK,CAClB,oBACA,sBACA,uBACA;IACJ;IAEA,kBAAkB,GAClB,SAAS,qBAAqB,IAAI;QAChC,IAAI,WAAW;QACf,eAAe;QACf,OAAO,kBAAkB;IAC3B;IAEA,kBAAkB,GAClB,SAAS,sBAAsB,IAAI;QACjC,KAAK,MAAM,CAAC,IAAI,CAAC,KAAK,GAAG,GAAG,IAAI,CAAC,GAAG,cAAc,MAAM,MAAM;QAC9D,kBAAkB,KAAK,GAAG,GAAG,MAAM;QACnC,OAAO,UAAU;IACnB;IAEA,kBAAkB,GAClB,SAAS,kBAAkB,IAAI;QAC7B,sBAAsB;QACtB,KAAK,cAAc,GAAG,CAAC;QACvB,OAAO,QAAQ,OAAO,CACpB,oBACA,mBACA,WACA;IACJ;IAEA,kBAAkB,GAClB,SAAS,kBAAkB,IAAI;QAC7B,+LACE,KAAK,gBAAgB,EACrB;QAEF,+LACE,KAAK,cAAc,EACnB;QAEF;QACA,MAAM,IAAI,CAAC;YAAC,KAAK,gBAAgB;YAAE,KAAK,cAAc;SAAC;QACvD,eAAe;QACf,OAAO,kBAAkB;IAC3B;IAEA,kBAAkB,GAClB,SAAS,UAAU,IAAI;QACrB,IAAI,SAAS,wOAAM,GAAG,EAAE;YACtB,IAAI,WAAW;YACf,eAAe;YACf,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,YAAY,aAAa,KAAK,MAAM,CAAC,IAAI,CAAC,KAAK,GAAG;QAClD,QAAQ,KAAK,CAAC,wOAAM,SAAS,EAAE;YAC7B,aAAa,4OAAU,eAAe;YACtC,UAAU;YACV,YAAY;QACd;QAEA,OAAO,aAAa;IACtB;IAEA,kBAAkB,GAClB,SAAS,aAAa,IAAI;QACxB,IAAI,SAAS,wOAAM,GAAG,EAAE;YACtB,aAAa,QAAQ,IAAI,CAAC,wOAAM,SAAS,GAAG;YAC5C,eAAe;YACf,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,IAAI,yPAAmB,OAAO;YAC5B,QAAQ,OAAO,CAAC;YAChB,aAAa,QAAQ,IAAI,CAAC,wOAAM,SAAS;YACzC,+BAA+B;YAC/B,YAAY;YACZ,KAAK,SAAS,GAAG;YACjB,OAAO;QACT;QAEA,QAAQ,OAAO,CAAC;QAChB,OAAO;IACT;IAEA;;;;GAIC,GACD,SAAS,aAAa,KAAK,EAAE,GAAG;QAC9B,+LAAO,WAAW;QAClB,MAAM,SAAS,KAAK,WAAW,CAAC;QAChC,IAAI,KAAK,OAAO,IAAI,CAAC;QACrB,MAAM,QAAQ,GAAG;QACjB,IAAI,YAAY,WAAW,IAAI,GAAG;QAClC,aAAa;QACb,UAAU,UAAU,CAAC,MAAM,KAAK;QAChC,UAAU,KAAK,CAAC;QAEhB,yCAAyC;QACzC,EAAE;QACF,cAAc;QACd,MAAM;QACN,KAAK;QACL,EAAE;QACF,MAAM;QACN,EAAE;QACF,SAAS;QACT,IAAI;QACJ,EAAE;QACF,MAAM;QACN,EAAE;QACF,UAAU;QACV,IAAI;QACJ,MAAM;QACN,EAAE;QACF,yEAAyE;QACzE,uEAAuE;QACvE,yCAAyC;QACzC,yEAAyE;QACzE,wDAAwD;QACxD,EAAE;QACF,qEAAqE;QACrE,qBAAqB;QACrB,oEAAoE;QACpE,uBAAuB;QACvB,yEAAyE;QACzE,8CAA8C;QAC9C,EAAE;QACF,sEAAsE;QACtE,kDAAkD;QAClD,yEAAyE;QACzE,IAAI,KAAK,MAAM,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,IAAI,CAAC,EAAE;YACtC,IAAI,QAAQ,UAAU,MAAM,CAAC,MAAM;YAEnC,MAAO,QAAS;gBACd,IACE,2CAA2C;gBAC3C,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,KAAK,CAAC,MAAM,GAAG,mBAC1C,gCAAgC;gBAChC,CAAC,CAAC,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,IAC9B,qBAAqB;gBACrB,UAAU,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,CAAC,MAAM,GAAG,eAAe,GACzD;oBACA,mEAAmE;oBACnE,qBAAqB;oBACrB;gBACF;YACF;YAEA,kEAAkE;YAClE,qDAAqD;YACrD,MAAM,mBAAmB,KAAK,MAAM,CAAC,MAAM;YAC3C,IAAI,kBAAkB;YACtB,gCAAgC,GAChC,IAAI;YACJ,8BAA8B,GAC9B,IAAI;YAEJ,0DAA0D;YAC1D,MAAO,kBAAmB;gBACxB,IACE,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,KAAK,UACpC,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,SAAS,EACxD;oBACA,IAAI,MAAM;wBACR,QAAQ,KAAK,MAAM,CAAC,gBAAgB,CAAC,EAAE,CAAC,GAAG;wBAC3C;oBACF;oBAEA,OAAO;gBACT;YACF;YAEA,+LAAO,OAAO;YAEd,eAAe;YAEf,iBAAiB;YACjB,QAAQ;YAER,MAAO,QAAQ,KAAK,MAAM,CAAC,MAAM,CAAE;gBACjC,KAAK,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG,OAAO,MAAM,CAAC,CAAC,GAAG;gBAC9C;YACF;YAEA,4DAA4D;YAC5D,yOACE,KAAK,MAAM,EACX,kBAAkB,GAClB,GACA,KAAK,MAAM,CAAC,KAAK,CAAC;YAGpB,+BAA+B;YAC/B,KAAK,MAAM,CAAC,MAAM,GAAG;QACvB;IACF;IAEA;;;GAGC,GACD,SAAS,eAAe,IAAI;QAC1B,IAAI,QAAQ,MAAM,MAAM;QAExB,wBAAwB;QACxB,MAAO,UAAU,KAAM;YACrB,MAAM,QAAQ,KAAK,CAAC,MAAM;YAC1B,KAAK,cAAc,GAAG,KAAK,CAAC,EAAE;YAC9B,+LACE,KAAK,CAAC,EAAE,CAAC,IAAI,EACb;YAEF,KAAK,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM;QAC3B;QAEA,MAAM,MAAM,GAAG;IACjB;IAEA,SAAS;QACP,+LACE,KAAK,cAAc,EACnB;QAEF,+LAAO,WAAW;QAClB,UAAU,KAAK,CAAC;YAAC,wOAAM,GAAG;SAAC;QAC3B,aAAa;QACb,YAAY;QACZ,KAAK,cAAc,CAAC,UAAU,GAAG;IACnC;AACF;AAEA;;;CAGC,GACD,SAAS,kBAAkB,OAAO,EAAE,EAAE,EAAE,GAAG;IACzC,gCAAgC;IAChC,+LACE,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,EACnC;IAEF,OAAO,iPACL,SACA,QAAQ,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,QAAQ,EAAE,IAAI,MACrD,wOAAM,UAAU,EAChB,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,kBACzC,YACA,4OAAU,OAAO;AAEzB"}},
    {"offset": {"line": 5034, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5039, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/initialize/content.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n */\n\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {codes, constants, types} from 'micromark-util-symbol'\nimport {ok as assert} from 'devlop'\n\n/** @type {InitialConstruct} */\nexport const content = {tokenize: initializeContent}\n\n/**\n * @this {TokenizeContext}\n * @type {Initializer}\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n  let previous\n\n  return contentStart\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    assert(\n      code === codes.eof || markdownLineEnding(code),\n      'expected eol or eof'\n    )\n\n    if (code === codes.eof) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter(types.lineEnding)\n    effects.consume(code)\n    effects.exit(types.lineEnding)\n    return factorySpace(effects, contentStart, types.linePrefix)\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    assert(\n      code !== codes.eof && !markdownLineEnding(code),\n      'expected anything other than a line ending or EOF'\n    )\n    effects.enter(types.paragraph)\n    return lineStart(code)\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter(types.chunkText, {\n      contentType: constants.contentTypeText,\n      previous\n    })\n\n    if (previous) {\n      previous.next = token\n    }\n\n    previous = token\n\n    return data(code)\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === codes.eof) {\n      effects.exit(types.chunkText)\n      effects.exit(types.paragraph)\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit(types.chunkText)\n      return lineStart\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;CAMC;;;;;;;;;;;;AAQM,MAAM,UAAU;IAAC,UAAU;AAAiB;AAEnD;;;CAGC,GACD,SAAS,kBAAkB,OAAO;IAChC,MAAM,eAAe,QAAQ,OAAO,CAClC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,cAAc,EACrC,4BACA;IAEF,kBAAkB,GAClB,IAAI;IAEJ,OAAO;IAEP,kBAAkB,GAClB,SAAS,2BAA2B,IAAI;QACtC,+LACE,SAAS,wOAAM,GAAG,IAAI,yPAAmB,OACzC;QAGF,IAAI,SAAS,wOAAM,GAAG,EAAE;YACtB,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,QAAQ,KAAK,CAAC,wOAAM,UAAU;QAC9B,QAAQ,OAAO,CAAC;QAChB,QAAQ,IAAI,CAAC,wOAAM,UAAU;QAC7B,OAAO,iPAAa,SAAS,cAAc,wOAAM,UAAU;IAC7D;IAEA,kBAAkB,GAClB,SAAS,iBAAiB,IAAI;QAC5B,+LACE,SAAS,wOAAM,GAAG,IAAI,CAAC,yPAAmB,OAC1C;QAEF,QAAQ,KAAK,CAAC,wOAAM,SAAS;QAC7B,OAAO,UAAU;IACnB;IAEA,kBAAkB,GAClB,SAAS,UAAU,IAAI;QACrB,MAAM,QAAQ,QAAQ,KAAK,CAAC,wOAAM,SAAS,EAAE;YAC3C,aAAa,4OAAU,eAAe;YACtC;QACF;QAEA,IAAI,UAAU;YACZ,SAAS,IAAI,GAAG;QAClB;QAEA,WAAW;QAEX,OAAO,KAAK;IACd;IAEA,kBAAkB,GAClB,SAAS,KAAK,IAAI;QAChB,IAAI,SAAS,wOAAM,GAAG,EAAE;YACtB,QAAQ,IAAI,CAAC,wOAAM,SAAS;YAC5B,QAAQ,IAAI,CAAC,wOAAM,SAAS;YAC5B,QAAQ,OAAO,CAAC;YAChB;QACF;QAEA,IAAI,yPAAmB,OAAO;YAC5B,QAAQ,OAAO,CAAC;YAChB,QAAQ,IAAI,CAAC,wOAAM,SAAS;YAC5B,OAAO;QACT;QAEA,QAAQ;QACR,QAAQ,OAAO,CAAC;QAChB,OAAO;IACT;AACF"}},
    {"offset": {"line": 5111, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5116, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/parse.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Create} Create\n * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n */\n\nimport {combineExtensions} from 'micromark-util-combine-extensions'\nimport {content} from './initialize/content.js'\nimport {document} from './initialize/document.js'\nimport {flow} from './initialize/flow.js'\nimport {string, text} from './initialize/text.js'\nimport {createTokenizer} from './create-tokenizer.js'\nimport * as defaultConstructs from './constructs.js'\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n * @returns {ParseContext}\n */\nexport function parse(options) {\n  const settings = options || {}\n  const constructs = /** @type {FullNormalizedExtension} */ (\n    combineExtensions([defaultConstructs, ...(settings.extensions || [])])\n  )\n\n  /** @type {ParseContext} */\n  const parser = {\n    defined: [],\n    lazy: {},\n    constructs,\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(string),\n    text: create(text)\n  }\n\n  return parser\n\n  /**\n   * @param {InitialConstruct} initial\n   */\n  function create(initial) {\n    return creator\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from)\n    }\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;CAMC;;;;;;;;;;;;;;;;;;AAcM,SAAS,MAAM,OAAO;IAC3B,MAAM,WAAW,WAAW,CAAC;IAC7B,MAAM,aACJ,yQAAkB;;WAAwB,SAAS,UAAU,IAAI,EAAE;KAAE;IAGvE,yBAAyB,GACzB,MAAM,SAAS;QACb,SAAS,EAAE;QACX,MAAM,CAAC;QACP;QACA,SAAS;QACT,UAAU;QACV,MAAM;QACN,QAAQ;QACR,MAAM;IACR;IAEA,OAAO;IAEP;;GAEC,GACD,SAAS,OAAO,OAAO;QACrB,OAAO;QACP,mBAAmB,GACnB,SAAS,QAAQ,IAAI;YACnB,OAAO,iOAAgB,QAAQ,SAAS;QAC1C;IACF;AACF"}},
    {"offset": {"line": 5166, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5171, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/lib/compile.js"],"sourcesContent":["/**\n * While micromark is a lexer/tokenizer, the common case of going from markdown\n * to html is currently built in as this module, even though the parts can be\n * used separately to build ASTs, CSTs, or many other output formats.\n *\n * Having an HTML compiler built in is useful because it allows us to check for\n * compliancy to CommonMark, the de facto norm of markdown, specified in roughly\n * 600 input/output cases.\n *\n * This module has an interface that accepts lists of events instead of the\n * whole at once, however, because markdown can’t be truly streaming, we buffer\n * events before processing and outputting the final result.\n */\n\n/**\n * @typedef {import('micromark-util-types').Compile} Compile\n * @typedef {import('micromark-util-types').CompileContext} CompileContext\n * @typedef {import('micromark-util-types').CompileData} CompileData\n * @typedef {import('micromark-util-types').CompileOptions} CompileOptions\n * @typedef {import('micromark-util-types').Definition} Definition\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Handle} Handle\n * @typedef {import('micromark-util-types').HtmlExtension} HtmlExtension\n * @typedef {import('micromark-util-types').NormalizedHtmlExtension} NormalizedHtmlExtension\n * @typedef {import('micromark-util-types').Token} Token\n */\n\n/**\n * @typedef Media\n * @property {boolean | undefined} [image]\n * @property {string | undefined} [labelId]\n * @property {string | undefined} [label]\n * @property {string | undefined} [referenceId]\n * @property {string | undefined} [destination]\n * @property {string | undefined} [title]\n */\n\nimport {decodeNamedCharacterReference} from 'decode-named-character-reference'\nimport {push} from 'micromark-util-chunked'\nimport {combineHtmlExtensions} from 'micromark-util-combine-extensions'\nimport {decodeNumericCharacterReference} from 'micromark-util-decode-numeric-character-reference'\nimport {encode as _encode} from 'micromark-util-encode'\nimport {normalizeIdentifier} from 'micromark-util-normalize-identifier'\nimport {sanitizeUri} from 'micromark-util-sanitize-uri'\nimport {codes, constants, types} from 'micromark-util-symbol'\nimport {ok as assert} from 'devlop'\n\nconst hasOwnProperty = {}.hasOwnProperty\n\n/**\n * These two are allowlists of safe protocols for full URLs in respectively the\n * `href` (on `<a>`) and `src` (on `<img>`) attributes.\n * They are based on what is allowed on GitHub,\n * <https://github.com/syntax-tree/hast-util-sanitize/blob/9275b21/lib/github.json#L31>\n */\nconst protocolHref = /^(https?|ircs?|mailto|xmpp)$/i\nconst protocolSrc = /^https?$/i\n\n/**\n * @param {CompileOptions | null | undefined} [options]\n * @returns {Compile}\n */\nexport function compile(options) {\n  const settings = options || {}\n\n  /**\n   * Tags is needed because according to markdown, links and emphasis and\n   * whatnot can exist in images, however, as HTML doesn’t allow content in\n   * images, the tags are ignored in the `alt` attribute, but the content\n   * remains.\n   *\n   * @type {boolean | undefined}\n   */\n  let tags = true\n\n  /**\n   * An object to track identifiers to media (URLs and titles) defined with\n   * definitions.\n   *\n   * @type {Record<string, Definition>}\n   */\n  const definitions = {}\n\n  /**\n   * A lot of the handlers need to capture some of the output data, modify it\n   * somehow, and then deal with it.\n   * We do that by tracking a stack of buffers, that can be opened (with\n   * `buffer`) and closed (with `resume`) to access them.\n   *\n   * @type {Array<Array<string>>}\n   */\n  const buffers = [[]]\n\n  /**\n   * As we can have links in images and the other way around, where the deepest\n   * ones are closed first, we need to track which one we’re in.\n   *\n   * @type {Array<Media>}\n   */\n  const mediaStack = []\n\n  /**\n   * Same as `mediaStack` for tightness, which is specific to lists.\n   * We need to track if we’re currently in a tight or loose container.\n   *\n   * @type {Array<boolean>}\n   */\n  const tightStack = []\n\n  /** @type {HtmlExtension} */\n  const defaultHandlers = {\n    enter: {\n      blockQuote: onenterblockquote,\n      codeFenced: onentercodefenced,\n      codeFencedFenceInfo: buffer,\n      codeFencedFenceMeta: buffer,\n      codeIndented: onentercodeindented,\n      codeText: onentercodetext,\n      content: onentercontent,\n      definition: onenterdefinition,\n      definitionDestinationString: onenterdefinitiondestinationstring,\n      definitionLabelString: buffer,\n      definitionTitleString: buffer,\n      emphasis: onenteremphasis,\n      htmlFlow: onenterhtmlflow,\n      htmlText: onenterhtml,\n      image: onenterimage,\n      label: buffer,\n      link: onenterlink,\n      listItemMarker: onenterlistitemmarker,\n      listItemValue: onenterlistitemvalue,\n      listOrdered: onenterlistordered,\n      listUnordered: onenterlistunordered,\n      paragraph: onenterparagraph,\n      reference: buffer,\n      resource: onenterresource,\n      resourceDestinationString: onenterresourcedestinationstring,\n      resourceTitleString: buffer,\n      setextHeading: onentersetextheading,\n      strong: onenterstrong\n    },\n    exit: {\n      atxHeading: onexitatxheading,\n      atxHeadingSequence: onexitatxheadingsequence,\n      autolinkEmail: onexitautolinkemail,\n      autolinkProtocol: onexitautolinkprotocol,\n      blockQuote: onexitblockquote,\n      characterEscapeValue: onexitdata,\n      characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,\n      characterReferenceMarkerNumeric: onexitcharacterreferencemarker,\n      characterReferenceValue: onexitcharacterreferencevalue,\n      codeFenced: onexitflowcode,\n      codeFencedFence: onexitcodefencedfence,\n      codeFencedFenceInfo: onexitcodefencedfenceinfo,\n      codeFencedFenceMeta: onresumedrop,\n      codeFlowValue: onexitcodeflowvalue,\n      codeIndented: onexitflowcode,\n      codeText: onexitcodetext,\n      codeTextData: onexitdata,\n      data: onexitdata,\n      definition: onexitdefinition,\n      definitionDestinationString: onexitdefinitiondestinationstring,\n      definitionLabelString: onexitdefinitionlabelstring,\n      definitionTitleString: onexitdefinitiontitlestring,\n      emphasis: onexitemphasis,\n      hardBreakEscape: onexithardbreak,\n      hardBreakTrailing: onexithardbreak,\n      htmlFlow: onexithtml,\n      htmlFlowData: onexitdata,\n      htmlText: onexithtml,\n      htmlTextData: onexitdata,\n      image: onexitmedia,\n      label: onexitlabel,\n      labelText: onexitlabeltext,\n      lineEnding: onexitlineending,\n      link: onexitmedia,\n      listOrdered: onexitlistordered,\n      listUnordered: onexitlistunordered,\n      paragraph: onexitparagraph,\n      reference: onresumedrop,\n      referenceString: onexitreferencestring,\n      resource: onresumedrop,\n      resourceDestinationString: onexitresourcedestinationstring,\n      resourceTitleString: onexitresourcetitlestring,\n      setextHeading: onexitsetextheading,\n      setextHeadingLineSequence: onexitsetextheadinglinesequence,\n      setextHeadingText: onexitsetextheadingtext,\n      strong: onexitstrong,\n      thematicBreak: onexitthematicbreak\n    }\n  }\n\n  /**\n   * Combine the HTML extensions with the default handlers.\n   * An HTML extension is an object whose fields are either `enter` or `exit`\n   * (reflecting whether a token is entered or exited).\n   * The values at such objects are names of tokens mapping to handlers.\n   * Handlers are called, respectively when a token is opener or closed, with\n   * that token, and a context as `this`.\n   */\n  const handlers = /** @type {NormalizedHtmlExtension} */ (\n    combineHtmlExtensions(\n      [defaultHandlers].concat(settings.htmlExtensions || [])\n    )\n  )\n\n  /**\n   * Handlers do often need to keep track of some state.\n   * That state is provided here as a key-value store (an object).\n   *\n   * @type {CompileData}\n   */\n  const data = {\n    tightStack,\n    definitions\n  }\n\n  /**\n   * The context for handlers references a couple of useful functions.\n   * In handlers from extensions, those can be accessed at `this`.\n   * For the handlers here, they can be accessed directly.\n   *\n   * @type {Omit<CompileContext, 'sliceSerialize'>}\n   */\n  const context = {\n    lineEndingIfNeeded,\n    options: settings,\n    encode,\n    raw,\n    tag,\n    buffer,\n    resume,\n    setData,\n    getData\n  }\n\n  /**\n   * Generally, micromark copies line endings (`'\\r'`, `'\\n'`, `'\\r\\n'`) in the\n   * markdown document over to the compiled HTML.\n   * In some cases, such as `> a`, CommonMark requires that extra line endings\n   * are added: `<blockquote>\\n<p>a</p>\\n</blockquote>`.\n   * This variable hold the default line ending when given (or `undefined`),\n   * and in the latter case will be updated to the first found line ending if\n   * there is one.\n   */\n  let lineEndingStyle = settings.defaultLineEnding\n\n  // Return the function that handles a slice of events.\n  return compile\n\n  /**\n   * Deal w/ a slice of events.\n   * Return either the empty string if there’s nothing of note to return, or the\n   * result when done.\n   *\n   * @param {Array<Event>} events\n   * @returns {string}\n   */\n  function compile(events) {\n    let index = -1\n    let start = 0\n    /** @type {Array<number>} */\n    const listStack = []\n    // As definitions can come after references, we need to figure out the media\n    // (urls and titles) defined by them before handling the references.\n    // So, we do sort of what HTML does: put metadata at the start (in head), and\n    // then put content after (`body`).\n    /** @type {Array<Event>} */\n    let head = []\n    /** @type {Array<Event>} */\n    let body = []\n\n    while (++index < events.length) {\n      // Figure out the line ending style used in the document.\n      if (\n        !lineEndingStyle &&\n        (events[index][1].type === types.lineEnding ||\n          events[index][1].type === types.lineEndingBlank)\n      ) {\n        // @ts-expect-error Hush, it’s a line ending.\n        lineEndingStyle = events[index][2].sliceSerialize(events[index][1])\n      }\n\n      // Preprocess lists to infer whether the list is loose or not.\n      if (\n        events[index][1].type === types.listOrdered ||\n        events[index][1].type === types.listUnordered\n      ) {\n        if (events[index][0] === 'enter') {\n          listStack.push(index)\n        } else {\n          prepareList(events.slice(listStack.pop(), index))\n        }\n      }\n\n      // Move definitions to the front.\n      if (events[index][1].type === types.definition) {\n        if (events[index][0] === 'enter') {\n          body = push(body, events.slice(start, index))\n          start = index\n        } else {\n          head = push(head, events.slice(start, index + 1))\n          start = index + 1\n        }\n      }\n    }\n\n    head = push(head, body)\n    head = push(head, events.slice(start))\n    index = -1\n    const result = head\n\n    // Handle the start of the document, if defined.\n    if (handlers.enter.null) {\n      handlers.enter.null.call(context)\n    }\n\n    // Handle all events.\n    while (++index < events.length) {\n      const handles = handlers[result[index][0]]\n      const kind = result[index][1].type\n      const handle = handles[kind]\n\n      if (hasOwnProperty.call(handles, kind) && handle) {\n        handle.call(\n          Object.assign(\n            {sliceSerialize: result[index][2].sliceSerialize},\n            context\n          ),\n          result[index][1]\n        )\n      }\n    }\n\n    // Handle the end of the document, if defined.\n    if (handlers.exit.null) {\n      handlers.exit.null.call(context)\n    }\n\n    return buffers[0].join('')\n  }\n\n  /**\n   * Figure out whether lists are loose or not.\n   *\n   * @param {Array<Event>} slice\n   * @returns {undefined}\n   */\n  function prepareList(slice) {\n    const length = slice.length\n    let index = 0 // Skip open.\n    let containerBalance = 0\n    let loose = false\n    /** @type {boolean | undefined} */\n    let atMarker\n\n    while (++index < length) {\n      const event = slice[index]\n\n      if (event[1]._container) {\n        atMarker = undefined\n\n        if (event[0] === 'enter') {\n          containerBalance++\n        } else {\n          containerBalance--\n        }\n      } else\n        switch (event[1].type) {\n          case types.listItemPrefix: {\n            if (event[0] === 'exit') {\n              atMarker = true\n            }\n\n            break\n          }\n\n          case types.linePrefix: {\n            // Ignore\n\n            break\n          }\n\n          case types.lineEndingBlank: {\n            if (event[0] === 'enter' && !containerBalance) {\n              if (atMarker) {\n                atMarker = undefined\n              } else {\n                loose = true\n              }\n            }\n\n            break\n          }\n\n          default: {\n            atMarker = undefined\n          }\n        }\n    }\n\n    slice[0][1]._loose = loose\n  }\n\n  /**\n   * @type {CompileContext['setData']}\n   */\n  function setData(key, value) {\n    // @ts-expect-error: assume `value` is omitted (`undefined` is passed) only\n    // if allowed.\n    data[key] = value\n  }\n\n  /**\n   * @type {CompileContext['getData']}\n   */\n  function getData(key) {\n    return data[key]\n  }\n\n  /** @type {CompileContext['buffer']} */\n  function buffer() {\n    buffers.push([])\n  }\n\n  /** @type {CompileContext['resume']} */\n  function resume() {\n    const buf = buffers.pop()\n    assert(buf !== undefined, 'Cannot resume w/o buffer')\n    return buf.join('')\n  }\n\n  /** @type {CompileContext['tag']} */\n  function tag(value) {\n    if (!tags) return\n    setData('lastWasTag', true)\n    buffers[buffers.length - 1].push(value)\n  }\n\n  /** @type {CompileContext['raw']} */\n  function raw(value) {\n    setData('lastWasTag')\n    buffers[buffers.length - 1].push(value)\n  }\n\n  /**\n   * Output an extra line ending.\n   *\n   * @returns {undefined}\n   */\n  function lineEnding() {\n    raw(lineEndingStyle || '\\n')\n  }\n\n  /** @type {CompileContext['lineEndingIfNeeded']} */\n  function lineEndingIfNeeded() {\n    const buffer = buffers[buffers.length - 1]\n    const slice = buffer[buffer.length - 1]\n    const previous = slice ? slice.charCodeAt(slice.length - 1) : codes.eof\n\n    if (\n      previous === codes.lf ||\n      previous === codes.cr ||\n      previous === codes.eof\n    ) {\n      return\n    }\n\n    lineEnding()\n  }\n\n  /** @type {CompileContext['encode']} */\n  function encode(value) {\n    return getData('ignoreEncode') ? value : _encode(value)\n  }\n\n  //\n  // Handlers.\n  //\n\n  /**\n   * @returns {undefined}\n   */\n  function onresumedrop() {\n    resume()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistordered(token) {\n    tightStack.push(!token._loose)\n    lineEndingIfNeeded()\n    tag('<ol')\n    setData('expectFirstItem', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistunordered(token) {\n    tightStack.push(!token._loose)\n    lineEndingIfNeeded()\n    tag('<ul')\n    setData('expectFirstItem', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlistitemvalue(token) {\n    if (getData('expectFirstItem')) {\n      const value = Number.parseInt(\n        this.sliceSerialize(token),\n        constants.numericBaseDecimal\n      )\n\n      if (value !== 1) {\n        tag(' start=\"' + encode(String(value)) + '\"')\n      }\n    }\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenterlistitemmarker() {\n    if (getData('expectFirstItem')) {\n      tag('>')\n    } else {\n      onexitlistitem()\n    }\n\n    lineEndingIfNeeded()\n    tag('<li>')\n    setData('expectFirstItem')\n    // “Hack” to prevent a line ending from showing up if the item is empty.\n    setData('lastWasTag')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitlistordered() {\n    onexitlistitem()\n    tightStack.pop()\n    lineEnding()\n    tag('</ol>')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitlistunordered() {\n    onexitlistitem()\n    tightStack.pop()\n    lineEnding()\n    tag('</ul>')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitlistitem() {\n    if (getData('lastWasTag') && !getData('slurpAllLineEndings')) {\n      lineEndingIfNeeded()\n    }\n\n    tag('</li>')\n    setData('slurpAllLineEndings')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterblockquote() {\n    tightStack.push(false)\n    lineEndingIfNeeded()\n    tag('<blockquote>')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitblockquote() {\n    tightStack.pop()\n    lineEndingIfNeeded()\n    tag('</blockquote>')\n    setData('slurpAllLineEndings')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterparagraph() {\n    if (!tightStack[tightStack.length - 1]) {\n      lineEndingIfNeeded()\n      tag('<p>')\n    }\n\n    setData('slurpAllLineEndings')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitparagraph() {\n    if (tightStack[tightStack.length - 1]) {\n      setData('slurpAllLineEndings', true)\n    } else {\n      tag('</p>')\n    }\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentercodefenced() {\n    lineEndingIfNeeded()\n    tag('<pre><code')\n    setData('fencesCount', 0)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfenceinfo() {\n    const value = resume()\n    tag(' class=\"language-' + value + '\"')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodefencedfence() {\n    const count = getData('fencesCount') || 0\n\n    if (!count) {\n      tag('>')\n      setData('slurpOneLineEnding', true)\n    }\n\n    setData('fencesCount', count + 1)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentercodeindented() {\n    lineEndingIfNeeded()\n    tag('<pre><code>')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitflowcode() {\n    const count = getData('fencesCount')\n\n    // One special case is if we are inside a container, and the fenced code was\n    // not closed (meaning it runs to the end).\n    // In that case, the following line ending, is considered *outside* the\n    // fenced code and block quote by micromark, but CM wants to treat that\n    // ending as part of the code.\n    if (\n      count !== undefined &&\n      count < 2 &&\n      data.tightStack.length > 0 &&\n      !getData('lastWasTag')\n    ) {\n      lineEnding()\n    }\n\n    // But in most cases, it’s simpler: when we’ve seen some data, emit an extra\n    // line ending when needed.\n    if (getData('flowCodeSeenData')) {\n      lineEndingIfNeeded()\n    }\n\n    tag('</code></pre>')\n    if (count !== undefined && count < 2) lineEndingIfNeeded()\n    setData('flowCodeSeenData')\n    setData('fencesCount')\n    setData('slurpOneLineEnding')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterimage() {\n    mediaStack.push({image: true})\n    tags = undefined // Disallow tags.\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterlink() {\n    mediaStack.push({})\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitlabeltext(token) {\n    mediaStack[mediaStack.length - 1].labelId = this.sliceSerialize(token)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitlabel() {\n    mediaStack[mediaStack.length - 1].label = resume()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitreferencestring(token) {\n    mediaStack[mediaStack.length - 1].referenceId = this.sliceSerialize(token)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterresource() {\n    buffer() // We can have line endings in the resource, ignore them.\n    mediaStack[mediaStack.length - 1].destination = ''\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterresourcedestinationstring() {\n    buffer()\n    // Ignore encoding the result, as we’ll first percent encode the url and\n    // encode manually after.\n    setData('ignoreEncode', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitresourcedestinationstring() {\n    mediaStack[mediaStack.length - 1].destination = resume()\n    setData('ignoreEncode')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitresourcetitlestring() {\n    mediaStack[mediaStack.length - 1].title = resume()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitmedia() {\n    let index = mediaStack.length - 1 // Skip current.\n    const media = mediaStack[index]\n    const id = media.referenceId || media.labelId\n    assert(id !== undefined, 'media should have `referenceId` or `labelId`')\n    assert(media.label !== undefined, 'media should have `label`')\n    const context =\n      media.destination === undefined\n        ? definitions[normalizeIdentifier(id)]\n        : media\n\n    tags = true\n\n    while (index--) {\n      if (mediaStack[index].image) {\n        tags = undefined\n        break\n      }\n    }\n\n    if (media.image) {\n      tag(\n        '<img src=\"' +\n          sanitizeUri(\n            context.destination,\n            settings.allowDangerousProtocol ? undefined : protocolSrc\n          ) +\n          '\" alt=\"'\n      )\n      raw(media.label)\n      tag('\"')\n    } else {\n      tag(\n        '<a href=\"' +\n          sanitizeUri(\n            context.destination,\n            settings.allowDangerousProtocol ? undefined : protocolHref\n          ) +\n          '\"'\n      )\n    }\n\n    tag(context.title ? ' title=\"' + context.title + '\"' : '')\n\n    if (media.image) {\n      tag(' />')\n    } else {\n      tag('>')\n      raw(media.label)\n      tag('</a>')\n    }\n\n    mediaStack.pop()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterdefinition() {\n    buffer()\n    mediaStack.push({})\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitionlabelstring(token) {\n    // Discard label, use the source content instead.\n    resume()\n    mediaStack[mediaStack.length - 1].labelId = this.sliceSerialize(token)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onenterdefinitiondestinationstring() {\n    buffer()\n    setData('ignoreEncode', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiondestinationstring() {\n    mediaStack[mediaStack.length - 1].destination = resume()\n    setData('ignoreEncode')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinitiontitlestring() {\n    mediaStack[mediaStack.length - 1].title = resume()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdefinition() {\n    const media = mediaStack[mediaStack.length - 1]\n    assert(media.labelId !== undefined, 'media should have `labelId`')\n    const id = normalizeIdentifier(media.labelId)\n\n    resume()\n\n    if (!hasOwnProperty.call(definitions, id)) {\n      definitions[id] = mediaStack[mediaStack.length - 1]\n    }\n\n    mediaStack.pop()\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentercontent() {\n    setData('slurpAllLineEndings', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitatxheadingsequence(token) {\n    // Exit for further sequences.\n    if (getData('headingRank')) return\n    setData('headingRank', this.sliceSerialize(token).length)\n    lineEndingIfNeeded()\n    tag('<h' + getData('headingRank') + '>')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onentersetextheading() {\n    buffer()\n    setData('slurpAllLineEndings')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadingtext() {\n    setData('slurpAllLineEndings', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitatxheading() {\n    tag('</h' + getData('headingRank') + '>')\n    setData('headingRank')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheadinglinesequence(token) {\n    setData(\n      'headingRank',\n      this.sliceSerialize(token).charCodeAt(0) === codes.equalsTo ? 1 : 2\n    )\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitsetextheading() {\n    const value = resume()\n    lineEndingIfNeeded()\n    tag('<h' + getData('headingRank') + '>')\n    raw(value)\n    tag('</h' + getData('headingRank') + '>')\n    setData('slurpAllLineEndings')\n    setData('headingRank')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitdata(token) {\n    raw(encode(this.sliceSerialize(token)))\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitlineending(token) {\n    if (getData('slurpAllLineEndings')) {\n      return\n    }\n\n    if (getData('slurpOneLineEnding')) {\n      setData('slurpOneLineEnding')\n      return\n    }\n\n    if (getData('inCodeText')) {\n      raw(' ')\n      return\n    }\n\n    raw(encode(this.sliceSerialize(token)))\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcodeflowvalue(token) {\n    raw(encode(this.sliceSerialize(token)))\n    setData('flowCodeSeenData', true)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexithardbreak() {\n    tag('<br />')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenterhtmlflow() {\n    lineEndingIfNeeded()\n    onenterhtml()\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexithtml() {\n    setData('ignoreEncode')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenterhtml() {\n    if (settings.allowDangerousHtml) {\n      setData('ignoreEncode', true)\n    }\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenteremphasis() {\n    tag('<em>')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onenterstrong() {\n    tag('<strong>')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onentercodetext() {\n    setData('inCodeText', true)\n    tag('<code>')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitcodetext() {\n    setData('inCodeText')\n    tag('</code>')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitemphasis() {\n    tag('</em>')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitstrong() {\n    tag('</strong>')\n  }\n\n  /**\n   * @returns {undefined}\n   */\n  function onexitthematicbreak() {\n    lineEndingIfNeeded()\n    tag('<hr />')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @param {Token} token\n   * @returns {undefined}\n   */\n  function onexitcharacterreferencemarker(token) {\n    setData('characterReferenceType', token.type)\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitcharacterreferencevalue(token) {\n    let value = this.sliceSerialize(token)\n\n    // @ts-expect-error `decodeNamedCharacterReference` can return false for\n    // invalid named character references, but everything we’ve tokenized is\n    // valid.\n    value = getData('characterReferenceType')\n      ? decodeNumericCharacterReference(\n          value,\n          getData('characterReferenceType') ===\n            types.characterReferenceMarkerNumeric\n            ? constants.numericBaseDecimal\n            : constants.numericBaseHexadecimal\n        )\n      : decodeNamedCharacterReference(value)\n\n    raw(encode(value))\n    setData('characterReferenceType')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkprotocol(token) {\n    const uri = this.sliceSerialize(token)\n    tag(\n      '<a href=\"' +\n        sanitizeUri(\n          uri,\n          settings.allowDangerousProtocol ? undefined : protocolHref\n        ) +\n        '\">'\n    )\n    raw(encode(uri))\n    tag('</a>')\n  }\n\n  /**\n   * @this {CompileContext}\n   * @type {Handle}\n   */\n  function onexitautolinkemail(token) {\n    const uri = this.sliceSerialize(token)\n    tag('<a href=\"' + sanitizeUri('mailto:' + uri) + '\">')\n    raw(encode(uri))\n    tag('</a>')\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;CAYC,GAED;;;;;;;;;;;CAWC,GAED;;;;;;;;CAQC;;;;;;;;;;;;;;;;;;;;;;AAYD,MAAM,iBAAiB,CAAC,EAAE,cAAc;AAExC;;;;;CAKC,GACD,MAAM,eAAe;AACrB,MAAM,cAAc;AAMb,SAAS,QAAQ,OAAO;IAC7B,MAAM,WAAW,WAAW,CAAC;IAE7B;;;;;;;GAOC,GACD,IAAI,OAAO;IAEX;;;;;GAKC,GACD,MAAM,cAAc,CAAC;IAErB;;;;;;;GAOC,GACD,MAAM,UAAU;QAAC,EAAE;KAAC;IAEpB;;;;;GAKC,GACD,MAAM,aAAa,EAAE;IAErB;;;;;GAKC,GACD,MAAM,aAAa,EAAE;IAErB,0BAA0B,GAC1B,MAAM,kBAAkB;QACtB,OAAO;YACL,YAAY;YACZ,YAAY;YACZ,qBAAqB;YACrB,qBAAqB;YACrB,cAAc;YACd,UAAU;YACV,SAAS;YACT,YAAY;YACZ,6BAA6B;YAC7B,uBAAuB;YACvB,uBAAuB;YACvB,UAAU;YACV,UAAU;YACV,UAAU;YACV,OAAO;YACP,OAAO;YACP,MAAM;YACN,gBAAgB;YAChB,eAAe;YACf,aAAa;YACb,eAAe;YACf,WAAW;YACX,WAAW;YACX,UAAU;YACV,2BAA2B;YAC3B,qBAAqB;YACrB,eAAe;YACf,QAAQ;QACV;QACA,MAAM;YACJ,YAAY;YACZ,oBAAoB;YACpB,eAAe;YACf,kBAAkB;YAClB,YAAY;YACZ,sBAAsB;YACtB,qCAAqC;YACrC,iCAAiC;YACjC,yBAAyB;YACzB,YAAY;YACZ,iBAAiB;YACjB,qBAAqB;YACrB,qBAAqB;YACrB,eAAe;YACf,cAAc;YACd,UAAU;YACV,cAAc;YACd,MAAM;YACN,YAAY;YACZ,6BAA6B;YAC7B,uBAAuB;YACvB,uBAAuB;YACvB,UAAU;YACV,iBAAiB;YACjB,mBAAmB;YACnB,UAAU;YACV,cAAc;YACd,UAAU;YACV,cAAc;YACd,OAAO;YACP,OAAO;YACP,WAAW;YACX,YAAY;YACZ,MAAM;YACN,aAAa;YACb,eAAe;YACf,WAAW;YACX,WAAW;YACX,iBAAiB;YACjB,UAAU;YACV,2BAA2B;YAC3B,qBAAqB;YACrB,eAAe;YACf,2BAA2B;YAC3B,mBAAmB;YACnB,QAAQ;YACR,eAAe;QACjB;IACF;IAEA;;;;;;;GAOC,GACD,MAAM,WACJ,6QACE;QAAC;KAAgB,CAAC,MAAM,CAAC,SAAS,cAAc,IAAI,EAAE;IAI1D;;;;;GAKC,GACD,MAAM,OAAO;QACX;QACA;IACF;IAEA;;;;;;GAMC,GACD,MAAM,UAAU;QACd;QACA,SAAS;QACT;QACA;QACA;QACA;QACA;QACA;QACA;IACF;IAEA;;;;;;;;GAQC,GACD,IAAI,kBAAkB,SAAS,iBAAiB;IAEhD,sDAAsD;IACtD,OAAO;IAEP;;;;;;;GAOC,GACD,SAAS,QAAQ,MAAM;QACrB,IAAI,QAAQ,CAAC;QACb,IAAI,QAAQ;QACZ,0BAA0B,GAC1B,MAAM,YAAY,EAAE;QACpB,4EAA4E;QAC5E,oEAAoE;QACpE,6EAA6E;QAC7E,mCAAmC;QACnC,yBAAyB,GACzB,IAAI,OAAO,EAAE;QACb,yBAAyB,GACzB,IAAI,OAAO,EAAE;QAEb,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;YAC9B,yDAAyD;YACzD,IACE,CAAC,mBACD,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,UAAU,IACzC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,eAAe,GACjD;gBACA,6CAA6C;gBAC7C,kBAAkB,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,cAAc,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE;YACpE;YAEA,8DAA8D;YAC9D,IACE,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,WAAW,IAC3C,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,aAAa,EAC7C;gBACA,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,KAAK,SAAS;oBAChC,UAAU,IAAI,CAAC;gBACjB,OAAO;oBACL,YAAY,OAAO,KAAK,CAAC,UAAU,GAAG,IAAI;gBAC5C;YACF;YAEA,iCAAiC;YACjC,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,wOAAM,UAAU,EAAE;gBAC9C,IAAI,MAAM,CAAC,MAAM,CAAC,EAAE,KAAK,SAAS;oBAChC,OAAO,uOAAK,MAAM,OAAO,KAAK,CAAC,OAAO;oBACtC,QAAQ;gBACV,OAAO;oBACL,OAAO,uOAAK,MAAM,OAAO,KAAK,CAAC,OAAO,QAAQ;oBAC9C,QAAQ,QAAQ;gBAClB;YACF;QACF;QAEA,OAAO,uOAAK,MAAM;QAClB,OAAO,uOAAK,MAAM,OAAO,KAAK,CAAC;QAC/B,QAAQ,CAAC;QACT,MAAM,SAAS;QAEf,gDAAgD;QAChD,IAAI,SAAS,KAAK,CAAC,IAAI,EAAE;YACvB,SAAS,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC;QAC3B;QAEA,qBAAqB;QACrB,MAAO,EAAE,QAAQ,OAAO,MAAM,CAAE;YAC9B,MAAM,UAAU,QAAQ,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC;YAC1C,MAAM,OAAO,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI;YAClC,MAAM,SAAS,OAAO,CAAC,KAAK;YAE5B,IAAI,eAAe,IAAI,CAAC,SAAS,SAAS,QAAQ;gBAChD,OAAO,IAAI,CACT,OAAO,MAAM,CACX;oBAAC,gBAAgB,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,cAAc;gBAAA,GAChD,UAEF,MAAM,CAAC,MAAM,CAAC,EAAE;YAEpB;QACF;QAEA,8CAA8C;QAC9C,IAAI,SAAS,IAAI,CAAC,IAAI,EAAE;YACtB,SAAS,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;QAC1B;QAEA,OAAO,OAAO,CAAC,EAAE,CAAC,IAAI,CAAC;IACzB;IAEA;;;;;GAKC,GACD,SAAS,YAAY,KAAK;QACxB,MAAM,SAAS,MAAM,MAAM;QAC3B,IAAI,QAAQ,EAAE,aAAa;;QAC3B,IAAI,mBAAmB;QACvB,IAAI,QAAQ;QACZ,gCAAgC,GAChC,IAAI;QAEJ,MAAO,EAAE,QAAQ,OAAQ;YACvB,MAAM,QAAQ,KAAK,CAAC,MAAM;YAE1B,IAAI,KAAK,CAAC,EAAE,CAAC,UAAU,EAAE;gBACvB,WAAW;gBAEX,IAAI,KAAK,CAAC,EAAE,KAAK,SAAS;oBACxB;gBACF,OAAO;oBACL;gBACF;YACF,OACE,OAAQ,KAAK,CAAC,EAAE,CAAC,IAAI;gBACnB,KAAK,wOAAM,cAAc;oBAAE;wBACzB,IAAI,KAAK,CAAC,EAAE,KAAK,QAAQ;4BACvB,WAAW;wBACb;wBAEA;oBACF;gBAEA,KAAK,wOAAM,UAAU;oBAAE;wBAGrB;oBACF;gBAEA,KAAK,wOAAM,eAAe;oBAAE;wBAC1B,IAAI,KAAK,CAAC,EAAE,KAAK,WAAW,CAAC,kBAAkB;4BAC7C,IAAI,UAAU;gCACZ,WAAW;4BACb,OAAO;gCACL,QAAQ;4BACV;wBACF;wBAEA;oBACF;gBAEA;oBAAS;wBACP,WAAW;oBACb;YACF;QACJ;QAEA,KAAK,CAAC,EAAE,CAAC,EAAE,CAAC,MAAM,GAAG;IACvB;IAEA;;GAEC,GACD,SAAS,QAAQ,GAAG,EAAE,KAAK;QACzB,2EAA2E;QAC3E,cAAc;QACd,IAAI,CAAC,IAAI,GAAG;IACd;IAEA;;GAEC,GACD,SAAS,QAAQ,GAAG;QAClB,OAAO,IAAI,CAAC,IAAI;IAClB;IAEA,qCAAqC,GACrC,SAAS;QACP,QAAQ,IAAI,CAAC,EAAE;IACjB;IAEA,qCAAqC,GACrC,SAAS;QACP,MAAM,MAAM,QAAQ,GAAG;QACvB,+LAAO,QAAQ,WAAW;QAC1B,OAAO,IAAI,IAAI,CAAC;IAClB;IAEA,kCAAkC,GAClC,SAAS,IAAI,KAAK;QAChB,IAAI,CAAC,MAAM;QACX,QAAQ,cAAc;QACtB,OAAO,CAAC,QAAQ,MAAM,GAAG,EAAE,CAAC,IAAI,CAAC;IACnC;IAEA,kCAAkC,GAClC,SAAS,IAAI,KAAK;QAChB,QAAQ;QACR,OAAO,CAAC,QAAQ,MAAM,GAAG,EAAE,CAAC,IAAI,CAAC;IACnC;IAEA;;;;GAIC,GACD,SAAS;QACP,IAAI,mBAAmB;IACzB;IAEA,iDAAiD,GACjD,SAAS;QACP,MAAM,SAAS,OAAO,CAAC,QAAQ,MAAM,GAAG,EAAE;QAC1C,MAAM,QAAQ,MAAM,CAAC,OAAO,MAAM,GAAG,EAAE;QACvC,MAAM,WAAW,QAAQ,MAAM,UAAU,CAAC,MAAM,MAAM,GAAG,KAAK,wOAAM,GAAG;QAEvE,IACE,aAAa,wOAAM,EAAE,IACrB,aAAa,wOAAM,EAAE,IACrB,aAAa,wOAAM,GAAG,EACtB;YACA;QACF;QAEA;IACF;IAEA,qCAAqC,GACrC,SAAS,OAAO,KAAK;QACnB,OAAO,QAAQ,kBAAkB,QAAQ,gOAAQ;IACnD;IAEA,EAAE;IACF,YAAY;IACZ,EAAE;IAEF;;GAEC,GACD,SAAS;QACP;IACF;IAEA;;;GAGC,GACD,SAAS,mBAAmB,KAAK;QAC/B,WAAW,IAAI,CAAC,CAAC,MAAM,MAAM;QAC7B;QACA,IAAI;QACJ,QAAQ,mBAAmB;IAC7B;IAEA;;;GAGC,GACD,SAAS,qBAAqB,KAAK;QACjC,WAAW,IAAI,CAAC,CAAC,MAAM,MAAM;QAC7B;QACA,IAAI;QACJ,QAAQ,mBAAmB;IAC7B;IAEA;;;GAGC,GACD,SAAS,qBAAqB,KAAK;QACjC,IAAI,QAAQ,oBAAoB;YAC9B,MAAM,QAAQ,OAAO,QAAQ,CAC3B,IAAI,CAAC,cAAc,CAAC,QACpB,4OAAU,kBAAkB;YAG9B,IAAI,UAAU,GAAG;gBACf,IAAI,aAAa,OAAO,OAAO,UAAU;YAC3C;QACF;IACF;IAEA;;GAEC,GACD,SAAS;QACP,IAAI,QAAQ,oBAAoB;YAC9B,IAAI;QACN,OAAO;YACL;QACF;QAEA;QACA,IAAI;QACJ,QAAQ;QACR,wEAAwE;QACxE,QAAQ;IACV;IAEA;;GAEC,GACD,SAAS;QACP;QACA,WAAW,GAAG;QACd;QACA,IAAI;IACN;IAEA;;GAEC,GACD,SAAS;QACP;QACA,WAAW,GAAG;QACd;QACA,IAAI;IACN;IAEA;;GAEC,GACD,SAAS;QACP,IAAI,QAAQ,iBAAiB,CAAC,QAAQ,wBAAwB;YAC5D;QACF;QAEA,IAAI;QACJ,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,WAAW,IAAI,CAAC;QAChB;QACA,IAAI;IACN;IAEA;;;GAGC,GACD,SAAS;QACP,WAAW,GAAG;QACd;QACA,IAAI;QACJ,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,CAAC,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,EAAE;YACtC;YACA,IAAI;QACN;QAEA,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,EAAE;YACrC,QAAQ,uBAAuB;QACjC,OAAO;YACL,IAAI;QACN;IACF;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,IAAI;QACJ,QAAQ,eAAe;IACzB;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ;QACd,IAAI,sBAAsB,QAAQ;IACpC;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ,QAAQ,kBAAkB;QAExC,IAAI,CAAC,OAAO;YACV,IAAI;YACJ,QAAQ,sBAAsB;QAChC;QAEA,QAAQ,eAAe,QAAQ;IACjC;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,IAAI;IACN;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ,QAAQ;QAEtB,4EAA4E;QAC5E,2CAA2C;QAC3C,uEAAuE;QACvE,uEAAuE;QACvE,8BAA8B;QAC9B,IACE,UAAU,aACV,QAAQ,KACR,KAAK,UAAU,CAAC,MAAM,GAAG,KACzB,CAAC,QAAQ,eACT;YACA;QACF;QAEA,4EAA4E;QAC5E,2BAA2B;QAC3B,IAAI,QAAQ,qBAAqB;YAC/B;QACF;QAEA,IAAI;QACJ,IAAI,UAAU,aAAa,QAAQ,GAAG;QACtC,QAAQ;QACR,QAAQ;QACR,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,WAAW,IAAI,CAAC;YAAC,OAAO;QAAI;QAC5B,OAAO,UAAU,iBAAiB;;IACpC;IAEA;;;GAGC,GACD,SAAS;QACP,WAAW,IAAI,CAAC,CAAC;IACnB;IAEA;;;GAGC,GACD,SAAS,gBAAgB,KAAK;QAC5B,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,OAAO,GAAG,IAAI,CAAC,cAAc,CAAC;IAClE;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,KAAK,GAAG;IAC5C;IAEA;;;GAGC,GACD,SAAS,sBAAsB,KAAK;QAClC,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,WAAW,GAAG,IAAI,CAAC,cAAc,CAAC;IACtE;IAEA;;;GAGC,GACD,SAAS;QACP,SAAS,yDAAyD;;QAClE,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,WAAW,GAAG;IAClD;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,wEAAwE;QACxE,yBAAyB;QACzB,QAAQ,gBAAgB;IAC1B;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,WAAW,GAAG;QAChD,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,KAAK,GAAG;IAC5C;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,QAAQ,WAAW,MAAM,GAAG,EAAE,gBAAgB;;QAClD,MAAM,QAAQ,UAAU,CAAC,MAAM;QAC/B,MAAM,KAAK,MAAM,WAAW,IAAI,MAAM,OAAO;QAC7C,+LAAO,OAAO,WAAW;QACzB,+LAAO,MAAM,KAAK,KAAK,WAAW;QAClC,MAAM,UACJ,MAAM,WAAW,KAAK,YAClB,WAAW,CAAC,sRAAoB,IAAI,GACpC;QAEN,OAAO;QAEP,MAAO,QAAS;YACd,IAAI,UAAU,CAAC,MAAM,CAAC,KAAK,EAAE;gBAC3B,OAAO;gBACP;YACF;QACF;QAEA,IAAI,MAAM,KAAK,EAAE;YACf,IACE,eACE,8PACE,QAAQ,WAAW,EACnB,SAAS,sBAAsB,GAAG,YAAY,eAEhD;YAEJ,IAAI,MAAM,KAAK;YACf,IAAI;QACN,OAAO;YACL,IACE,cACE,8PACE,QAAQ,WAAW,EACnB,SAAS,sBAAsB,GAAG,YAAY,gBAEhD;QAEN;QAEA,IAAI,QAAQ,KAAK,GAAG,aAAa,QAAQ,KAAK,GAAG,MAAM;QAEvD,IAAI,MAAM,KAAK,EAAE;YACf,IAAI;QACN,OAAO;YACL,IAAI;YACJ,IAAI,MAAM,KAAK;YACf,IAAI;QACN;QAEA,WAAW,GAAG;IAChB;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,WAAW,IAAI,CAAC,CAAC;IACnB;IAEA;;;GAGC,GACD,SAAS,4BAA4B,KAAK;QACxC,iDAAiD;QACjD;QACA,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,OAAO,GAAG,IAAI,CAAC,cAAc,CAAC;IAClE;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,QAAQ,gBAAgB;IAC1B;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,WAAW,GAAG;QAChD,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,CAAC,KAAK,GAAG;IAC5C;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE;QAC/C,+LAAO,MAAM,OAAO,KAAK,WAAW;QACpC,MAAM,KAAK,sRAAoB,MAAM,OAAO;QAE5C;QAEA,IAAI,CAAC,eAAe,IAAI,CAAC,aAAa,KAAK;YACzC,WAAW,CAAC,GAAG,GAAG,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE;QACrD;QAEA,WAAW,GAAG;IAChB;IAEA;;;GAGC,GACD,SAAS;QACP,QAAQ,uBAAuB;IACjC;IAEA;;;GAGC,GACD,SAAS,yBAAyB,KAAK;QACrC,8BAA8B;QAC9B,IAAI,QAAQ,gBAAgB;QAC5B,QAAQ,eAAe,IAAI,CAAC,cAAc,CAAC,OAAO,MAAM;QACxD;QACA,IAAI,OAAO,QAAQ,iBAAiB;IACtC;IAEA;;;GAGC,GACD,SAAS;QACP;QACA,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS;QACP,QAAQ,uBAAuB;IACjC;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI,QAAQ,QAAQ,iBAAiB;QACrC,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS,gCAAgC,KAAK;QAC5C,QACE,eACA,IAAI,CAAC,cAAc,CAAC,OAAO,UAAU,CAAC,OAAO,wOAAM,QAAQ,GAAG,IAAI;IAEtE;IAEA;;;GAGC,GACD,SAAS;QACP,MAAM,QAAQ;QACd;QACA,IAAI,OAAO,QAAQ,iBAAiB;QACpC,IAAI;QACJ,IAAI,QAAQ,QAAQ,iBAAiB;QACrC,QAAQ;QACR,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS,WAAW,KAAK;QACvB,IAAI,OAAO,IAAI,CAAC,cAAc,CAAC;IACjC;IAEA;;;GAGC,GACD,SAAS,iBAAiB,KAAK;QAC7B,IAAI,QAAQ,wBAAwB;YAClC;QACF;QAEA,IAAI,QAAQ,uBAAuB;YACjC,QAAQ;YACR;QACF;QAEA,IAAI,QAAQ,eAAe;YACzB,IAAI;YACJ;QACF;QAEA,IAAI,OAAO,IAAI,CAAC,cAAc,CAAC;IACjC;IAEA;;;GAGC,GACD,SAAS,oBAAoB,KAAK;QAChC,IAAI,OAAO,IAAI,CAAC,cAAc,CAAC;QAC/B,QAAQ,oBAAoB;IAC9B;IAEA;;;GAGC,GACD,SAAS;QACP,IAAI;IACN;IAEA;;GAEC,GACD,SAAS;QACP;QACA;IACF;IAEA;;GAEC,GACD,SAAS;QACP,QAAQ;IACV;IAEA;;GAEC,GACD,SAAS;QACP,IAAI,SAAS,kBAAkB,EAAE;YAC/B,QAAQ,gBAAgB;QAC1B;IACF;IAEA;;GAEC,GACD,SAAS;QACP,IAAI;IACN;IAEA;;GAEC,GACD,SAAS;QACP,IAAI;IACN;IAEA;;GAEC,GACD,SAAS;QACP,QAAQ,cAAc;QACtB,IAAI;IACN;IAEA;;GAEC,GACD,SAAS;QACP,QAAQ;QACR,IAAI;IACN;IAEA;;GAEC,GACD,SAAS;QACP,IAAI;IACN;IAEA;;GAEC,GACD,SAAS;QACP,IAAI;IACN;IAEA;;GAEC,GACD,SAAS;QACP;QACA,IAAI;IACN;IAEA;;;;GAIC,GACD,SAAS,+BAA+B,KAAK;QAC3C,QAAQ,0BAA0B,MAAM,IAAI;IAC9C;IAEA;;;GAGC,GACD,SAAS,8BAA8B,KAAK;QAC1C,IAAI,QAAQ,IAAI,CAAC,cAAc,CAAC;QAEhC,wEAAwE;QACxE,wEAAwE;QACxE,SAAS;QACT,QAAQ,QAAQ,4BACZ,0UACE,OACA,QAAQ,8BACN,wOAAM,+BAA+B,GACnC,4OAAU,kBAAkB,GAC5B,4OAAU,sBAAsB,IAEtC,mRAA8B;QAElC,IAAI,OAAO;QACX,QAAQ;IACV;IAEA;;;GAGC,GACD,SAAS,uBAAuB,KAAK;QACnC,MAAM,MAAM,IAAI,CAAC,cAAc,CAAC;QAChC,IACE,cACE,8PACE,KACA,SAAS,sBAAsB,GAAG,YAAY,gBAEhD;QAEJ,IAAI,OAAO;QACX,IAAI;IACN;IAEA;;;GAGC,GACD,SAAS,oBAAoB,KAAK;QAChC,MAAM,MAAM,IAAI,CAAC,cAAc,CAAC;QAChC,IAAI,cAAc,8PAAY,YAAY,OAAO;QACjD,IAAI,OAAO;QACX,IAAI;IACN;AACF"}},
    {"offset": {"line": 6066, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6071, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/.pnpm/micromark@4.0.0/node_modules/micromark/dev/index.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Options} Options\n * @typedef {import('micromark-util-types').Value} Value\n */\n\nimport {compile} from './lib/compile.js'\nimport {parse} from './lib/parse.js'\nimport {postprocess} from './lib/postprocess.js'\nimport {preprocess} from './lib/preprocess.js'\n\nexport {compile} from './lib/compile.js'\nexport {parse} from './lib/parse.js'\nexport {postprocess} from './lib/postprocess.js'\nexport {preprocess} from './lib/preprocess.js'\n\n/**\n * Compile markdown to HTML.\n *\n * > Note: which encodings are supported depends on the engine.\n * > For info on Node.js, see:\n * > <https://nodejs.org/api/util.html#whatwg-supported-encodings>.\n *\n * @overload\n * @param {Value} value\n *   Markdown to parse (`string` or `Uint8Array`).\n * @param {Encoding | null | undefined} encoding\n *   Character encoding to understand `value` as when it’s a `Uint8Array`\n *   (`string`, default: `'utf8'`).\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {string}\n *   Compiled HTML.\n *\n * @overload\n * @param {Value} value\n *   Markdown to parse (`string` or `Uint8Array`).\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {string}\n *   Compiled HTML.\n *\n * @param {Value} value\n *   Markdown to parse (`string` or `Uint8Array`).\n * @param {Encoding | Options | null | undefined} [encoding]\n *   Character encoding to understand `value` as when it’s a `Uint8Array`\n *   (`string`, default: `'utf8'`).\n * @param {Options | null | undefined} [options]\n *   Configuration.\n * @returns {string}\n *   Compiled HTML.\n */\nexport function micromark(value, encoding, options) {\n  if (typeof encoding !== 'string') {\n    options = encoding\n    encoding = undefined\n  }\n\n  return compile(options)(\n    postprocess(\n      parse(options).document().write(preprocess()(value, encoding, true))\n    )\n  )\n}\n"],"names":[],"mappings":"AAAA;;;;CAIC;;;;;;;;;;;;;;;;;;;;;;;;AAgDM,SAAS,UAAU,KAAK,EAAE,QAAQ,EAAE,OAAO;IAChD,IAAI,OAAO,aAAa,UAAU;QAChC,UAAU;QACV,WAAW;IACb;IAEA,OAAO,6MAAQ,SACb,qNACE,yMAAM,SAAS,QAAQ,GAAG,KAAK,CAAC,qNAAa,OAAO,UAAU;AAGpE"}},
    {"offset": {"line": 6106, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}